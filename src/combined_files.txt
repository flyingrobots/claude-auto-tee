# /Users/james/git/claude-auto-tee/src/claude-auto-tee.sh
#!/usr/bin/env bash
# Claude Auto-Tee Hook - Minimal Implementation
# Automatically injects tee for pipe commands to save full output

set -euo pipefail
IFS=$'\n\t'

# Source required modules
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/error-codes.sh"
source "${SCRIPT_DIR}/disk-space-check.sh"
source "${SCRIPT_DIR}/path-utils.sh"
source "${SCRIPT_DIR}/markers/pretooluse-markers.sh"

# Environment variable overrides (P1.T003)
readonly VERBOSE_MODE="${CLAUDE_AUTO_TEE_VERBOSE:-false}"
readonly CLEANUP_ON_SUCCESS="${CLAUDE_AUTO_TEE_CLEANUP_ON_SUCCESS:-true}"
readonly TEMP_FILE_PREFIX="${CLAUDE_AUTO_TEE_TEMP_PREFIX:-claude}"
# Default size limit: 100MB (100 * 1024 * 1024 = 104857600 bytes)
readonly DEFAULT_MAX_TEMP_FILE_SIZE=104857600
readonly MAX_TEMP_FILE_SIZE="${CLAUDE_AUTO_TEE_MAX_SIZE:-$DEFAULT_MAX_TEMP_FILE_SIZE}"

# Age-based cleanup configuration (P1.T015)
readonly CLEANUP_AGE_HOURS="${CLAUDE_AUTO_TEE_CLEANUP_AGE_HOURS:-48}"   # Default: 48 hours
readonly ENABLE_AGE_CLEANUP="${CLAUDE_AUTO_TEE_ENABLE_AGE_CLEANUP:-true}"

# Resource usage warning configuration (P1.T022)
readonly ENABLE_RESOURCE_WARNINGS="${CLAUDE_AUTO_TEE_ENABLE_RESOURCE_WARNINGS:-true}"
readonly SPACE_WARNING_THRESHOLD_MB="${CLAUDE_AUTO_TEE_SPACE_WARNING_THRESHOLD_MB:-500}" # Warn if less than 500MB
readonly TEMP_FILE_WARNING_SIZE_MB="${CLAUDE_AUTO_TEE_TEMP_FILE_WARNING_SIZE_MB:-50}"     # Warn if temp file > 50MB
readonly MAX_TEMP_FILES_WARNING="${CLAUDE_AUTO_TEE_MAX_TEMP_FILES_WARNING:-20}"           # Warn if > 20 temp files

# Verbose logging function
log_verbose() {
    if [[ "$VERBOSE_MODE" == "true" ]]; then
        echo "[CLAUDE-AUTO-TEE] $1" >&2
    fi
}

# Check if verbose mode is enabled (for error reporting)
is_verbose_mode() {
    [[ "$VERBOSE_MODE" == "true" ]]
}

# Resource usage warning functions (P1.T022)
log_resource_warning() {
    if [[ "$ENABLE_RESOURCE_WARNINGS" == "true" ]]; then
        echo "[CLAUDE-AUTO-TEE] ⚠️  RESOURCE WARNING: $1" >&2
    fi
}

check_disk_space_warnings() {
    local temp_dir="$1"
    
    if [[ "$ENABLE_RESOURCE_WARNINGS" != "true" ]]; then
        return 0
    fi
    
    # Get available space in MB with timeout protection
    local available_mb
    if available_mb=$(timeout 5 check_disk_space "$temp_dir" 2>/dev/null); then
        # Remove 'MB' suffix if present
        available_mb="${available_mb%MB}"
        
        # Check if space is below warning threshold
        if [[ "$available_mb" =~ ^[0-9]+$ ]] && [[ "$available_mb" -lt "$SPACE_WARNING_THRESHOLD_MB" ]]; then
            log_resource_warning "Low disk space in temp directory: ${available_mb}MB available (threshold: ${SPACE_WARNING_THRESHOLD_MB}MB)"
            log_resource_warning "Consider cleaning up temp files or using CLAUDE_AUTO_TEE_TEMP_DIR to specify alternative location"
        fi
    fi
}

check_temp_file_count_warnings() {
    local temp_dir="$1"
    
    if [[ "$ENABLE_RESOURCE_WARNINGS" != "true" ]] || [[ ! -d "$temp_dir" ]]; then
        return 0
    fi
    
    # Count existing claude temp files with timeout and depth protection
    local temp_file_count
    if temp_file_count=$(timeout 3 find "$temp_dir" -maxdepth 1 -name "${TEMP_FILE_PREFIX}-*" -type f 2>/dev/null | wc -l 2>/dev/null); then
        temp_file_count="${temp_file_count// /}" # Remove whitespace
        
        if [[ "$temp_file_count" =~ ^[0-9]+$ ]] && [[ "$temp_file_count" -gt "$MAX_TEMP_FILES_WARNING" ]]; then
            log_resource_warning "High number of temp files detected: $temp_file_count files (threshold: $MAX_TEMP_FILES_WARNING)"
            log_resource_warning "Consider enabling cleanup: export CLAUDE_AUTO_TEE_CLEANUP_ON_SUCCESS=true"
            if [[ "$temp_file_count" -gt $((MAX_TEMP_FILES_WARNING * 2)) ]]; then
                log_resource_warning "Very high temp file count! You may want to clean up manually: rm -f ${temp_dir}/${TEMP_FILE_PREFIX}-*"
            fi
        fi
    else
        # Fallback: skip the check if find takes too long
        log_verbose "Temp file count check skipped (directory scan timeout)"
    fi
}

monitor_resource_usage() {
    local temp_dir="$1"
    
    if [[ "$ENABLE_RESOURCE_WARNINGS" != "true" ]]; then
        return 0
    fi
    
    log_verbose "Monitoring resource usage (warnings enabled)"
    
    # Check disk space warnings (with timeout protection)
    check_disk_space_warnings "$temp_dir"
    
    # Check temp file count warnings (with timeout protection)
    check_temp_file_count_warnings "$temp_dir"
}

# Create cleanup function script (P1.T013)
create_cleanup_function() {
    local temp_dir="$1"
    local cleanup_script="${temp_dir}/claude-cleanup-$$-$RANDOM.sh"
    
    cat > "$cleanup_script" << 'EOF'
#!/usr/bin/env bash
# Cleanup function for claude-auto-tee temp files
cleanup_temp_file() {
    local file_path="$1"
    if [[ -n "$file_path" ]] && [[ -f "$file_path" ]]; then
        if rm -f "$file_path" 2>/dev/null; then
            if [[ "${CLAUDE_AUTO_TEE_VERBOSE:-false}" == "true" ]]; then
                echo "[CLAUDE-AUTO-TEE] Cleaned up temp file: $file_path" >&2
            fi
        else
            echo "[CLAUDE-AUTO-TEE] Warning: Could not clean up temp file: $file_path" >&2
        fi
    fi
}
EOF
    
    chmod +x "$cleanup_script" 2>/dev/null || true
    echo "$cleanup_script"
}


# Initial verbose mode detection
log_verbose "Verbose mode enabled (CLAUDE_AUTO_TEE_VERBOSE=$VERBOSE_MODE)"
log_verbose "Resource usage warnings: $ENABLE_RESOURCE_WARNINGS (disk space threshold: ${SPACE_WARNING_THRESHOLD_MB}MB, file size threshold: ${TEMP_FILE_WARNING_SIZE_MB}MB)"

# Global variables for cleanup on interruption (P1.T014)
CURRENT_TEMP_FILE=""
CURRENT_CLEANUP_SCRIPT=""
MONITOR_PID=""

# Cleanup function for script interruption (P1.T014)
cleanup_on_interruption() {
    local signal="${1:-UNKNOWN}"
    log_verbose "Received signal $signal - performing cleanup"
    
    # Kill background monitoring process if running (for future size limit monitoring)
    if [[ -n "$MONITOR_PID" ]]; then
        kill "$MONITOR_PID" 2>/dev/null || true
        log_verbose "Killed background monitoring process (PID: $MONITOR_PID)"
    fi
    
    # Clean up temp files
    if [[ -n "$CURRENT_TEMP_FILE" ]] && [[ -f "$CURRENT_TEMP_FILE" ]]; then
        rm -f "$CURRENT_TEMP_FILE" 2>/dev/null || true
        log_verbose "Cleaned up temp file: $CURRENT_TEMP_FILE"
    fi
    
    # Clean up cleanup script
    if [[ -n "$CURRENT_CLEANUP_SCRIPT" ]] && [[ -f "$CURRENT_CLEANUP_SCRIPT" ]]; then
        rm -f "$CURRENT_CLEANUP_SCRIPT" 2>/dev/null || true
        log_verbose "Cleaned up cleanup script: $CURRENT_CLEANUP_SCRIPT"
    fi
    
    # Exit with appropriate code
    if [[ "$signal" == "EXIT" ]]; then
        exit 0
    else
        exit 130  # Standard exit code for script interrupted by Ctrl+C
    fi
}

# Set up signal handlers for interruption cleanup (P1.T014)
trap 'cleanup_on_interruption INT' INT     # Ctrl+C
trap 'cleanup_on_interruption TERM' TERM  # Termination signal
trap 'cleanup_on_interruption EXIT' EXIT  # Normal exit
trap 'cleanup_on_interruption HUP' HUP    # Hangup signal
log_verbose "Signal handlers installed for cleanup on interruption"

# Age-based cleanup for orphaned files (P1.T015)
cleanup_orphaned_files() {
    local temp_dir="$1"
    local age_hours="${CLEANUP_AGE_HOURS}"
    
    # Validate inputs
    if [[ ! -d "$temp_dir" ]]; then
        log_verbose "Temp directory doesn't exist for orphaned cleanup: $temp_dir"
        return 0
    fi
    
    if [[ -z "$age_hours" ]] || [[ ! "$age_hours" =~ ^[0-9]+$ ]]; then
        log_verbose "Invalid age hours for cleanup: '$age_hours', using default: 48"
        age_hours=48
    fi
    
    log_verbose "Starting orphaned file cleanup in $temp_dir (age threshold: ${age_hours}h)"
    
    # Find files older than the threshold
    local cleanup_count=0
    local error_count=0
    
    # Use find with -mtime for age detection (convert hours to days for find)
    # find -mtime +n finds files modified more than n*24 hours ago
    # For hours, we need to be more precise, so we'll use a different approach
    local age_minutes=$((age_hours * 60))
    
    # Find claude-auto-tee temp files older than threshold
    # Use a more portable approach that works across platforms
    local current_time
    current_time=$(date +%s)
    local cutoff_time=$((current_time - age_hours * 3600))
    
    log_verbose "Cleanup cutoff time: $(date -r "$cutoff_time" 2>/dev/null || date -d "@$cutoff_time" 2>/dev/null || echo "unknown")"
    
    # Find files matching our pattern
    local temp_pattern="${temp_dir}/${TEMP_FILE_PREFIX}-*"
    
    # Use find if available, otherwise fall back to ls-based approach
    if command -v find >/dev/null 2>&1; then
        log_verbose "Using find to locate orphaned files in: $temp_dir"
        # Find files matching our pattern that are older than cutoff time
        while IFS= read -r -d '' file; do
            if [[ -f "$file" ]]; then
                # Check if file is safe to delete (not currently in use)
                if is_file_safe_to_delete "$file"; then
                    local file_time
                    # Get file modification time (cross-platform)
                    if stat -c %Y "$file" >/dev/null 2>&1; then
                        # GNU stat (Linux)
                        file_time=$(stat -c %Y "$file")
                    elif stat -f %m "$file" >/dev/null 2>&1; then
                        # BSD stat (macOS)
                        file_time=$(stat -f %m "$file")
                    else
                        # Fallback - assume file is old enough if we can't check
                        log_verbose "Cannot determine file age for $file, skipping"
                        continue
                    fi
                    
                    # Check if file is old enough
                    if [[ "$file_time" -lt "$cutoff_time" ]]; then
                        if rm -f "$file" 2>/dev/null; then
                            ((cleanup_count++))
                            log_verbose "Removed orphaned file: $file (age: $(( (current_time - file_time) / 3600 ))h)"
                        else
                            log_verbose "Failed to remove orphaned file: $file"
                            ((error_count++))
                        fi
                    fi
                else
                    log_verbose "File appears to be in use, skipping: $file"
                fi
            fi
        done < <(timeout 10 find "$temp_dir" -maxdepth 2 -name "${TEMP_FILE_PREFIX}-*" -type f -print0 2>/dev/null || true)
    else
        # Fallback for systems without find
        log_verbose "find command not available, using fallback cleanup method"
        # This is less precise but still functional
        local pattern="${temp_dir}/${TEMP_FILE_PREFIX}-*"
        for file in $pattern; do
            # Check if the glob pattern matched any files
            if [[ -f "$file" ]] && is_file_safe_to_delete "$file"; then
                # Simple age check - if file exists, try to remove if older than threshold
                # This is a simplified version without precise time checking
                log_verbose "Attempting to remove potentially orphaned file: $file"
                if rm -f "$file" 2>/dev/null; then
                    ((cleanup_count++))
                else
                    ((error_count++))
                fi
            fi
        done
    fi
    
    if [[ "$cleanup_count" -gt 0 ]] || [[ "$error_count" -gt 0 ]]; then
        log_verbose "Orphaned file cleanup completed: $cleanup_count removed, $error_count errors"
    else
        log_verbose "No orphaned files found for cleanup"
    fi
    
    return 0
}

# Check if a file is safe to delete (not actively in use)
is_file_safe_to_delete() {
    local file="$1"
    
    # Basic safety checks
    if [[ ! -f "$file" ]]; then
        return 1  # File doesn't exist
    fi
    
    # Check if file is currently being written to by checking for file locks
    # This is platform-dependent and best-effort
    
    # Method 1: Check if file is open (Linux with lsof)
    if command -v lsof >/dev/null 2>&1; then
        if lsof "$file" >/dev/null 2>&1; then
            log_verbose "File appears to be open: $file"
            return 1  # File is in use
        fi
    fi
    
    # Method 2: Try to get exclusive lock (portable but may not work on all systems)
    # Use flock if available
    if command -v flock >/dev/null 2>&1; then
        if ! flock -n 9 2>/dev/null 9<"$file"; then
            log_verbose "File appears to be locked: $file"
            return 1  # File is locked
        fi
        # Close the file descriptor
        exec 9<&-
    fi
    
    # Method 3: Check file age vs process lifetime (conservative approach)
    # If file was created very recently (within last 5 minutes), be cautious
    local current_time
    current_time=$(date +%s)
    local file_time
    
    if stat -c %Y "$file" >/dev/null 2>&1; then
        file_time=$(stat -c %Y "$file")
    elif stat -f %m "$file" >/dev/null 2>&1; then
        file_time=$(stat -f %m "$file")
    else
        # Cannot determine file age, err on side of caution for very recently created files
        # Use file creation time heuristic from filename if possible
        local filename
        filename=$(basename "$file")
        if [[ "$filename" =~ ${TEMP_FILE_PREFIX}-([0-9]+)\.log ]]; then
            local file_timestamp="${BASH_REMATCH[1]}"
            # This is a nanosecond timestamp truncated to 13 digits
            # Convert to seconds (first 10 digits)
            file_time="${file_timestamp:0:10}"
        else
            # Cannot determine age, assume it's safe after 5 minutes of existence
            # This is a fallback - in practice, this shouldn't happen often
            log_verbose "Cannot determine file creation time for $file, assuming safe"
            return 0
        fi
    fi
    
    # If file is very recent (less than 5 minutes old), be cautious
    local age_seconds=$((current_time - file_time))
    if [[ "$age_seconds" -lt 300 ]]; then  # 5 minutes
        log_verbose "File too recent for safe deletion: $file (${age_seconds}s old)"
        return 1
    fi
    
    # File appears safe to delete
    return 0
}

# Run age-based cleanup during initialization (P1.T015)
run_startup_cleanup() {
    if [[ "$ENABLE_AGE_CLEANUP" != "true" ]]; then
        log_verbose "Age-based cleanup disabled (CLAUDE_AUTO_TEE_ENABLE_AGE_CLEANUP=$ENABLE_AGE_CLEANUP)"
        return 0
    fi
    
    log_verbose "Running startup orphaned file cleanup"
    
    # Get list of potential temp directories to clean
    local temp_dirs_to_clean=()
    
    # Add the current temp directory
    local current_temp_dir
    current_temp_dir=$(get_temp_dir 2>/dev/null || echo "")
    if [[ -n "$current_temp_dir" ]] && [[ -d "$current_temp_dir" ]]; then
        temp_dirs_to_clean+=("$current_temp_dir")
    fi
    
    # Add standard temp directories if different from current
    for std_temp_dir in "/tmp" "/var/tmp" "${HOME}/tmp" "${HOME}/.tmp"; do
        if [[ -d "$std_temp_dir" ]] && [[ "$std_temp_dir" != "$current_temp_dir" ]]; then
            temp_dirs_to_clean+=("$std_temp_dir")
        fi
    done
    
    # Add environment variable temp directories
    for env_temp_dir in "${TMPDIR:-}" "${TMP:-}" "${TEMP:-}" "${CLAUDE_AUTO_TEE_TEMP_DIR:-}"; do
        if [[ -n "$env_temp_dir" ]] && [[ -d "$env_temp_dir" ]]; then
            local clean_dir
            clean_dir=$(normalize_path "$env_temp_dir")
            # Check if not already in list
            local already_added=false
            for existing_dir in "${temp_dirs_to_clean[@]}"; do
                if [[ "$clean_dir" == "$existing_dir" ]]; then
                    already_added=true
                    break
                fi
            done
            if [[ "$already_added" == "false" ]]; then
                temp_dirs_to_clean+=("$clean_dir")
            fi
        fi
    done
    
    if [[ "${#temp_dirs_to_clean[@]}" -eq 0 ]]; then
        log_verbose "No suitable temp directories found for cleanup"
        return 0
    fi
    
    log_verbose "Checking ${#temp_dirs_to_clean[@]} temp directories for orphaned files"
    
    # Clean each temp directory
    for temp_dir in "${temp_dirs_to_clean[@]}"; do
        cleanup_orphaned_files "$temp_dir"
    done
    
    log_verbose "Startup orphaned file cleanup completed"
}

# Run startup cleanup during initialization (P1.T015)
# Only run if explicitly enabled to avoid startup delays
if [[ "$ENABLE_AGE_CLEANUP" == "true" ]]; then
    timeout 30 run_startup_cleanup 2>/dev/null || {
        log_verbose "Startup cleanup timed out or failed - continuing without cleanup"
    }
fi

# Enhanced environment detection functions (P1.T004)
detect_container_environment() {
    # Container/sandbox detection
    if [[ -f /.dockerenv ]] || [[ -f /proc/1/cgroup ]] && grep -q docker /proc/1/cgroup 2>/dev/null; then
        log_verbose "Docker container environment detected"
        return 0
    fi
    
    # Check for other container indicators
    if [[ -n "${container:-}" ]] || [[ -n "${CONTAINER:-}" ]]; then
        log_verbose "Container environment detected via environment variables"
        return 0
    fi
    
    # Check for common container/sandbox patterns
    if [[ "$(id -u 2>/dev/null || echo 0)" == "0" ]] && [[ ! -w "/" ]]; then
        log_verbose "Read-only root filesystem detected (likely containerized)"
        return 0
    fi
    
    return 1
}

detect_readonly_filesystem() {
    local test_dir="$1"
    
    if [[ ! -d "$test_dir" ]]; then
        return 1  # Directory doesn't exist, not our concern here
    fi
    
    # Test if filesystem is read-only
    local test_file="${test_dir}/.claude-write-test-$$"
    if ! touch "$test_file" 2>/dev/null; then
        log_verbose "Directory $test_dir appears to be on read-only filesystem"
        return 0
    fi
    
    # Clean up test file
    rm -f "$test_file" 2>/dev/null || true
    return 1
}

attempt_directory_creation() {
    local dir="$1"
    
    # Don't try to create system directories that should already exist
    if [[ "$dir" == "/tmp" ]] || [[ "$dir" == "/var/tmp" ]] || [[ "$dir" == "/private/var/tmp" ]]; then
        return 1
    fi
    
    # Don't try to create paths that look dangerous (avoid root filesystem modifications)
    if [[ "$dir" == "/" ]] || [[ "$dir" == "/usr"* ]] || [[ "$dir" == "/etc"* ]] || [[ "$dir" == "/bin"* ]] || [[ "$dir" == "/sbin"* ]]; then
        return 1
    fi
    
    # Allow creation for user-controlled paths and reasonable temp paths
    if [[ "$dir" == "${HOME}/"* ]] || [[ "$dir" == "."* ]] || [[ "$dir" == "/tmp/"* ]] || [[ "$dir" == "/var/tmp/"* ]]; then
        log_verbose "Attempting to create missing directory: $dir"
        if mkdir -p "$dir" 2>/dev/null; then
            log_verbose "Successfully created directory: $dir"
            return 0
        fi
        log_verbose "Failed to create directory: $dir"
    else
        log_verbose "Directory path not suitable for creation: $dir"
    fi
    
    return 1
}

test_temp_directory_suitability() {
    local dir="$1"
    local context="${2:-unknown}"
    
    # Basic existence check
    if [[ ! -d "$dir" ]]; then
        log_verbose "Directory does not exist: $dir (context: $context)"
        return 1
    fi
    
    # Permission checks
    if [[ ! -w "$dir" ]]; then
        if detect_readonly_filesystem "$dir"; then
            log_verbose "Directory $dir is on read-only filesystem (context: $context)"
            return 1
        fi
        log_verbose "Directory not writable: $dir (context: $context)"
        return 1
    fi
    
    if [[ ! -x "$dir" ]]; then
        log_verbose "Directory not executable: $dir (context: $context)"
        return 1
    fi
    
    # Test actual file creation
    local test_file="${dir}/.claude-temp-test-$$-$RANDOM"
    if ! touch "$test_file" 2>/dev/null; then
        log_verbose "Cannot create test file in directory: $dir (context: $context)"
        return 1
    fi
    
    # Clean up test file
    rm -f "$test_file" 2>/dev/null || true
    
    log_verbose "Directory is suitable: $dir (context: $context)"
    return 0
}

# Get temp directory with fallback hierarchy and enhanced edge case handling (P1.T001, P1.T004)
get_temp_dir() {
    local dir
    local is_container=false
    
    # Detect environment characteristics
    if detect_container_environment; then
        is_container=true
        log_verbose "Container/sandbox environment detected - using enhanced fallback strategies"
    fi
    
    # Test candidates in priority order
    # 1. Claude Auto-Tee specific override (P1.T003)
    if [[ -n "${CLAUDE_AUTO_TEE_TEMP_DIR:-}" ]]; then
        dir=$(normalize_path "${CLAUDE_AUTO_TEE_TEMP_DIR}")
        log_verbose "Testing CLAUDE_AUTO_TEE_TEMP_DIR override: $dir"
        
        # Try to create directory if it doesn't exist
        if [[ ! -d "$dir" ]]; then
            log_verbose "CLAUDE_AUTO_TEE_TEMP_DIR override does not exist: $dir"
            if attempt_directory_creation "$dir"; then
                log_verbose "Created CLAUDE_AUTO_TEE_TEMP_DIR override: $dir"
            else
                log_verbose "Failed to create CLAUDE_AUTO_TEE_TEMP_DIR override: $dir"
            fi
        fi
        
        if test_temp_directory_suitability "$dir" "CLAUDE_AUTO_TEE_TEMP_DIR override"; then
            log_verbose "Using CLAUDE_AUTO_TEE_TEMP_DIR override: $dir"
            echo "$dir"
            return 0
        fi
        log_verbose "CLAUDE_AUTO_TEE_TEMP_DIR override not suitable: $dir"
        # Continue with fallback chain instead of failing immediately
    fi
    
    # 2. Standard environment variables (cross-platform)
    if [[ -n "${TMPDIR:-}" ]]; then
        dir=$(normalize_path "${TMPDIR}")
        log_verbose "Testing TMPDIR: $dir"
        if test_temp_directory_suitability "$dir" "TMPDIR"; then
            log_verbose "Using TMPDIR: $dir"
            echo "$dir"
            return 0
        fi
        log_verbose "TMPDIR not suitable: $dir"
    fi
    
    if [[ -n "${TMP:-}" ]]; then
        dir=$(normalize_path "${TMP}")
        log_verbose "Testing TMP: $dir"
        if test_temp_directory_suitability "$dir" "TMP"; then
            log_verbose "Using TMP: $dir"
            echo "$dir"
            return 0
        fi
        log_verbose "TMP not suitable: $dir"
    fi
    
    if [[ -n "${TEMP:-}" ]]; then
        dir=$(normalize_path "${TEMP}")
        log_verbose "Testing TEMP: $dir"
        if test_temp_directory_suitability "$dir" "TEMP"; then
            log_verbose "Using TEMP: $dir"
            echo "$dir"
            return 0
        fi
        log_verbose "TEMP not suitable: $dir"
    fi
    
    # 3. Platform-specific defaults with enhanced edge case handling
    local platform
    platform="$(uname -s)"
    log_verbose "Platform detected: $platform"
    
    case "$platform" in
        Darwin*)
            log_verbose "Using macOS temp directory fallbacks"
            for dir in "/private/var/tmp" "/tmp"; do
                log_verbose "Testing platform fallback: $dir"
                if test_temp_directory_suitability "$dir" "macOS platform fallback"; then
                    log_verbose "Using platform fallback: $dir"
                    echo "$dir"
                    return 0
                fi
            done
            ;;
        Linux*)
            log_verbose "Using Linux temp directory fallbacks"
            # In containers, try additional locations
            local linux_candidates=("/var/tmp" "/tmp")
            if [[ "$is_container" == "true" ]]; then
                linux_candidates+=("/dev/shm" "/run/user/$(id -u 2>/dev/null || echo 0)")
                log_verbose "Container detected - expanded Linux temp directory candidates"
            fi
            
            for dir in "${linux_candidates[@]}"; do
                log_verbose "Testing platform fallback: $dir"
                if test_temp_directory_suitability "$dir" "Linux platform fallback"; then
                    log_verbose "Using platform fallback: $dir"
                    echo "$dir"
                    return 0
                fi
            done
            ;;
        CYGWIN*|MINGW*|MSYS*)
            log_verbose "Using Windows/Cygwin temp directory fallbacks"
            for dir in "/tmp" "/var/tmp"; do
                log_verbose "Testing platform fallback: $dir"
                if test_temp_directory_suitability "$dir" "Windows platform fallback"; then
                    log_verbose "Using platform fallback: $dir"
                    echo "$dir"
                    return 0
                fi
            done
            ;;
        *)
            log_verbose "Using generic Unix temp directory fallbacks"
            for dir in "/var/tmp" "/tmp"; do
                log_verbose "Testing platform fallback: $dir"
                if test_temp_directory_suitability "$dir" "generic platform fallback"; then
                    log_verbose "Using platform fallback: $dir"
                    echo "$dir"
                    return 0
                fi
            done
            ;;
    esac
    
    # 4. Last resort fallbacks with creation attempts
    log_verbose "Trying last resort fallbacks"
    
    # Enhanced fallback list for different environments
    local fallback_candidates=("${HOME}/.tmp" "${HOME}/tmp" ".")
    
    # In container environments, try additional locations
    if [[ "$is_container" == "true" ]]; then
        fallback_candidates+=("${HOME}/.cache/tmp" "/tmp/user-$(id -u 2>/dev/null || echo 0)")
        log_verbose "Container detected - expanded last resort candidates"
    fi
    
    for dir in "${fallback_candidates[@]}"; do
        log_verbose "Testing last resort: $dir"
        
        # Try to create directory if it doesn't exist
        if [[ ! -d "$dir" ]]; then
            if attempt_directory_creation "$dir"; then
                log_verbose "Created last resort directory: $dir"
            fi
        fi
        
        if test_temp_directory_suitability "$dir" "last resort fallback"; then
            log_verbose "Using last resort: $dir"
            echo "$dir"
            return 0
        fi
    done
    
    # Generate detailed error message with actionable guidance (P1.T004)
    log_verbose "No suitable temp directory found after exhaustive search"
    
    # Build environment-specific guidance
    local error_context="No writable temporary directory found after exhaustive search."
    local guidance="\n\nTroubleshooting steps:\n"
    guidance+="1. Check if you have write access to any temp directory:\n"
    guidance+="   ls -ld /tmp /var/tmp \${HOME}/tmp 2>/dev/null\n\n"
    
    if [[ "$is_container" == "true" ]]; then
        guidance+="2. Container environment detected. Try mounting a writable volume:\n"
        guidance+="   docker run -v /host/tmp:/tmp your-image\n"
        guidance+="   Or set CLAUDE_AUTO_TEE_TEMP_DIR to a writable path\n\n"
    fi
    
    guidance+="3. Create a user temp directory:\n"
    guidance+="   mkdir -p \${HOME}/tmp && export CLAUDE_AUTO_TEE_TEMP_DIR=\${HOME}/tmp\n\n"
    guidance+="4. Check filesystem mount status:\n"
    guidance+="   mount | grep -E '(tmp|ro)'\n\n"
    guidance+="5. For read-only root filesystems, ensure a writable volume is mounted\n"
    
    report_error $ERR_NO_TEMP_DIR "${error_context}${guidance}" false
    return $ERR_NO_TEMP_DIR
}

# Read Claude Code hook input with error handling
set_error_context "Reading hook input"
input=$(cat 2>/dev/null) || {
    report_error $ERR_INVALID_INPUT "Failed to read input from stdin" true
}

# Validate input is not empty
if [[ -z "$input" ]]; then
    report_error $ERR_INVALID_INPUT "Empty input received" true
fi

# Extract command from JSON (handle escaped quotes)
set_error_context "Parsing JSON input"
command_escaped=$(echo "$input" | sed -n 's/.*"command":"\([^"]*\(\\"[^"]*\)*\)".*/\1/p' | tr -d '\n')
if [[ -z "$command_escaped" ]]; then
    log_verbose "No command found in JSON, checking for malformed JSON"
    if ! echo "$input" | grep -q '"tool"'; then
        log_verbose "Input does not appear to be valid tool JSON - passing through unchanged"
        report_warning $ERR_MALFORMED_JSON "Malformed JSON input - graceful passthrough"
        echo "$input"
        exit 0
    fi
    # Not a bash command, pass through unchanged
    echo "$input"
    exit 0
fi

command=$(echo "$command_escaped" | sed 's/\\"/"/g')
if [[ -z "$command" ]]; then
    report_error $ERR_MISSING_COMMAND "Command field is empty" true
fi

clear_error_context

# Security validation and safe pipe detection
validate_command_security() {
    local cmd="$1"
    
    # 1. Syntax validation using bash parser
    if ! bash -n <<< "$cmd" 2>/dev/null; then
        log_verbose "Command failed syntax validation"
        return 1
    fi
    
    # 2. Security checks - reject dangerous patterns
    # Allow 2>&1 and 1>&2 redirections but block dangerous operators
    # First remove safe redirections, then check for dangerous patterns
    local safe_cmd
    safe_cmd=$(echo "$cmd" | sed 's/[12]>&[12]//g')
    if echo "$safe_cmd" | grep -qE '&|;|\$\(|\`|\\|&&|\|\|'; then
        log_verbose "Command contains potentially dangerous operators or expansions"
        return 1
    fi
    
    # 3. Length check
    if [[ "${#cmd}" -gt 500 ]]; then
        log_verbose "Command too long (>${#cmd} chars)"
        return 1
    fi
    
    # 4. Quote balance check
    local single_quotes double_quotes
    single_quotes=$(echo "$cmd" | grep -o "'" | wc -l)
    double_quotes=$(echo "$cmd" | grep -o '"' | wc -l)
    if [[ $((single_quotes % 2)) -ne 0 ]] || [[ $((double_quotes % 2)) -ne 0 ]]; then
        log_verbose "Unbalanced quotes detected"
        return 1
    fi
    
    return 0
}

# Safe pipe detection that respects quotes
detect_safe_pipes() {
    local cmd="$1"
    local in_single_quote=false
    local in_double_quote=false
    local escaped=false
    local pipe_positions=()
    local i=0
    
    while [[ $i -lt ${#cmd} ]]; do
        local char="${cmd:$i:1}"
        local next_char="${cmd:$((i+1)):1}"
        local prev_char="${cmd:$((i-1)):1}"
        
        if [[ "$escaped" == "true" ]]; then
            escaped=false
            ((i++))
            continue
        fi
        
        case "$char" in
            '\\')
                escaped=true
                ;;
            "'")
                if [[ "$in_double_quote" == "false" ]]; then
                    in_single_quote=$([[ "$in_single_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '"')
                if [[ "$in_single_quote" == "false" ]]; then
                    in_double_quote=$([[ "$in_double_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '|')
                if [[ "$in_single_quote" == "false" ]] && [[ "$in_double_quote" == "false" ]]; then
                    # Check for proper pipe with spaces
                    if [[ "$prev_char" == " " ]] && [[ "$next_char" == " " ]]; then
                        pipe_positions+=($i)
                    fi
                fi
                ;;
        esac
        
        ((i++))
    done
    
    echo "${#pipe_positions[@]}"
    return 0
}

# Get position of first safe pipe
detect_first_pipe_position() {
    local cmd="$1"
    local in_single_quote=false
    local in_double_quote=false
    local escaped=false
    local i=0
    
    while [[ $i -lt ${#cmd} ]]; do
        local char="${cmd:$i:1}"
        local next_char="${cmd:$((i+1)):1}"
        local prev_char="${cmd:$((i-1)):1}"
        
        if [[ "$escaped" == "true" ]]; then
            escaped=false
            ((i++))
            continue
        fi
        
        case "$char" in
            '\\')
                escaped=true
                ;;
            "'")
                if [[ "$in_double_quote" == "false" ]]; then
                    in_single_quote=$([[ "$in_single_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '"')
                if [[ "$in_single_quote" == "false" ]]; then
                    in_double_quote=$([[ "$in_double_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '|')
                if [[ "$in_single_quote" == "false" ]] && [[ "$in_double_quote" == "false" ]]; then
                    # Check for proper pipe with spaces
                    if [[ "$prev_char" == " " ]] && [[ "$next_char" == " " ]]; then
                        echo "$i"
                        return 0
                    fi
                fi
                ;;
        esac
        
        ((i++))
    done
    
    echo "-1"
    return 0
}

# Check if command contains pipe and doesn't already have tee
log_verbose "Validating command security: $command"
if ! validate_command_security "$command"; then
    log_verbose "Command failed security validation - passing through unchanged"
    echo "$input"
    exit 0
fi

pipe_count=$(detect_safe_pipes "$command")
if [[ "$pipe_count" -gt 0 ]]; then
    if echo "$command" | grep -q "tee "; then
        # Skip - already has tee
        log_verbose "Command already contains tee - passing through unchanged"
        echo "$input"
        exit 0
    fi
    
    # Additional check: only handle simple single-pipe commands for security
    if [[ "$pipe_count" -ne 1 ]]; then
        log_verbose "Multiple pipes detected ($pipe_count) - passing through unchanged for security"
        echo "$input"
        exit 0
    fi
    
    # Process - has single pipe but no tee
    log_verbose "Safe single pipe command detected: $command"
    
    # Get suitable temp directory with error context
    set_error_context "Detecting suitable temp directory"
    log_verbose "Detecting suitable temp directory..."
    temp_dir=$(get_temp_dir)
    temp_dir_status=$?
    if [[ $temp_dir_status -ne 0 ]]; then
        clear_error_context
        log_verbose "No suitable temp directory found - passing through unchanged"
        # Graceful degradation: pass through unchanged if no temp directory available
        report_warning $ERR_NO_TEMP_DIR "Falling back to pass-through mode"
        echo "$input"
        exit 0
    fi
    clear_error_context
    log_verbose "Selected temp directory: $temp_dir"
    
    # Inject PreToolUse marker early (before temp file creation) - P2.T001
    log_verbose "Injecting PreToolUse capture marker (before temp file creation)"
    inject_pretooluse_marker "$command" "$temp_dir" "$TEMP_FILE_PREFIX" || {
        log_verbose "Warning: Failed to inject PreToolUse marker - continuing without early marker"
    }
    
    # Check disk space before proceeding (P1.T017, P1.T019)
    set_error_context "Checking disk space for command execution"
    log_verbose "Checking disk space for command execution..."
    
    # Use enhanced space checking with meaningful error messages (P1.T019)
    space_check_result=""
    if ! check_space_with_detailed_errors "$temp_dir" "$command" "$VERBOSE_MODE"; then
        space_check_result=$?
        clear_error_context
        log_verbose "Space check failed with code $space_check_result - enabling graceful degradation"
        
        # Different handling based on space error severity
        case $space_check_result in
            21) # ERR_DISK_FULL - critical, must fallback
                report_warning $ERR_DISK_FULL "Critical disk space issue - falling back to pass-through mode"
                ;;
            22) # ERR_QUOTA_EXCEEDED - user issue, fallback recommended
                report_warning $ERR_QUOTA_EXCEEDED "Quota exceeded - falling back to pass-through mode"
                ;;
            20) # ERR_INSUFFICIENT_SPACE - warning, but can try to continue
                report_warning $ERR_INSUFFICIENT_SPACE "Limited disk space - falling back to pass-through mode"
                ;;
            *) # Other space-related issues
                report_warning $ERR_SPACE_CHECK_FAILED "Space check failed - falling back to pass-through mode"
                ;;
        esac
        
        echo "$input"
        exit 0
    fi
    log_verbose "Disk space check passed"
    clear_error_context
    
    # Validate and apply MAX_TEMP_FILE_SIZE limit (P1.T018)
    if [[ "$MAX_TEMP_FILE_SIZE" =~ ^[0-9]+$ ]]; then
        if [[ "$MAX_TEMP_FILE_SIZE" -gt 0 ]]; then
            log_verbose "Max temp file size limit: ${MAX_TEMP_FILE_SIZE} bytes ($(($MAX_TEMP_FILE_SIZE / 1024 / 1024))MB)"
            # Size limit will be enforced during command execution
        else
            log_verbose "Warning: MAX_TEMP_FILE_SIZE must be greater than 0, using default: $DEFAULT_MAX_TEMP_FILE_SIZE bytes"
            MAX_TEMP_FILE_SIZE="$DEFAULT_MAX_TEMP_FILE_SIZE"
        fi
    elif [[ -n "$MAX_TEMP_FILE_SIZE" ]]; then
        log_verbose "Warning: Invalid MAX_TEMP_FILE_SIZE value '$MAX_TEMP_FILE_SIZE', using default: $DEFAULT_MAX_TEMP_FILE_SIZE bytes"
        MAX_TEMP_FILE_SIZE="$DEFAULT_MAX_TEMP_FILE_SIZE"
    fi
    
    # Generate unique temp file and cleanup script (P1.T013, P1.T007)
    set_error_context "Creating temp file and cleanup script"
    
    # Use path utilities for robust cross-platform path handling
    if ! temp_file=$(create_safe_temp_path "$temp_dir" "$TEMP_FILE_PREFIX" ".log"); then
        log_verbose "Failed to create safe temp path, falling back to basic method"
        # Fallback: POSIX timestamp + hash
        timestamp=$(date +%s)
        unique_string="${timestamp}-$$-${RANDOM:-0}"
        if command -v md5sum >/dev/null 2>&1; then
            hash_suffix=$(echo "$unique_string" | md5sum | cut -c1-6)
        elif command -v md5 >/dev/null 2>&1; then
            hash_suffix=$(echo "$unique_string" | md5 | cut -c1-6)
        else
            hash_suffix="$$$(date +%S)"
        fi
        temp_file="${temp_dir}/${TEMP_FILE_PREFIX}-${timestamp}${hash_suffix}.log"
        temp_file=$(normalize_path "$temp_file")
    fi
    
    # Set global variables for interruption cleanup (P1.T014)
    CURRENT_TEMP_FILE="$temp_file"
    
    # Validate temp file path
    if [[ ! -w "$temp_dir" ]]; then
        report_warning $ERR_TEMP_DIR_NOT_WRITABLE "Temp directory not writable: $temp_dir"
        echo "$input"
        exit 0
    fi
    
    # Create cleanup script
    cleanup_script=$(create_cleanup_function "$temp_dir")
    CURRENT_CLEANUP_SCRIPT="$cleanup_script"
    if [[ -z "$cleanup_script" ]] || [[ ! -f "$cleanup_script" ]]; then
        report_warning $ERR_TEMP_FILE_CREATE_FAILED "Failed to create cleanup script, proceeding without cleanup"
        cleanup_script=""
    fi
    
    log_verbose "Generated temp file: $temp_file"
    log_verbose "Generated cleanup script: $cleanup_script"
    
    # Legacy marker injection for PostToolUse hook compatibility (P2.T001)
    # Note: PreToolUse marker was already injected earlier with predicted path
    log_verbose "Injecting additional capture start marker for PostToolUse hook (legacy compatibility)"
    inject_capture_start_marker "$temp_file" || {
        log_verbose "Warning: Failed to inject legacy capture start marker - continuing without additional markers"
    }
    
    # Monitor resource usage and provide warnings (P1.T022)
    monitor_resource_usage "$temp_dir"
    
    clear_error_context
    
    # Find first pipe and split command using quote-aware detection
    pipe_position=$(detect_first_pipe_position "$command")
    if [[ "$pipe_position" -eq -1 ]]; then
        log_verbose "No valid pipe found after security validation - passing through unchanged"
        echo "$input"
        exit 0
    fi
    
    # Extract parts around the pipe (pipe_position points to |, we want to exclude " | ")
    before_pipe="${command:0:$((pipe_position-1))}"  # Up to space before |
    after_pipe="${command:$((pipe_position+2))}"     # After | and space
    log_verbose "Split command - before pipe: $before_pipe"
    log_verbose "Split command - after pipe: $after_pipe"
    
    # Construct modified command with tee, size limits, and cleanup (P1.T013, P1.T018)
    # FIXED: tee should capture full output, size limiting only applies to downstream pipeline
    # Only add 2>&1 if not already present
    if echo "$before_pipe" | grep -q "2>&1"; then
        base_tee_command="$before_pipe | tee \"$temp_file\" | head -c $MAX_TEMP_FILE_SIZE"
        log_verbose "Command already has 2>&1, tee captures full output, size limit applied to pipeline: $base_tee_command"
    else
        base_tee_command="$before_pipe 2>&1 | tee \"$temp_file\" | head -c $MAX_TEMP_FILE_SIZE"
        log_verbose "Added 2>&1, tee captures full output, size limit applied to pipeline: $base_tee_command"
    fi
    
    # Add size warning when pipeline truncation occurs (temp file may still contain full output)
    modified_command="{ $base_tee_command; PIPELINE_SIZE=\$?; TEMP_SIZE=\$(wc -c < \"$temp_file\" 2>/dev/null || echo 0); if [[ \$TEMP_SIZE -gt $MAX_TEMP_FILE_SIZE ]]; then echo \"[CLAUDE-AUTO-TEE] INFO: Full output (\$TEMP_SIZE bytes) saved to temp file, pipeline limited to $((MAX_TEMP_FILE_SIZE / 1024 / 1024))MB\" >&2; fi; } | $after_pipe"
    log_verbose "Pipeline receives size-limited data, temp file contains full output: $modified_command"
    
    # Add cleanup on successful completion (P1.T013)
    # Use CLEANUP_ON_SUCCESS environment variable override (P1.T003)
    final_command="$modified_command"
    
    if [[ "$CLEANUP_ON_SUCCESS" == "true" ]] && [[ -n "$cleanup_script" ]] && [[ -f "$cleanup_script" ]]; then
        cleanup_command="source \"$cleanup_script\" && { $final_command; } && { echo \"Full output saved to: $temp_file\"; if [[ -f \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" ]]; then source \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" && inject_capture_end_marker \"$temp_file\" 2>/dev/null || true; fi; cleanup_temp_file \"$temp_file\"; rm -f \"$cleanup_script\" 2>/dev/null || true; } || { echo \"Command failed - temp file preserved: $temp_file\"; if [[ -f \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" ]]; then source \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" && inject_capture_end_marker \"$temp_file\" 2>/dev/null || true; fi; rm -f \"$cleanup_script\" 2>/dev/null || true; }"
        log_verbose "Added cleanup logic with end markers for successful completion (CLEANUP_ON_SUCCESS=$CLEANUP_ON_SUCCESS)"
    else
        # No cleanup or cleanup disabled - preserve temp file
        cleanup_command="{ $final_command; } && { echo \"Full output saved to: $temp_file\"; if [[ -f \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" ]]; then source \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" && inject_capture_end_marker \"$temp_file\" 2>/dev/null || true; fi; } || { echo \"Command failed - temp file preserved: $temp_file\"; if [[ -f \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" ]]; then source \"${SCRIPT_DIR}/markers/pretooluse-markers.sh\" && inject_capture_end_marker \"$temp_file\" 2>/dev/null || true; fi; }"
        if [[ "$CLEANUP_ON_SUCCESS" != "true" ]]; then
            log_verbose "Cleanup disabled via CLAUDE_AUTO_TEE_CLEANUP_ON_SUCCESS=$CLEANUP_ON_SUCCESS"
        else
            log_verbose "Running without cleanup script (cleanup script creation failed)"
        fi
        # Clean up the cleanup script itself if it exists
        if [[ -n "$cleanup_script" ]] && [[ -f "$cleanup_script" ]]; then
            rm -f "$cleanup_script" 2>/dev/null || true
        fi
    fi
    
    # Build new JSON - simpler approach using printf with proper escaping
    # Escape the command properly for JSON
    escaped_command=$(printf '%s' "$cleanup_command" | sed 's/\\/\\\\/g' | sed 's/"/\\"/g')
    
    # Use a more robust approach to reconstruct JSON
    # First extract the timeout value
    timeout_value=$(echo "$input" | sed -n 's/.*"timeout":\([^,}]*\).*/\1/p')
    if [ -z "$timeout_value" ]; then
        timeout_value="null"
    fi
    
    # Output properly formatted JSON
    printf '{"tool":{"name":"Bash","input":{"command":"%s"}},"timeout":%s}\n' \
        "$escaped_command" "$timeout_value"
    
else
    # Pass through unchanged
    echo "$input"
fi

# /Users/james/git/claude-auto-tee/src/disk-space-check.sh
#!/usr/bin/env bash
# Disk Space Checking Functions for Claude Auto-Tee
# P1.T017: Check available disk space before creating temp files

set -euo pipefail
IFS=$'\n\t'

# Minimum required space in bytes (default 100MB)
readonly DEFAULT_MIN_SPACE_BYTES=$((100 * 1024 * 1024))

# Check available disk space in a directory
# Args: directory_path [min_required_bytes]
# Returns: 0 if sufficient space, 1 if insufficient, 2 if unable to determine
check_disk_space() {
    local dir_path="${1:-}"
    local min_bytes="${2:-$DEFAULT_MIN_SPACE_BYTES}"
    
    if [[ -z "$dir_path" ]]; then
        echo "Error: Directory path required" >&2
        return 2
    fi
    
    if [[ ! -d "$dir_path" ]]; then
        echo "Error: Directory does not exist: $dir_path" >&2
        return 2
    fi
    
    local available_bytes
    
    # Try different methods to get disk space
    if command -v df >/dev/null 2>&1; then
        # Use df command (most portable)
        available_bytes=$(get_space_with_df "$dir_path")
    elif command -v stat >/dev/null 2>&1; then
        # Fallback to stat (less portable)
        available_bytes=$(get_space_with_stat "$dir_path")
    else
        echo "Error: No disk space checking tools available (df, stat)" >&2
        return 2
    fi
    
    if [[ -z "$available_bytes" ]] || [[ "$available_bytes" -eq 0 ]]; then
        echo "Error: Could not determine available disk space" >&2
        return 2
    fi
    
    # Compare available space with minimum requirement
    if [[ "$available_bytes" -ge "$min_bytes" ]]; then
        return 0  # Sufficient space
    else
        # Format sizes for error message
        local available_mb=$((available_bytes / 1024 / 1024))
        local required_mb=$((min_bytes / 1024 / 1024))
        echo "Error: Insufficient disk space. Available: ${available_mb}MB, Required: ${required_mb}MB" >&2
        return 1  # Insufficient space
    fi
}

# Get available space using df command
get_space_with_df() {
    local dir_path="$1"
    local df_output
    
    # Use df with POSIX output format for portability
    if df_output=$(df -P "$dir_path" 2>/dev/null); then
        # Extract available bytes from df output
        # df -P format: Filesystem 1K-blocks Used Available Use% Mounted-on
        local available_kb
        available_kb=$(echo "$df_output" | awk 'NR==2 {print $4}')
        
        if [[ -n "$available_kb" ]] && [[ "$available_kb" =~ ^[0-9]+$ ]]; then
            echo $((available_kb * 1024))  # Convert KB to bytes
        else
            echo ""
        fi
    else
        echo ""
    fi
}

# Get available space using stat command (fallback)
get_space_with_stat() {
    local dir_path="$1"
    
    # This is less portable and may not work on all systems
    if command -v stat >/dev/null 2>&1; then
        # Try different stat formats based on platform
        case "$(uname -s)" in
            Darwin*)
                # macOS stat format
                if stat -f '%a*%S' "$dir_path" 2>/dev/null | bc 2>/dev/null; then
                    return
                fi
                ;;
            Linux*)
                # Linux stat format
                if stat -f '%a*%S' "$dir_path" 2>/dev/null | bc 2>/dev/null; then
                    return
                fi
                ;;
        esac
    fi
    
    # If all methods fail
    echo ""
}

# Check if directory has enough space for estimated file size
# Args: directory_path estimated_size_bytes
check_space_for_file() {
    local dir_path="$1"
    local estimated_size="${2:-0}"
    
    # Add buffer (20% or minimum 50MB, whichever is larger)
    local buffer_size=$((estimated_size / 5))
    local min_buffer=$((50 * 1024 * 1024))  # 50MB
    
    if [[ $buffer_size -lt $min_buffer ]]; then
        buffer_size=$min_buffer
    fi
    
    local required_space=$((estimated_size + buffer_size))
    
    check_disk_space "$dir_path" "$required_space"
}

# Get human-readable disk space information
get_disk_space_info() {
    local dir_path="${1:-}"
    
    if [[ -z "$dir_path" ]] || [[ ! -d "$dir_path" ]]; then
        echo "Invalid directory path" >&2
        return 1
    fi
    
    if command -v df >/dev/null 2>&1; then
        local df_output
        if df_output=$(df -h "$dir_path" 2>/dev/null); then
            echo "Disk space for $dir_path:"
            echo "$df_output"
            return 0
        fi
    fi
    
    echo "Unable to retrieve disk space information for $dir_path" >&2
    return 1
}

# Estimate command output size based on command type
# This is a heuristic - actual output may vary significantly
estimate_command_output_size() {
    local command="$1"
    
    # Default conservative estimate: 10MB
    local default_size=$((10 * 1024 * 1024))
    
    # Analyze command patterns for size estimation
    case "$command" in
        *"find "*" -name "*|*"ls -la "*|*"ls -R "*)
            # Directory listings can be large
            echo $((50 * 1024 * 1024))  # 50MB
            ;;
        *"grep "*" -r "*|*"grep "*" --recursive "*)
            # Recursive grep can produce lots of output
            echo $((100 * 1024 * 1024))  # 100MB
            ;;
        *"cat "*|*"head "*|*"tail "*)
            # File operations - moderate size
            echo $((20 * 1024 * 1024))  # 20MB
            ;;
        *"npm "*" build"*|*"yarn "*" build"*|*"make "*|*"gcc "*|*"clang "*)
            # Build commands can be verbose
            echo $((200 * 1024 * 1024))  # 200MB
            ;;
        *"test"*|*"spec"*|*"jest"*|*"mocha"*)
            # Test commands with detailed output
            echo $((30 * 1024 * 1024))  # 30MB
            ;;
        *)
            # Default for unknown commands
            echo $default_size
            ;;
    esac
}

# Main function to check if temp directory has sufficient space
check_temp_space_for_command() {
    local temp_dir="$1"
    local command="$2"
    local verbose="${3:-false}"
    
    # Estimate required space
    local estimated_size
    estimated_size=$(estimate_command_output_size "$command")
    
    if [[ "$verbose" == "true" ]]; then
        local estimated_mb=$((estimated_size / 1024 / 1024))
        echo "Estimated command output size: ${estimated_mb}MB" >&2
        get_disk_space_info "$temp_dir" >&2
    fi
    
    # Check if directory has sufficient space
    if check_space_for_file "$temp_dir" "$estimated_size"; then
        if [[ "$verbose" == "true" ]]; then
            echo "Disk space check: PASSED" >&2
        fi
        return 0
    else
        if [[ "$verbose" == "true" ]]; then
            echo "Disk space check: FAILED" >&2
        fi
        return 1
    fi
}

# Generate meaningful error message for space issues (P1.T019)
generate_space_error_message() {
    local error_code="$1"
    local dir_path="$2"
    local required_mb="${3:-}"
    local command="${4:-}"
    
    local base_message=""
    local suggestions=()
    local available_info=""
    
    # Get current space information if possible
    if command -v df >/dev/null 2>&1 && [[ -d "$dir_path" ]]; then
        local df_output
        if df_output=$(df -h "$dir_path" 2>/dev/null); then
            local available_space
            available_space=$(echo "$df_output" | awk 'NR==2 {print $4}')
            available_info=" (${available_space} available)"
        fi
    fi
    
    # Generate specific message based on error code
    case "$error_code" in
        20) # ERR_INSUFFICIENT_SPACE
            base_message="Insufficient disk space in ${dir_path}${available_info}"
            if [[ -n "$required_mb" ]]; then
                base_message+=". Need at least ${required_mb}MB for safe operation"
            fi
            suggestions=(
                "Free up disk space: rm -f ${dir_path}/claude-*.log"
                "Use alternative temp directory: export TMPDIR=/path/with/more/space"
                "Clean system temp files: rm -rf \${TMPDIR:-/tmp}/*"
                "Check disk usage: df -h ${dir_path}"
            )
            ;;
        21) # ERR_DISK_FULL
            base_message="Disk is completely full at ${dir_path}${available_info}"
            suggestions=(
                "Immediately free critical space: rm -f ${dir_path}/claude-*.log"
                "Clean large temporary files: find ${dir_path} -name '*.tmp' -size +10M -delete"
                "Move to different filesystem: export TMPDIR=/mnt/other/filesystem"
                "Check what's using space: du -sh ${dir_path}/* | sort -hr"
            )
            ;;
        22) # ERR_QUOTA_EXCEEDED
            base_message="Disk quota exceeded for ${dir_path}${available_info}"
            suggestions=(
                "Clean your temporary files: rm -f ${dir_path}/claude-*.log"
                "Use system temp directory: export TMPDIR=/tmp"
                "Check quota usage: quota -u \$USER"
                "Contact system administrator for quota increase"
            )
            ;;
        23) # ERR_SPACE_CHECK_FAILED
            base_message="Unable to determine disk space for ${dir_path}"
            suggestions=(
                "Verify directory exists and is accessible: ls -la ${dir_path}"
                "Check filesystem health: fsck ${dir_path}"
                "Try alternative temp location: export TMPDIR=/tmp"
                "Check system tools availability: which df stat"
            )
            ;;
        *)
            base_message="Space-related error in ${dir_path}${available_info}"
            suggestions=(
                "Check available space: df -h ${dir_path}"
                "Clean temporary files: rm -f ${dir_path}/claude-*.log"
                "Use alternative temp directory: export TMPDIR=/alternative/path"
            )
            ;;
    esac
    
    # Add command-specific suggestions
    if [[ -n "$command" ]]; then
        case "$command" in
            *"build"*|*"compile"*|*"make"*)
                suggestions+=("For build commands, consider using: export CLAUDE_AUTO_TEE_MAX_SIZE=52428800")
                ;;
            *"find"*|*"grep -r"*)
                suggestions+=("For large searches, consider: command | head -1000")
                ;;
            *"npm "*|*"yarn "*)
                suggestions+=("Clear package manager cache: npm cache clean --force")
                ;;
        esac
    fi
    
    # Format the complete error message
    echo "$base_message"
    echo ""
    echo "💡 Suggested solutions (try in order):"
    local count=1
    for suggestion in "${suggestions[@]}"; do
        echo "   $count. $suggestion"
        ((count++))
    done
    
    # Add general tip
    echo ""
    echo "ℹ️  Tip: Use 'export CLAUDE_AUTO_TEE_VERBOSE=true' for detailed space checking info"
}

# Enhanced space error reporting function
report_space_error() {
    local error_code="$1"
    local dir_path="$2"
    local required_mb="${3:-}"
    local command="${4:-}"
    
    # Generate detailed error message
    local detailed_message
    detailed_message=$(generate_space_error_message "$error_code" "$dir_path" "$required_mb" "$command")
    
    echo "❌ Space Issue Detected:" >&2
    echo "$detailed_message" >&2
}

# Check if we have enough space and provide meaningful feedback
check_space_with_detailed_errors() {
    local dir_path="$1"
    local command="$2"
    local verbose="${3:-false}"
    
    # Estimate required space
    local estimated_size
    estimated_size=$(estimate_command_output_size "$command")
    local estimated_mb=$((estimated_size / 1024 / 1024))
    
    if [[ "$verbose" == "true" ]]; then
        echo "Estimated command output size: ${estimated_mb}MB" >&2
    fi
    
    # Check basic directory existence and permissions
    if [[ ! -d "$dir_path" ]]; then
        report_space_error 23 "$dir_path" "" "$command"
        return 23
    fi
    
    if [[ ! -w "$dir_path" ]]; then
        report_space_error 23 "$dir_path" "" "$command"
        return 23  
    fi
    
    # Check available space with detailed error reporting
    local available_bytes
    if available_bytes=$(get_space_with_df "$dir_path") && [[ -n "$available_bytes" ]] && [[ "$available_bytes" -gt 0 ]]; then
        local available_mb=$((available_bytes / 1024 / 1024))
        local required_space=$((estimated_size + 50 * 1024 * 1024))  # Add 50MB buffer
        local required_mb=$((required_space / 1024 / 1024))
        
        if [[ "$verbose" == "true" ]]; then
            echo "Available space: ${available_mb}MB, Required: ${required_mb}MB" >&2
        fi
        
        if [[ "$available_bytes" -lt "$required_space" ]]; then
            if [[ "$available_mb" -lt 10 ]]; then
                # Nearly full disk
                report_space_error 21 "$dir_path" "$required_mb" "$command"
                return 21
            else
                # Insufficient but not critical
                report_space_error 20 "$dir_path" "$required_mb" "$command"
                return 20
            fi
        fi
        
        # Space check passed
        if [[ "$verbose" == "true" ]]; then
            echo "✓ Sufficient space available (${available_mb}MB)" >&2
        fi
        return 0
    else
        # Unable to determine space
        report_space_error 23 "$dir_path" "$estimated_mb" "$command"
        return 23
    fi
}

# Example usage and testing
if [[ "${BASH_SOURCE[0]:-}" == "${0:-}" ]]; then
    # Test the functions if script is run directly
    echo "Testing disk space checking functions..."
    
    # Test current directory
    if check_disk_space "."; then
        echo "✓ Current directory has sufficient space"
    else
        echo "✗ Current directory lacks sufficient space"
    fi
    
    # Show disk space info
    echo ""
    get_disk_space_info "."
    
    # Test command estimation
    echo ""
    echo "Command size estimations:"
    echo "ls -la: $(estimate_command_output_size "ls -la") bytes"
    echo "npm run build: $(estimate_command_output_size "npm run build") bytes"
    echo "find . -name '*.js': $(estimate_command_output_size "find . -name '*.js'") bytes"
    
    # Test meaningful error message generation
    echo ""
    echo "Testing meaningful error messages:"
    echo "--- ERR_INSUFFICIENT_SPACE ---"
    generate_space_error_message 20 "/tmp" "100" "npm run build"
    echo ""
    echo "--- ERR_DISK_FULL ---"
    generate_space_error_message 21 "/tmp" "" "find . -name '*.js'"
fi

# /Users/james/git/claude-auto-tee/src/env/README.md
# Environment Exporter (P1.T004)

The Environment Exporter module provides the `EnvExporter:v1` interface for setting `CLAUDE_LAST_CAPTURE` and `CLAUDE_CAPTURES` environment variables in the PostToolUse hook implementation.

## Files

- **`environment-exporter.js`** - Main EnvExporter class implementation
- **`../test/env/environment-exporter.test.js`** - Comprehensive test suite (30 tests)
- **`../test/env/acceptance-test.sh`** - Acceptance test verifying `test -n "$CLAUDE_LAST_CAPTURE"` succeeds
- **`../test/env/demo.js`** - Interactive demonstration of all features

## Features Implemented

### ✅ Core Functionality
- **CLAUDE_LAST_CAPTURE**: Sets path to most recent capture file
- **CLAUDE_CAPTURES**: Sets JSON array of recent captures (limited to last 10 entries)
- **History Management**: Automatic cleanup and size limiting
- **Metadata Support**: Timestamps, file sizes, and custom metadata

### ✅ Shell Compatibility
- **Bash/Zsh/Sh**: Uses `export VAR="value"` syntax
- **Fish Shell**: Uses `set -gx VAR value` syntax
- **Auto-detection**: Supports shell type detection and validation

### ✅ Security & Safety
- **Path Escaping**: Proper quoting for special characters (`"`, `$`, `` ` ``, `!`, etc.)
- **JSON Escaping**: Safe encoding of JSON data for shell variables
- **Input Validation**: Comprehensive error handling and type checking
- **Shell Injection Prevention**: All paths and data properly escaped

### ✅ Atomic Operations
- **Race Condition Prevention**: Optional atomic updates to history
- **Data Consistency**: Immutable operations when atomicity is enabled
- **Thread Safety**: Safe for concurrent access patterns

### ✅ Edge Case Handling
- **Unicode Paths**: Full support for international characters
- **Special Characters**: Handles spaces, quotes, dollar signs, etc.
- **Long Paths**: No arbitrary length limits
- **Non-existent Files**: Graceful handling with test mode support

## Usage

```javascript
const { EnvExporter } = require('./src/env/environment-exporter.js');

// Create exporter instance
const exporter = new EnvExporter({
    maxCapturesHistory: 10,        // Keep last 10 captures
    enableAtomicOperations: true,  // Prevent race conditions
    verbose: false                 // Enable debug logging
});

// Add a capture
exporter.addCapture('/path/to/capture.log', {
    toolName: 'Bash',
    command: 'npm run build | tee /path/to/capture.log'
});

// Generate export commands
const exports = exporter.generateAllExports('bash');
console.log(exports.lastCapture);  // export CLAUDE_LAST_CAPTURE="/path/to/capture.log"
console.log(exports.captures);     // export CLAUDE_CAPTURES="[{...}]"

// Generate complete shell script
const script = exporter.generateExportScript('bash');
```

## Error Handling

The module defines custom error types for robust error handling:

- **`EnvironmentExportError`** - Base error class
- **`ShellCompatibilityError`** - Shell type validation errors
- **`PathEscapingError`** - Path processing errors

## Testing

Run the test suite:
```bash
npm run test:env              # Full test suite (30 tests)
npm run test:env-acceptance   # Acceptance test
npm run test:env-demo         # Interactive demo
```

## Shell Support Matrix

| Shell | Export Syntax | Unset Syntax | Status |
|-------|---------------|--------------|--------|
| bash  | `export VAR="value"` | `unset VAR` | ✅ Full |
| zsh   | `export VAR="value"` | `unset VAR` | ✅ Full |
| sh    | `export VAR="value"` | `unset VAR` | ✅ Full |
| fish  | `set -gx VAR 'value'` | `set -e VAR` | ✅ Full |

## Integration with PostToolUse Hook

The EnvExporter is designed to integrate seamlessly with the PostToolUse hook:

1. **Tool Completion**: When a Bash tool completes with tee output
2. **Capture Addition**: Add the capture file path to the exporter
3. **Export Generation**: Generate shell-appropriate export commands
4. **Environment Setting**: Execute exports to make variables available

The acceptance criteria `test -n "$CLAUDE_LAST_CAPTURE"` succeeds after proper integration.

# /Users/james/git/claude-auto-tee/src/env/env-exporter.sh
#!/bin/sh
# Claude Auto-Tee Environment Exporter
# 
# POSIX-compliant shell script that exports CLAUDE_CAPTURES and CLAUDE_LAST_CAPTURE
# environment variables based on the captures registry.
#
# Usage: . /path/to/env-exporter.sh
# 
# Interfaces produced: EnvExporter:v1 (shell version)
#
# Environment variables set:
# - CLAUDE_LAST_CAPTURE: Path to most recent capture file
# - CLAUDE_CAPTURES: JSON array of recent captures (last 10 entries)

# Configuration
CLAUDE_REGISTRY_FILE="${HOME}/.claude/captures.json"
CLAUDE_MAX_CAPTURES=10
CLAUDE_DEBUG="${CLAUDE_DEBUG:-0}"

# Logging function
claude_log() {
    if [ "$CLAUDE_DEBUG" = "1" ]; then
        printf "[env-exporter] %s: %s\n" "$(date '+%Y-%m-%d %H:%M:%S')" "$*" >&2
    fi
}

# Error handling function
claude_error() {
    printf "[env-exporter] ERROR: %s\n" "$*" >&2
    return 1
}

# Escape special shell characters in a path
# Input: path string
# Output: shell-safe quoted string
claude_escape_path() {
    if [ -z "$1" ]; then
        printf '""'
        return 0
    fi
    
    # Use printf to safely escape the path with double quotes
    # Escape backslashes, double quotes, backticks, dollar signs, and exclamation marks
    printf '"%s"' "$(printf '%s' "$1" | sed 's/\\/\\\\/g; s/"/\\"/g; s/`/\\`/g; s/\$/\\$/g; s/!/\\!/g')"
}

# Extract JSON string value safely without jq
# Input: json_string key_name
# Output: unescaped string value
claude_extract_json_string() {
    json_string="$1"
    key_name="$2"
    
    # Use sed to extract the value for the given key
    printf '%s' "$json_string" | sed -n 's/.*"'"$key_name"'"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p' | head -1
}

# Extract JSON array length without jq
# Input: json_string
# Output: array length (0 if empty or not an array)
claude_json_array_length() {
    json_string="$1"
    
    if [ -z "$json_string" ] || ! printf '%s' "$json_string" | grep -q '^\[.*\]$'; then
        printf '0'
        return
    fi
    
    # Count objects by counting opening braces (more reliable)
    count=$(printf '%s' "$json_string" | grep -o '{' | wc -l | tr -d ' ')
    printf '%d' "$count"
}

# Extract path from last JSON object in array
# Input: json_array
# Output: path string from last object
claude_extract_last_path() {
    json_array="$1"
    
    # Extract the last object by finding the last occurrence of path
    printf '%s' "$json_array" | sed -n 's/.*"path"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p' | tail -1
}

# Truncate JSON array to last N entries (simplified version)
# Input: json_string max_elements
# Output: truncated JSON array
claude_truncate_json_array() {
    json_string="$1"
    max_elements="$2"
    
    if [ -z "$json_string" ] || ! printf '%s' "$json_string" | grep -q '^\[.*\]$'; then
        printf '[]'
        return 0
    fi
    
    array_length=$(claude_json_array_length "$json_string")
    
    if [ "$array_length" -le "$max_elements" ]; then
        printf '%s' "$json_string"
        return 0
    fi
    
    # For now, if we have more than max_elements, just return the original array
    # This is a simplified implementation - could be enhanced later
    printf '%s' "$json_string"
}

# Escape JSON string for shell export
# Input: json_string
# Output: shell-safe escaped JSON
claude_escape_json_for_shell() {
    if [ -z "$1" ]; then
        printf '""'
        return 0
    fi
    
    # Escape the JSON string for shell use
    printf '"%s"' "$(printf '%s' "$1" | sed 's/\\/\\\\/g; s/"/\\"/g; s/`/\\`/g; s/\$/\\$/g; s/!/\\!/g')"
}

# Main export function
claude_export_environment() {
    claude_log "Starting environment export process"
    
    # Check if registry file exists
    if [ ! -f "$CLAUDE_REGISTRY_FILE" ]; then
        claude_log "Registry file does not exist: $CLAUDE_REGISTRY_FILE"
        # Unset variables if registry doesn't exist
        unset CLAUDE_LAST_CAPTURE
        unset CLAUDE_CAPTURES
        claude_log "Environment variables unset due to missing registry"
        return 0
    fi
    
    # Check if registry file is readable
    if [ ! -r "$CLAUDE_REGISTRY_FILE" ]; then
        claude_error "Registry file is not readable: $CLAUDE_REGISTRY_FILE"
        return 1
    fi
    
    # Read the registry file
    claude_log "Reading registry file: $CLAUDE_REGISTRY_FILE"
    registry_content=$(cat "$CLAUDE_REGISTRY_FILE" 2>/dev/null)
    
    if [ $? -ne 0 ]; then
        claude_error "Failed to read registry file: $CLAUDE_REGISTRY_FILE"
        return 1
    fi
    
    if [ -z "$registry_content" ]; then
        claude_log "Registry file is empty"
        unset CLAUDE_LAST_CAPTURE
        unset CLAUDE_CAPTURES
        return 0
    fi
    
    # Extract captures array from registry (handle multi-line JSON)
    # Remove newlines but preserve spaces within strings, then extract the array
    captures_array=$(printf '%s' "$registry_content" | tr -d '\n\r' | sed -n 's/.*"captures"[[:space:]]*:[[:space:]]*\(\[.*\]\).*/\1/p')
    
    if [ -z "$captures_array" ]; then
        claude_log "No captures array found in registry"
        unset CLAUDE_LAST_CAPTURE
        unset CLAUDE_CAPTURES
        return 0
    fi
    
    # Get array length
    array_length=$(claude_json_array_length "$captures_array")
    claude_log "Found $array_length captures in registry"
    
    if [ "$array_length" -eq 0 ]; then
        claude_log "Captures array is empty"
        unset CLAUDE_LAST_CAPTURE
        unset CLAUDE_CAPTURES
        return 0
    fi
    
    # Get the last capture path for CLAUDE_LAST_CAPTURE
    last_capture_path=$(claude_extract_last_path "$captures_array")
    
    if [ -n "$last_capture_path" ]; then
        export CLAUDE_LAST_CAPTURE="$last_capture_path"
        claude_log "Set CLAUDE_LAST_CAPTURE to: $last_capture_path"
    else
        claude_log "Could not extract path from last capture"
        unset CLAUDE_LAST_CAPTURE
    fi
    
    # Truncate captures array to last N entries for CLAUDE_CAPTURES
    truncated_captures=$(claude_truncate_json_array "$captures_array" "$CLAUDE_MAX_CAPTURES")
    
    if [ -n "$truncated_captures" ] && [ "$truncated_captures" != "[]" ]; then
        export CLAUDE_CAPTURES="$truncated_captures"
        claude_log "Set CLAUDE_CAPTURES with $(claude_json_array_length "$truncated_captures") entries"
    else
        claude_log "No valid captures to export"
        unset CLAUDE_CAPTURES
    fi
    
    claude_log "Environment export completed successfully"
    return 0
}

# Validation function to check if variables are set correctly
claude_validate_export() {
    if [ -n "$CLAUDE_LAST_CAPTURE" ]; then
        claude_log "✓ CLAUDE_LAST_CAPTURE is set: $CLAUDE_LAST_CAPTURE"
    else
        claude_log "✗ CLAUDE_LAST_CAPTURE is not set"
    fi
    
    if [ -n "$CLAUDE_CAPTURES" ]; then
        capture_count=$(claude_json_array_length "$CLAUDE_CAPTURES")
        claude_log "✓ CLAUDE_CAPTURES is set with $capture_count entries"
    else
        claude_log "✗ CLAUDE_CAPTURES is not set"
    fi
}

# Function to display current environment state (for debugging)
claude_show_environment() {
    printf "CLAUDE_LAST_CAPTURE=%s\n" "${CLAUDE_LAST_CAPTURE:-<unset>}"
    printf "CLAUDE_CAPTURES=%s\n" "${CLAUDE_CAPTURES:-<unset>}"
}

# Main execution - when sourced, this runs; when executed directly, it shows help
# Simple detection: if we can use 'return' successfully, we're sourced
if (return 0 2>/dev/null); then
    # Script is being sourced, perform the export
    claude_export_environment
    export_result=$?
    
    if [ "$CLAUDE_DEBUG" = "1" ]; then
        claude_validate_export
    fi
    
    return $export_result
else
    # Script is being executed directly, show usage
    cat << 'EOF'
Claude Auto-Tee Environment Exporter

This script exports CLAUDE_CAPTURES and CLAUDE_LAST_CAPTURE environment variables
based on the captures registry at ~/.claude/captures.json.

Usage:
  Source this script in your shell:
    . /path/to/env-exporter.sh

  Or with debug output:
    CLAUDE_DEBUG=1 . /path/to/env-exporter.sh

Environment Variables Set:
  CLAUDE_LAST_CAPTURE  - Path to the most recent capture file
  CLAUDE_CAPTURES      - JSON array of recent captures (last 10 entries)

Environment Variables Read:
  CLAUDE_DEBUG         - Set to 1 to enable debug logging
  HOME                 - Used to locate ~/.claude/captures.json

Exit Codes:
  0 - Success (variables exported or unset appropriately)
  1 - Error reading registry file or other failure

For acceptance testing:
  test -n "$CLAUDE_LAST_CAPTURE" && echo "SUCCESS" || echo "FAILURE"

EOF
fi

# /Users/james/git/claude-auto-tee/src/env/environment-exporter.js
#!/usr/bin/env node
/**
 * Environment Exporter for Claude Auto-Tee
 * 
 * Sets CLAUDE_LAST_CAPTURE and CLAUDE_CAPTURES environment variables
 * with proper shell escaping and compatibility across shell types.
 * 
 * Interfaces produced: EnvExporter:v1
 */

const fs = require('fs');
const path = require('path');

/**
 * Custom error types for environment export operations
 */
class EnvironmentExportError extends Error {
    constructor(message, operation = 'unknown') {
        super(message);
        this.name = 'EnvironmentExportError';
        this.operation = operation;
        this.timestamp = new Date().toISOString();
    }
}

class ShellCompatibilityError extends EnvironmentExportError {
    constructor(message, shell = 'unknown') {
        super(message, 'shell_compatibility');
        this.name = 'ShellCompatibilityError';
        this.shell = shell;
    }
}

class PathEscapingError extends EnvironmentExportError {
    constructor(message, path = '') {
        super(message, 'path_escaping');
        this.name = 'PathEscapingError';
        this.path = path;
    }
}

/**
 * Environment Exporter class that generates shell-compatible export commands
 * for CLAUDE_LAST_CAPTURE and CLAUDE_CAPTURES environment variables.
 */
class EnvExporter {
    constructor(options = {}) {
        this.maxCapturesHistory = options.maxCapturesHistory || 10;
        this.enableAtomicOperations = options.enableAtomicOperations !== false;
        this.verbose = options.verbose || false;
        
        // Track captures with metadata
        this.capturesHistory = [];
        
        // Supported shell types
        this.supportedShells = ['bash', 'zsh', 'fish', 'sh'];
        
        this.log('EnvExporter initialized', {
            maxCapturesHistory: this.maxCapturesHistory,
            enableAtomicOperations: this.enableAtomicOperations
        });
    }

    /**
     * Internal logging method
     */
    log(message, data = null) {
        if (this.verbose) {
            const timestamp = new Date().toISOString();
            const logData = data ? ` ${JSON.stringify(data)}` : '';
            console.error(`[EnvExporter] ${timestamp} ${message}${logData}`);
        }
    }

    /**
     * Validates if a shell type is supported
     */
    validateShellType(shell) {
        if (!shell || typeof shell !== 'string') {
            throw new ShellCompatibilityError('Shell type must be a non-empty string', shell);
        }
        
        const normalizedShell = shell.toLowerCase().trim();
        if (!this.supportedShells.includes(normalizedShell)) {
            throw new ShellCompatibilityError(
                `Unsupported shell type: ${shell}. Supported: ${this.supportedShells.join(', ')}`,
                shell
            );
        }
        
        return normalizedShell;
    }

    /**
     * Escapes a path for safe use in shell commands
     * Handles special characters and different shell quoting rules
     */
    escapePath(filePath, shell = 'bash') {
        if (!filePath || typeof filePath !== 'string') {
            throw new PathEscapingError('Path must be a non-empty string', filePath);
        }

        const normalizedShell = this.validateShellType(shell);

        try {
            // Normalize path to absolute path
            const absolutePath = path.resolve(filePath);
            
            switch (normalizedShell) {
                case 'fish':
                    // Fish shell uses single quotes and escapes single quotes differently
                    return `'${absolutePath.replace(/'/g, "\\'")}'`;
                
                case 'bash':
                case 'zsh':
                case 'sh':
                default:
                    // POSIX shells: use double quotes and escape special characters
                    return `"${absolutePath
                        .replace(/\\/g, '\\\\')    // Escape backslashes first
                        .replace(/"/g, '\\"')      // Escape double quotes
                        .replace(/`/g, '\\`')      // Escape backticks
                        .replace(/\$/g, '\\$')     // Escape dollar signs
                        .replace(/!/g, '\\!')      // Escape exclamation marks (bash history expansion)
                    }"`;
            }
        } catch (error) {
            throw new PathEscapingError(`Failed to escape path: ${error.message}`, filePath);
        }
    }

    /**
     * Escapes a JSON string for safe use in shell export commands
     */
    escapeJsonForShell(jsonString, shell = 'bash') {
        if (!jsonString || typeof jsonString !== 'string') {
            return '""';
        }

        const normalizedShell = this.validateShellType(shell);

        try {
            switch (normalizedShell) {
                case 'fish':
                    return `'${jsonString.replace(/'/g, "\\'")}'`;
                
                case 'bash':
                case 'zsh':
                case 'sh':
                default:
                    return `"${jsonString
                        .replace(/\\/g, '\\\\')
                        .replace(/"/g, '\\"')
                        .replace(/`/g, '\\`')
                        .replace(/\$/g, '\\$')
                        .replace(/!/g, '\\!')
                    }"`;
            }
        } catch (error) {
            throw new PathEscapingError(`Failed to escape JSON for shell: ${error.message}`, jsonString);
        }
    }

    /**
     * Adds a capture to the history with metadata
     */
    addCapture(filePath, metadata = {}) {
        if (!filePath) {
            throw new EnvironmentExportError('Capture file path is required', 'add_capture');
        }

        // Verify file exists if not in test mode
        if (!metadata.testMode && !fs.existsSync(filePath)) {
            throw new EnvironmentExportError(`Capture file does not exist: ${filePath}`, 'add_capture');
        }

        const captureEntry = {
            path: path.resolve(filePath),
            timestamp: new Date().toISOString(),
            size: metadata.testMode ? metadata.size || 0 : this.getFileSize(filePath),
            ...metadata
        };

        if (this.enableAtomicOperations) {
            // Atomic operation: create new array rather than modifying in place
            const newHistory = [...this.capturesHistory];
            newHistory.push(captureEntry);
            
            // Keep only the most recent entries
            if (newHistory.length > this.maxCapturesHistory) {
                newHistory.splice(0, newHistory.length - this.maxCapturesHistory);
            }
            
            this.capturesHistory = newHistory;
        } else {
            this.capturesHistory.push(captureEntry);
            
            // Keep only the most recent entries
            if (this.capturesHistory.length > this.maxCapturesHistory) {
                this.capturesHistory.shift();
            }
        }

        this.log('Added capture to history', {
            path: captureEntry.path,
            historyLength: this.capturesHistory.length
        });

        return captureEntry;
    }

    /**
     * Gets file size safely
     */
    getFileSize(filePath) {
        try {
            return fs.statSync(filePath).size;
        } catch (error) {
            this.log('Failed to get file size', { path: filePath, error: error.message });
            return 0;
        }
    }

    /**
     * Gets the most recent capture path
     */
    getLastCapture() {
        if (this.capturesHistory.length === 0) {
            return null;
        }
        return this.capturesHistory[this.capturesHistory.length - 1];
    }

    /**
     * Gets the captures history array
     */
    getCaptures() {
        return [...this.capturesHistory]; // Return copy to prevent external modification
    }

    /**
     * Generates export command for CLAUDE_LAST_CAPTURE
     */
    generateLastCaptureExport(shell = 'bash') {
        const normalizedShell = this.validateShellType(shell);
        const lastCapture = this.getLastCapture();

        if (!lastCapture) {
            return this.generateUnsetCommand('CLAUDE_LAST_CAPTURE', normalizedShell);
        }

        const escapedPath = this.escapePath(lastCapture.path, normalizedShell);
        
        switch (normalizedShell) {
            case 'fish':
                return `set -gx CLAUDE_LAST_CAPTURE ${escapedPath}`;
            
            case 'bash':
            case 'zsh':
            case 'sh':
            default:
                return `export CLAUDE_LAST_CAPTURE=${escapedPath}`;
        }
    }

    /**
     * Generates export command for CLAUDE_CAPTURES
     */
    generateCapturesExport(shell = 'bash') {
        const normalizedShell = this.validateShellType(shell);
        
        if (this.capturesHistory.length === 0) {
            return this.generateUnsetCommand('CLAUDE_CAPTURES', normalizedShell);
        }

        // Create simplified array for environment variable (just paths and timestamps)
        const capturesArray = this.capturesHistory.map(capture => ({
            path: capture.path,
            timestamp: capture.timestamp,
            size: capture.size
        }));

        const jsonString = JSON.stringify(capturesArray);
        const escapedJson = this.escapeJsonForShell(jsonString, normalizedShell);

        switch (normalizedShell) {
            case 'fish':
                return `set -gx CLAUDE_CAPTURES ${escapedJson}`;
            
            case 'bash':
            case 'zsh':
            case 'sh':
            default:
                return `export CLAUDE_CAPTURES=${escapedJson}`;
        }
    }

    /**
     * Generates unset command for environment variables
     */
    generateUnsetCommand(varName, shell = 'bash') {
        const normalizedShell = this.validateShellType(shell);
        
        switch (normalizedShell) {
            case 'fish':
                return `set -e ${varName}`;
            
            case 'bash':
            case 'zsh':
            case 'sh':
            default:
                return `unset ${varName}`;
        }
    }

    /**
     * Generates both export commands for a shell
     */
    generateAllExports(shell = 'bash') {
        const normalizedShell = this.validateShellType(shell);
        
        return {
            lastCapture: this.generateLastCaptureExport(normalizedShell),
            captures: this.generateCapturesExport(normalizedShell),
            shell: normalizedShell
        };
    }

    /**
     * Generates a complete shell script to export both variables
     */
    generateExportScript(shell = 'bash') {
        const exports = this.generateAllExports(shell);
        
        const header = `#!/usr/bin/env ${exports.shell}`;
        const comment = `# Claude Auto-Tee Environment Variables Export`;
        const timestamp = `# Generated: ${new Date().toISOString()}`;
        
        return [
            header,
            comment,
            timestamp,
            '',
            exports.lastCapture,
            exports.captures,
            ''
        ].join('\n');
    }

    /**
     * Clears the captures history
     */
    clearHistory() {
        this.capturesHistory = [];
        this.log('Cleared captures history');
    }

    /**
     * Updates an existing capture entry (atomic operation)
     */
    updateCapture(filePath, updates = {}) {
        if (!filePath) {
            throw new EnvironmentExportError('File path is required for update', 'update_capture');
        }

        const absolutePath = path.resolve(filePath);
        
        if (this.enableAtomicOperations) {
            // Atomic operation: create new array with updated entry
            const newHistory = this.capturesHistory.map(capture => {
                if (capture.path === absolutePath) {
                    return {
                        ...capture,
                        ...updates,
                        updatedAt: new Date().toISOString()
                    };
                }
                return capture;
            });
            
            this.capturesHistory = newHistory;
        } else {
            // Non-atomic update
            const captureIndex = this.capturesHistory.findIndex(capture => capture.path === absolutePath);
            if (captureIndex >= 0) {
                this.capturesHistory[captureIndex] = {
                    ...this.capturesHistory[captureIndex],
                    ...updates,
                    updatedAt: new Date().toISOString()
                };
            }
        }

        this.log('Updated capture', { path: absolutePath, updates });
    }

    /**
     * Removes a capture from history (atomic operation)
     */
    removeCapture(filePath) {
        if (!filePath) {
            throw new EnvironmentExportError('File path is required for removal', 'remove_capture');
        }

        const absolutePath = path.resolve(filePath);
        const originalLength = this.capturesHistory.length;
        
        if (this.enableAtomicOperations) {
            // Atomic operation: create new array without the entry
            this.capturesHistory = this.capturesHistory.filter(capture => capture.path !== absolutePath);
        } else {
            // Non-atomic removal
            const captureIndex = this.capturesHistory.findIndex(capture => capture.path === absolutePath);
            if (captureIndex >= 0) {
                this.capturesHistory.splice(captureIndex, 1);
            }
        }

        const removed = this.capturesHistory.length < originalLength;
        this.log('Remove capture result', { path: absolutePath, removed });
        
        return removed;
    }
}

// Export the class and error types
module.exports = {
    EnvExporter,
    EnvironmentExportError,
    ShellCompatibilityError,
    PathEscapingError
};

# /Users/james/git/claude-auto-tee/src/error-codes.sh
#!/usr/bin/env bash
# Claude Auto-Tee Error Code System
# Comprehensive error classification and reporting

# Error Code Categories (Exit Codes 1-99)
# 1-9:   Input/Configuration Errors
# 10-19: Temp Directory/File System Errors  
# 20-29: Resource/Space Errors
# 30-39: Command Execution Errors
# 40-49: Output Processing Errors
# 50-59: Cleanup/Lifecycle Errors
# 60-69: Platform/Compatibility Errors
# 70-79: Permission/Security Errors
# 80-89: Network/External Service Errors
# 90-99: Internal/Unexpected Errors

# Input/Configuration Errors (1-9)
readonly ERR_INVALID_INPUT=1
readonly ERR_MALFORMED_JSON=2
readonly ERR_MISSING_COMMAND=3
readonly ERR_INVALID_CONFIG=4
readonly ERR_UNSUPPORTED_MODE=5

# Temp Directory/File System Errors (10-19)
readonly ERR_NO_TEMP_DIR=10
readonly ERR_TEMP_DIR_NOT_WRITABLE=11
readonly ERR_TEMP_FILE_CREATE_FAILED=12
readonly ERR_TEMP_FILE_WRITE_FAILED=13
readonly ERR_TEMP_FILE_READ_FAILED=14
readonly ERR_TEMP_DIR_NOT_FOUND=15
readonly ERR_READONLY_FILESYSTEM=16
readonly ERR_CONTAINER_RESTRICTIONS=17
readonly ERR_DIRECTORY_CREATE_FAILED=18

# Resource/Space Errors (20-29)
readonly ERR_INSUFFICIENT_SPACE=20
readonly ERR_DISK_FULL=21
readonly ERR_QUOTA_EXCEEDED=22
readonly ERR_SPACE_CHECK_FAILED=23
readonly ERR_RESOURCE_EXHAUSTED=24

# Command Execution Errors (30-39)
readonly ERR_COMMAND_NOT_FOUND=30
readonly ERR_COMMAND_TIMEOUT=31
readonly ERR_COMMAND_KILLED=32
readonly ERR_COMMAND_INVALID=33
readonly ERR_PIPE_BROKEN=34
readonly ERR_EXECUTION_FAILED=35

# Output Processing Errors (40-49)  
readonly ERR_OUTPUT_TOO_LARGE=40
readonly ERR_OUTPUT_BINARY=41
readonly ERR_OUTPUT_CORRUPT=42
readonly ERR_ENCODING_ERROR=43
readonly ERR_TEE_FAILED=44

# Cleanup/Lifecycle Errors (50-59)
readonly ERR_CLEANUP_FAILED=50
readonly ERR_TEMP_FILE_ORPHANED=51
readonly ERR_SIGNAL_HANDLER_FAILED=52
readonly ERR_LIFECYCLE_VIOLATION=53

# Platform/Compatibility Errors (60-69)
readonly ERR_PLATFORM_UNSUPPORTED=60
readonly ERR_SHELL_INCOMPATIBLE=61
readonly ERR_FEATURE_UNAVAILABLE=62
readonly ERR_VERSION_MISMATCH=63

# Permission/Security Errors (70-79)
readonly ERR_PERMISSION_DENIED=70
readonly ERR_ACCESS_FORBIDDEN=71
readonly ERR_SECURITY_VIOLATION=72
readonly ERR_PRIVILEGE_REQUIRED=73

# Network/External Service Errors (80-89)
readonly ERR_NETWORK_UNAVAILABLE=80
readonly ERR_SERVICE_TIMEOUT=81
readonly ERR_EXTERNAL_FAILURE=82

# Internal/Unexpected Errors (90-99)
readonly ERR_INTERNAL_ERROR=90
readonly ERR_ASSERTION_FAILED=91
readonly ERR_CORRUPTED_STATE=92
readonly ERR_UNEXPECTED_CONDITION=99

# Error Message Mappings
# Use different approach for older bash compatibility
if declare -A test_array 2>/dev/null; then
    declare -A ERROR_MESSAGES=(
    # Input/Configuration Errors
    [$ERR_INVALID_INPUT]="Invalid input provided"
    [$ERR_MALFORMED_JSON]="Malformed JSON input"
    [$ERR_MISSING_COMMAND]="No command specified in input"
    [$ERR_INVALID_CONFIG]="Invalid configuration parameters"
    [$ERR_UNSUPPORTED_MODE]="Unsupported operation mode"
    
    # Temp Directory/File System Errors
    [$ERR_NO_TEMP_DIR]="No suitable temp directory found"
    [$ERR_TEMP_DIR_NOT_WRITABLE]="Temp directory is not writable"
    [$ERR_TEMP_FILE_CREATE_FAILED]="Failed to create temp file"
    [$ERR_TEMP_FILE_WRITE_FAILED]="Failed to write to temp file"
    [$ERR_TEMP_FILE_READ_FAILED]="Failed to read from temp file"
    [$ERR_TEMP_DIR_NOT_FOUND]="Specified temp directory not found"
    [$ERR_READONLY_FILESYSTEM]="Read-only filesystem detected"
    [$ERR_CONTAINER_RESTRICTIONS]="Container environment restrictions detected"
    [$ERR_DIRECTORY_CREATE_FAILED]="Failed to create temp directory"
    
    # Resource/Space Errors
    [$ERR_INSUFFICIENT_SPACE]="Insufficient disk space for temp file"
    [$ERR_DISK_FULL]="Disk full during operation"
    [$ERR_QUOTA_EXCEEDED]="Disk quota exceeded"
    [$ERR_SPACE_CHECK_FAILED]="Unable to check available disk space"
    [$ERR_RESOURCE_EXHAUSTED]="System resources exhausted"
    
    # Command Execution Errors
    [$ERR_COMMAND_NOT_FOUND]="Command not found"
    [$ERR_COMMAND_TIMEOUT]="Command execution timed out"
    [$ERR_COMMAND_KILLED]="Command was terminated"
    [$ERR_COMMAND_INVALID]="Invalid command syntax"
    [$ERR_PIPE_BROKEN]="Broken pipe in command chain"
    [$ERR_EXECUTION_FAILED]="Command execution failed"
    
    # Output Processing Errors
    [$ERR_OUTPUT_TOO_LARGE]="Command output exceeds size limits"
    [$ERR_OUTPUT_BINARY]="Binary output not supported"
    [$ERR_OUTPUT_CORRUPT]="Output data appears corrupted"
    [$ERR_ENCODING_ERROR]="Character encoding error"
    [$ERR_TEE_FAILED]="Failed to tee command output"
    
    # Cleanup/Lifecycle Errors
    [$ERR_CLEANUP_FAILED]="Temp file cleanup failed"
    [$ERR_TEMP_FILE_ORPHANED]="Temp file became orphaned"
    [$ERR_SIGNAL_HANDLER_FAILED]="Signal handler setup failed"
    [$ERR_LIFECYCLE_VIOLATION]="Lifecycle state violation"
    
    # Platform/Compatibility Errors
    [$ERR_PLATFORM_UNSUPPORTED]="Platform not supported"
    [$ERR_SHELL_INCOMPATIBLE]="Shell incompatible"
    [$ERR_FEATURE_UNAVAILABLE]="Required feature unavailable"
    [$ERR_VERSION_MISMATCH]="Version compatibility mismatch"
    
    # Permission/Security Errors
    [$ERR_PERMISSION_DENIED]="Permission denied"
    [$ERR_ACCESS_FORBIDDEN]="Access forbidden"
    [$ERR_SECURITY_VIOLATION]="Security policy violation"
    [$ERR_PRIVILEGE_REQUIRED]="Elevated privileges required"
    
    # Network/External Service Errors
    [$ERR_NETWORK_UNAVAILABLE]="Network unavailable"
    [$ERR_SERVICE_TIMEOUT]="External service timeout"
    [$ERR_EXTERNAL_FAILURE]="External service failure"
    
    # Internal/Unexpected Errors
    [$ERR_INTERNAL_ERROR]="Internal error occurred"
    [$ERR_ASSERTION_FAILED]="Internal assertion failed"
    [$ERR_CORRUPTED_STATE]="Internal state corrupted"
    [$ERR_UNEXPECTED_CONDITION]="Unexpected condition encountered"
)
else
    # Fallback for older bash versions - use functions
    get_error_message_fallback() {
        case "$1" in
            $ERR_INVALID_INPUT) echo "Invalid input provided" ;;
            $ERR_MALFORMED_JSON) echo "Malformed JSON input" ;;
            $ERR_MISSING_COMMAND) echo "No command specified in input" ;;
            $ERR_INVALID_CONFIG) echo "Invalid configuration parameters" ;;
            $ERR_UNSUPPORTED_MODE) echo "Unsupported operation mode" ;;
            $ERR_NO_TEMP_DIR) echo "No suitable temp directory found" ;;
            $ERR_TEMP_DIR_NOT_WRITABLE) echo "Temp directory is not writable" ;;
            $ERR_TEMP_FILE_CREATE_FAILED) echo "Failed to create temp file" ;;
            $ERR_TEMP_FILE_WRITE_FAILED) echo "Failed to write to temp file" ;;
            $ERR_TEMP_FILE_READ_FAILED) echo "Failed to read from temp file" ;;
            $ERR_TEMP_DIR_NOT_FOUND) echo "Specified temp directory not found" ;;
            $ERR_READONLY_FILESYSTEM) echo "Read-only filesystem detected" ;;
            $ERR_CONTAINER_RESTRICTIONS) echo "Container environment restrictions detected" ;;
            $ERR_DIRECTORY_CREATE_FAILED) echo "Failed to create temp directory" ;;
            $ERR_INSUFFICIENT_SPACE) echo "Insufficient disk space for temp file" ;;
            $ERR_DISK_FULL) echo "Disk full during operation" ;;
            $ERR_QUOTA_EXCEEDED) echo "Disk quota exceeded" ;;
            $ERR_SPACE_CHECK_FAILED) echo "Unable to check available disk space" ;;
            $ERR_RESOURCE_EXHAUSTED) echo "System resources exhausted" ;;
            $ERR_COMMAND_NOT_FOUND) echo "Command not found" ;;
            $ERR_COMMAND_TIMEOUT) echo "Command execution timed out" ;;
            $ERR_COMMAND_KILLED) echo "Command was terminated" ;;
            $ERR_COMMAND_INVALID) echo "Invalid command syntax" ;;
            $ERR_PIPE_BROKEN) echo "Broken pipe in command chain" ;;
            $ERR_EXECUTION_FAILED) echo "Command execution failed" ;;
            $ERR_OUTPUT_TOO_LARGE) echo "Command output exceeds size limits" ;;
            $ERR_OUTPUT_BINARY) echo "Binary output not supported" ;;
            $ERR_OUTPUT_CORRUPT) echo "Output data appears corrupted" ;;
            $ERR_ENCODING_ERROR) echo "Character encoding error" ;;
            $ERR_TEE_FAILED) echo "Failed to tee command output" ;;
            $ERR_CLEANUP_FAILED) echo "Temp file cleanup failed" ;;
            $ERR_TEMP_FILE_ORPHANED) echo "Temp file became orphaned" ;;
            $ERR_SIGNAL_HANDLER_FAILED) echo "Signal handler setup failed" ;;
            $ERR_LIFECYCLE_VIOLATION) echo "Lifecycle state violation" ;;
            $ERR_PLATFORM_UNSUPPORTED) echo "Platform not supported" ;;
            $ERR_SHELL_INCOMPATIBLE) echo "Shell incompatible" ;;
            $ERR_FEATURE_UNAVAILABLE) echo "Required feature unavailable" ;;
            $ERR_VERSION_MISMATCH) echo "Version compatibility mismatch" ;;
            $ERR_PERMISSION_DENIED) echo "Permission denied" ;;
            $ERR_ACCESS_FORBIDDEN) echo "Access forbidden" ;;
            $ERR_SECURITY_VIOLATION) echo "Security policy violation" ;;
            $ERR_PRIVILEGE_REQUIRED) echo "Elevated privileges required" ;;
            $ERR_NETWORK_UNAVAILABLE) echo "Network unavailable" ;;
            $ERR_SERVICE_TIMEOUT) echo "External service timeout" ;;
            $ERR_EXTERNAL_FAILURE) echo "External service failure" ;;
            $ERR_INTERNAL_ERROR) echo "Internal error occurred" ;;
            $ERR_ASSERTION_FAILED) echo "Internal assertion failed" ;;
            $ERR_CORRUPTED_STATE) echo "Internal state corrupted" ;;
            $ERR_UNEXPECTED_CONDITION) echo "Unexpected condition encountered" ;;
            *) echo "Unknown error code: $1" ;;
        esac
    }
fi

# Error Categories for Classification
if declare -A test_array2 2>/dev/null; then
    declare -A ERROR_CATEGORIES=(
    [$ERR_INVALID_INPUT]="input"
    [$ERR_MALFORMED_JSON]="input"
    [$ERR_MISSING_COMMAND]="input"
    [$ERR_INVALID_CONFIG]="input"
    [$ERR_UNSUPPORTED_MODE]="input"
    
    [$ERR_NO_TEMP_DIR]="filesystem"
    [$ERR_TEMP_DIR_NOT_WRITABLE]="filesystem"
    [$ERR_TEMP_FILE_CREATE_FAILED]="filesystem"
    [$ERR_TEMP_FILE_WRITE_FAILED]="filesystem"
    [$ERR_TEMP_FILE_READ_FAILED]="filesystem"
    [$ERR_TEMP_DIR_NOT_FOUND]="filesystem"
    
    [$ERR_INSUFFICIENT_SPACE]="resource"
    [$ERR_DISK_FULL]="resource"
    [$ERR_QUOTA_EXCEEDED]="resource"
    [$ERR_SPACE_CHECK_FAILED]="resource"
    [$ERR_RESOURCE_EXHAUSTED]="resource"
    
    [$ERR_COMMAND_NOT_FOUND]="execution"
    [$ERR_COMMAND_TIMEOUT]="execution"
    [$ERR_COMMAND_KILLED]="execution"
    [$ERR_COMMAND_INVALID]="execution"
    [$ERR_PIPE_BROKEN]="execution"
    [$ERR_EXECUTION_FAILED]="execution"
    
    [$ERR_OUTPUT_TOO_LARGE]="output"
    [$ERR_OUTPUT_BINARY]="output"
    [$ERR_OUTPUT_CORRUPT]="output"
    [$ERR_ENCODING_ERROR]="output"
    [$ERR_TEE_FAILED]="output"
    
    [$ERR_CLEANUP_FAILED]="lifecycle"
    [$ERR_TEMP_FILE_ORPHANED]="lifecycle"
    [$ERR_SIGNAL_HANDLER_FAILED]="lifecycle"
    [$ERR_LIFECYCLE_VIOLATION]="lifecycle"
    
    [$ERR_PLATFORM_UNSUPPORTED]="platform"
    [$ERR_SHELL_INCOMPATIBLE]="platform"
    [$ERR_FEATURE_UNAVAILABLE]="platform"
    [$ERR_VERSION_MISMATCH]="platform"
    
    [$ERR_PERMISSION_DENIED]="permission"
    [$ERR_ACCESS_FORBIDDEN]="permission"
    [$ERR_SECURITY_VIOLATION]="permission"
    [$ERR_PRIVILEGE_REQUIRED]="permission"
    
    [$ERR_NETWORK_UNAVAILABLE]="network"
    [$ERR_SERVICE_TIMEOUT]="network"
    [$ERR_EXTERNAL_FAILURE]="network"
    
    [$ERR_INTERNAL_ERROR]="internal"
    [$ERR_ASSERTION_FAILED]="internal"
    [$ERR_CORRUPTED_STATE]="internal"
    [$ERR_UNEXPECTED_CONDITION]="internal"
)
else
    # Fallback for older bash versions
    get_error_category_fallback() {
        case "$1" in
            $ERR_INVALID_INPUT|$ERR_MALFORMED_JSON|$ERR_MISSING_COMMAND|$ERR_INVALID_CONFIG|$ERR_UNSUPPORTED_MODE) echo "input" ;;
            $ERR_NO_TEMP_DIR|$ERR_TEMP_DIR_NOT_WRITABLE|$ERR_TEMP_FILE_CREATE_FAILED|$ERR_TEMP_FILE_WRITE_FAILED|$ERR_TEMP_FILE_READ_FAILED|$ERR_TEMP_DIR_NOT_FOUND) echo "filesystem" ;;
            $ERR_INSUFFICIENT_SPACE|$ERR_DISK_FULL|$ERR_QUOTA_EXCEEDED|$ERR_SPACE_CHECK_FAILED|$ERR_RESOURCE_EXHAUSTED) echo "resource" ;;
            $ERR_COMMAND_NOT_FOUND|$ERR_COMMAND_TIMEOUT|$ERR_COMMAND_KILLED|$ERR_COMMAND_INVALID|$ERR_PIPE_BROKEN|$ERR_EXECUTION_FAILED) echo "execution" ;;
            $ERR_OUTPUT_TOO_LARGE|$ERR_OUTPUT_BINARY|$ERR_OUTPUT_CORRUPT|$ERR_ENCODING_ERROR|$ERR_TEE_FAILED) echo "output" ;;
            $ERR_CLEANUP_FAILED|$ERR_TEMP_FILE_ORPHANED|$ERR_SIGNAL_HANDLER_FAILED|$ERR_LIFECYCLE_VIOLATION) echo "lifecycle" ;;
            $ERR_PLATFORM_UNSUPPORTED|$ERR_SHELL_INCOMPATIBLE|$ERR_FEATURE_UNAVAILABLE|$ERR_VERSION_MISMATCH) echo "platform" ;;
            $ERR_PERMISSION_DENIED|$ERR_ACCESS_FORBIDDEN|$ERR_SECURITY_VIOLATION|$ERR_PRIVILEGE_REQUIRED) echo "permission" ;;
            $ERR_NETWORK_UNAVAILABLE|$ERR_SERVICE_TIMEOUT|$ERR_EXTERNAL_FAILURE) echo "network" ;;
            $ERR_INTERNAL_ERROR|$ERR_ASSERTION_FAILED|$ERR_CORRUPTED_STATE|$ERR_UNEXPECTED_CONDITION) echo "internal" ;;
            *) echo "unknown" ;;
        esac
    }
fi

# Severity Levels
if declare -A test_array3 2>/dev/null; then
    declare -A ERROR_SEVERITY=(
    # Input errors - usually user fixable
    [$ERR_INVALID_INPUT]="error"
    [$ERR_MALFORMED_JSON]="error"
    [$ERR_MISSING_COMMAND]="error"
    [$ERR_INVALID_CONFIG]="error"
    [$ERR_UNSUPPORTED_MODE]="error"
    
    # Filesystem errors - system/environment issues
    [$ERR_NO_TEMP_DIR]="fatal"
    [$ERR_TEMP_DIR_NOT_WRITABLE]="fatal"
    [$ERR_TEMP_FILE_CREATE_FAILED]="error"
    [$ERR_TEMP_FILE_WRITE_FAILED]="error"
    [$ERR_TEMP_FILE_READ_FAILED]="error"
    [$ERR_TEMP_DIR_NOT_FOUND]="error"
    
    # Resource errors - system capacity issues
    [$ERR_INSUFFICIENT_SPACE]="warning"
    [$ERR_DISK_FULL]="error"
    [$ERR_QUOTA_EXCEEDED]="error"
    [$ERR_SPACE_CHECK_FAILED]="warning"
    [$ERR_RESOURCE_EXHAUSTED]="fatal"
    
    # Execution errors - command-related
    [$ERR_COMMAND_NOT_FOUND]="error"
    [$ERR_COMMAND_TIMEOUT]="warning"
    [$ERR_COMMAND_KILLED]="warning"
    [$ERR_COMMAND_INVALID]="error"
    [$ERR_PIPE_BROKEN]="error"
    [$ERR_EXECUTION_FAILED]="error"
    
    # Output processing - data handling issues
    [$ERR_OUTPUT_TOO_LARGE]="warning"
    [$ERR_OUTPUT_BINARY]="info"
    [$ERR_OUTPUT_CORRUPT]="error"
    [$ERR_ENCODING_ERROR]="warning"
    [$ERR_TEE_FAILED]="error"
    
    # Lifecycle - cleanup and management
    [$ERR_CLEANUP_FAILED]="warning"
    [$ERR_TEMP_FILE_ORPHANED]="info"
    [$ERR_SIGNAL_HANDLER_FAILED]="warning"
    [$ERR_LIFECYCLE_VIOLATION]="error"
    
    # Platform compatibility
    [$ERR_PLATFORM_UNSUPPORTED]="fatal"
    [$ERR_SHELL_INCOMPATIBLE]="error"
    [$ERR_FEATURE_UNAVAILABLE]="warning"
    [$ERR_VERSION_MISMATCH]="warning"
    
    # Security and permissions
    [$ERR_PERMISSION_DENIED]="error"
    [$ERR_ACCESS_FORBIDDEN]="error"
    [$ERR_SECURITY_VIOLATION]="fatal"
    [$ERR_PRIVILEGE_REQUIRED]="error"
    
    # Network and external
    [$ERR_NETWORK_UNAVAILABLE]="warning"
    [$ERR_SERVICE_TIMEOUT]="warning"
    [$ERR_EXTERNAL_FAILURE]="error"
    
    # Internal errors - bugs or corruption
    [$ERR_INTERNAL_ERROR]="fatal"
    [$ERR_ASSERTION_FAILED]="fatal"
    [$ERR_CORRUPTED_STATE]="fatal"
    [$ERR_UNEXPECTED_CONDITION]="fatal"
    )
else
    # Fallback for older bash versions
    get_error_severity_fallback() {
        case "$1" in
            $ERR_INVALID_INPUT|$ERR_MALFORMED_JSON|$ERR_MISSING_COMMAND|$ERR_INVALID_CONFIG|$ERR_UNSUPPORTED_MODE) echo "error" ;;
            $ERR_NO_TEMP_DIR|$ERR_TEMP_DIR_NOT_WRITABLE|$ERR_RESOURCE_EXHAUSTED|$ERR_PLATFORM_UNSUPPORTED|$ERR_SECURITY_VIOLATION|$ERR_INTERNAL_ERROR|$ERR_ASSERTION_FAILED|$ERR_CORRUPTED_STATE|$ERR_UNEXPECTED_CONDITION) echo "fatal" ;;
            $ERR_TEMP_FILE_CREATE_FAILED|$ERR_TEMP_FILE_WRITE_FAILED|$ERR_TEMP_FILE_READ_FAILED|$ERR_TEMP_DIR_NOT_FOUND|$ERR_DISK_FULL|$ERR_QUOTA_EXCEEDED|$ERR_COMMAND_NOT_FOUND|$ERR_COMMAND_INVALID|$ERR_PIPE_BROKEN|$ERR_EXECUTION_FAILED|$ERR_OUTPUT_CORRUPT|$ERR_TEE_FAILED|$ERR_LIFECYCLE_VIOLATION|$ERR_SHELL_INCOMPATIBLE|$ERR_PERMISSION_DENIED|$ERR_ACCESS_FORBIDDEN|$ERR_PRIVILEGE_REQUIRED|$ERR_EXTERNAL_FAILURE) echo "error" ;;
            $ERR_INSUFFICIENT_SPACE|$ERR_SPACE_CHECK_FAILED|$ERR_COMMAND_TIMEOUT|$ERR_COMMAND_KILLED|$ERR_OUTPUT_TOO_LARGE|$ERR_ENCODING_ERROR|$ERR_CLEANUP_FAILED|$ERR_SIGNAL_HANDLER_FAILED|$ERR_FEATURE_UNAVAILABLE|$ERR_VERSION_MISMATCH|$ERR_NETWORK_UNAVAILABLE|$ERR_SERVICE_TIMEOUT) echo "warning" ;;
            $ERR_OUTPUT_BINARY|$ERR_TEMP_FILE_ORPHANED) echo "info" ;;
            *) echo "unknown" ;;
        esac
    }
fi

# Error Reporting Functions

# Basic error reporting
report_error() {
    local error_code="$1"
    local context="${2:-}"
    local exit_after="${3:-true}"
    
    local message
    local category 
    local severity
    if declare -A test_array 2>/dev/null; then
        message="${ERROR_MESSAGES[$error_code]:-Unknown error}"
        category="${ERROR_CATEGORIES[$error_code]:-unknown}"
        severity="${ERROR_SEVERITY[$error_code]:-error}"
    else
        message=$(get_error_message_fallback "$error_code")
        category=$(get_error_category_fallback "$error_code")
        severity=$(get_error_severity_fallback "$error_code")
    fi
    
    # Format error message
    local formatted_message="[ERROR $error_code] $message"
    if [ -n "$context" ]; then
        formatted_message="$formatted_message: $context"
    fi
    
    echo "$formatted_message" >&2
    
    # Verbose mode additional information
    if is_verbose_mode 2>/dev/null; then
        echo "[VERBOSE] Error category: $category" >&2
        echo "[VERBOSE] Error severity: $severity" >&2
    fi
    
    # Exit if requested
    if [ "$exit_after" = "true" ]; then
        exit "$error_code"
    fi
    
    return "$error_code"
}

# Structured error reporting (JSON format)
report_error_json() {
    local error_code="$1"
    local context="${2:-}"
    local exit_after="${3:-true}"
    
    local message
    local category
    local severity
    if declare -A test_array 2>/dev/null; then
        message="${ERROR_MESSAGES[$error_code]:-Unknown error}"
        category="${ERROR_CATEGORIES[$error_code]:-unknown}"
        severity="${ERROR_SEVERITY[$error_code]:-error}"
    else
        message=$(get_error_message_fallback "$error_code")
        category=$(get_error_category_fallback "$error_code")
        severity=$(get_error_severity_fallback "$error_code")
    fi
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    
    # Create JSON error object
    cat >&2 <<EOF
{
  "error": {
    "code": $error_code,
    "message": "$message",
    "context": "$context",
    "category": "$category",
    "severity": "$severity",
    "timestamp": "$timestamp",
    "tool": "claude-auto-tee"
  }
}
EOF
    
    if [ "$exit_after" = "true" ]; then
        exit "$error_code"
    fi
    
    return "$error_code"
}

# Warning reporting (non-fatal)
report_warning() {
    local error_code="$1"
    local context="${2:-}"
    
    local message
    local category
    if declare -A test_array 2>/dev/null; then
        message="${ERROR_MESSAGES[$error_code]:-Unknown warning}"
        category="${ERROR_CATEGORIES[$error_code]:-unknown}"
    else
        message=$(get_error_message_fallback "$error_code")
        category=$(get_error_category_fallback "$error_code")
    fi
    
    echo "[WARNING $error_code] $message${context:+: $context}" >&2
    
    if is_verbose_mode 2>/dev/null; then
        echo "[VERBOSE] Warning category: $category" >&2
    fi
    
    return 0
}

# Assertion function for internal error checking
assert() {
    local condition="$1"
    local message="${2:-Assertion failed}"
    
    # Basic validation to prevent code injection in assertions
    if echo "$condition" | grep -qE '(;|\\||&|\\$\\(|`)'; then
        report_error $ERR_ASSERTION_FAILED "Unsafe assertion condition rejected: $message"
        return
    fi
    
    if ! eval "$condition"; then
        report_error $ERR_ASSERTION_FAILED "$message ($condition)"
    fi
}

# Error context management  
ERROR_CONTEXT=""

set_error_context() {
    ERROR_CONTEXT="$1"
}

clear_error_context() {
    ERROR_CONTEXT=""
}

# Context-aware error reporting
report_error_with_context() {
    local error_code="$1"
    local additional_context="${2:-}"
    local exit_after="${3:-true}"
    
    local full_context="$ERROR_CONTEXT"
    if [ -n "$additional_context" ]; then
        if [ -n "$full_context" ]; then
            full_context="$full_context: $additional_context"
        else
            full_context="$additional_context"
        fi
    fi
    
    report_error "$error_code" "$full_context" "$exit_after"
}

# Error code validation
is_valid_error_code() {
    local code="$1"
    if declare -A test_array 2>/dev/null; then
        [ -n "${ERROR_MESSAGES[$code]:-}" ]
    else
        [ "$(get_error_message_fallback "$code")" != "Unknown error code: $code" ]
    fi
}

# Get error information
get_error_message() {
    local code="$1"
    if declare -A test_array 2>/dev/null; then
        echo "${ERROR_MESSAGES[$code]:-Unknown error code: $code}"
    else
        get_error_message_fallback "$code"
    fi
}

get_error_category() {
    local code="$1"
    if declare -A test_array 2>/dev/null; then
        echo "${ERROR_CATEGORIES[$code]:-unknown}"
    else
        get_error_category_fallback "$code"
    fi
}

get_error_severity() {
    local code="$1"
    if declare -A test_array 2>/dev/null; then
        echo "${ERROR_SEVERITY[$code]:-unknown}"
    else
        get_error_severity_fallback "$code"
    fi
}

# List all error codes (utility function)
list_error_codes() {
    local category_filter="${1:-}"
    
    echo "Claude Auto-Tee Error Codes:"
    echo "============================"
    
    for code in $(printf '%s\n' "${!ERROR_MESSAGES[@]}" | sort -n); do
        local message="${ERROR_MESSAGES[$code]}"
        local category="${ERROR_CATEGORIES[$code]}"
        local severity="${ERROR_SEVERITY[$code]}"
        
        # Filter by category if specified
        if [ -n "$category_filter" ] && [ "$category" != "$category_filter" ]; then
            continue
        fi
        
        printf "%3d: %-50s [%s/%s]\n" "$code" "$message" "$category" "$severity"
    done
}

# Export error code constants for use in main script
export ERR_INVALID_INPUT ERR_MALFORMED_JSON ERR_MISSING_COMMAND ERR_INVALID_CONFIG ERR_UNSUPPORTED_MODE
export ERR_NO_TEMP_DIR ERR_TEMP_DIR_NOT_WRITABLE ERR_TEMP_FILE_CREATE_FAILED ERR_TEMP_FILE_WRITE_FAILED
export ERR_TEMP_FILE_READ_FAILED ERR_TEMP_DIR_NOT_FOUND
export ERR_INSUFFICIENT_SPACE ERR_DISK_FULL ERR_QUOTA_EXCEEDED ERR_SPACE_CHECK_FAILED ERR_RESOURCE_EXHAUSTED
export ERR_COMMAND_NOT_FOUND ERR_COMMAND_TIMEOUT ERR_COMMAND_KILLED ERR_COMMAND_INVALID ERR_PIPE_BROKEN
export ERR_EXECUTION_FAILED ERR_OUTPUT_TOO_LARGE ERR_OUTPUT_BINARY ERR_OUTPUT_CORRUPT ERR_ENCODING_ERROR
export ERR_TEE_FAILED ERR_CLEANUP_FAILED ERR_TEMP_FILE_ORPHANED ERR_SIGNAL_HANDLER_FAILED
export ERR_LIFECYCLE_VIOLATION ERR_PLATFORM_UNSUPPORTED ERR_SHELL_INCOMPATIBLE ERR_FEATURE_UNAVAILABLE
export ERR_VERSION_MISMATCH ERR_PERMISSION_DENIED ERR_ACCESS_FORBIDDEN ERR_SECURITY_VIOLATION
export ERR_PRIVILEGE_REQUIRED ERR_NETWORK_UNAVAILABLE ERR_SERVICE_TIMEOUT ERR_EXTERNAL_FAILURE
export ERR_INTERNAL_ERROR ERR_ASSERTION_FAILED ERR_CORRUPTED_STATE ERR_UNEXPECTED_CONDITION

# /Users/james/git/claude-auto-tee/src/graceful-degradation.sh
#!/usr/bin/env bash
# Claude Auto-Tee Graceful Degradation Implementation
# Provides fail-safe fallback mechanisms for common failure scenarios

# Source error codes if not already loaded
if [ -z "$ERR_NO_TEMP_DIR" ]; then
    source "$(dirname "${BASH_SOURCE[0]}")/error-codes.sh"
fi

# Degradation configuration constants
readonly MIN_SPACE_BYTES=$((1024 * 1024))                   # 1MB minimum space requirement
readonly MAX_COMMAND_LENGTH=10000                           # Maximum safe command length
readonly TEMP_FILE_PREFIX=".claude-test-"                  # Prefix for temp test files

# Degradation configuration
CLAUDE_DEGRADATION_MODE=${CLAUDE_DEGRADATION_MODE:-auto}    # auto|strict|permissive
CLAUDE_RETRY_ATTEMPTS=${CLAUDE_RETRY_ATTEMPTS:-3}           # number of retry attempts
CLAUDE_RETRY_DELAY=${CLAUDE_RETRY_DELAY:-1}                # initial retry delay seconds
CLAUDE_FAIL_FAST=${CLAUDE_FAIL_FAST:-false}                # override fail-safe behavior
CLAUDE_METRICS_LOG=${CLAUDE_METRICS_LOG:-}                 # optional metrics logging

# Global state
ORIGINAL_INPUT=""
DEGRADATION_ACTIVE="false"

# Utility functions for compatibility
verbose_log() {
    if is_verbose_mode 2>/dev/null; then
        echo "[VERBOSE] $1" >&2
    fi
}

is_verbose_mode() {
    [ "${CLAUDE_AUTO_TEE_VERBOSE:-0}" = "1" ]
}

# Mock functions for testing - these would be implemented elsewhere
detect_temp_directory() {
    local temp_candidates=("/tmp" "$HOME/tmp" "$HOME" ".")
    for dir in "${temp_candidates[@]}"; do
        if [ -d "$dir" ] && [ -w "$dir" ]; then
            echo "$dir"
            return 0
        fi
    done
    return 1
}

get_available_space() {
    local dir="$1"
    if command -v df >/dev/null 2>&1; then
        df -k "$dir" 2>/dev/null | tail -1 | awk '{print $4 * 1024}'
    else
        echo "1000000"  # 1MB fallback
    fi
}

# Error context management functions
set_error_context() {
    ERROR_CONTEXT="$1"
}

clear_error_context() {
    ERROR_CONTEXT=""
}

# Initialize degradation system
initialize_degradation() {
    local original_input="$1"
    ORIGINAL_INPUT="$original_input"
    DEGRADATION_ACTIVE="false"
    
    # Configure behavior based on mode
    configure_degradation_behavior
    
    # Set up signal handlers for graceful exit
    trap 'handle_failure_gracefully $ERR_UNEXPECTED_CONDITION "Script interrupted" "$ORIGINAL_INPUT"' INT TERM
}

# Configure degradation behavior based on mode
configure_degradation_behavior() {
    case "$CLAUDE_DEGRADATION_MODE" in
        "strict")
            # Fail fast on any error - for debugging
            CLAUDE_FAIL_FAST=true
            CLAUDE_RETRY_ATTEMPTS=0
            verbose_log "Degradation mode: strict (fail-fast enabled)"
            ;;
        "permissive")  
            # Maximum tolerance - almost always pass through
            CLAUDE_RETRY_ATTEMPTS=5
            CLAUDE_RETRY_DELAY=0.5
            verbose_log "Degradation mode: permissive (maximum tolerance)"
            ;;
        "auto"|*)
            # Default balanced approach
            verbose_log "Degradation mode: auto (balanced fail-safe)"
            ;;
    esac
}

# Main degradation decision point
handle_failure_gracefully() {
    local error_code="$1"
    local context="$2"
    local original_input="${3:-$ORIGINAL_INPUT}"
    
    # Override with fail-fast if configured
    if [ "$CLAUDE_FAIL_FAST" = "true" ]; then
        report_error "$error_code" "$context" true
        return $error_code
    fi
    
    # Get error category for decision making
    local category=$(get_error_category "$error_code")
    
    case "$category" in
        "input"|"internal")
            # Fail-fast scenarios - user can fix these
            report_error "$error_code" "$context" true
            ;;
        "filesystem"|"resource"|"platform"|"permission")
            # Fail-safe scenarios - pass through with warning
            initiate_passthrough_mode "$error_code" "$context" "$original_input"
            ;;
        "execution"|"output")
            # Fail-safe with recovery attempt
            attempt_recovery "$error_code" "$context" "$original_input"
            ;;
        *)
            # Unknown category - be conservative, pass through
            report_warning $ERR_UNEXPECTED_CONDITION "Unknown error category: $category"
            initiate_passthrough_mode $ERR_UNEXPECTED_CONDITION "Unknown error category" "$original_input"
            ;;
    esac
}

# Pass-through mode activation
initiate_passthrough_mode() {
    local error_code="$1"
    local context="$2"  
    local original_input="$3"
    local test_mode="${4:-false}"
    
    DEGRADATION_ACTIVE="true"
    
    # Log degradation event
    log_degradation_event "$error_code" "passthrough"
    
    # Show user-friendly message
    show_degradation_message "$error_code" ""
    
    # Show detailed information in verbose mode
    show_degradation_details "$error_code"
    
    # Pass through original input unchanged
    echo "$original_input"
    
    # Exit unless in test mode
    if [ "$test_mode" != "true" ]; then
        exit 0
    fi
}

# Recovery attempt for execution/output errors
attempt_recovery() {
    local error_code="$1"
    local context="$2"
    local original_input="$3"
    
    local recovery_attempted=false
    
    # Log recovery attempt
    log_degradation_event "$error_code" "recovery_attempt"
    
    case "$error_code" in
        $ERR_TEMP_FILE_CREATE_FAILED)
            if attempt_alternative_temp_location; then
                verbose_log "Recovery successful: alternative temp location found"
                return 0
            fi
            recovery_attempted=true
            ;;
        $ERR_INSUFFICIENT_SPACE)
            if attempt_minimal_space_mode; then
                verbose_log "Recovery successful: minimal space mode activated"
                return 0
            fi
            recovery_attempted=true
            ;;
        $ERR_TEE_FAILED|$ERR_PIPE_BROKEN)
            if attempt_simple_execution; then
                verbose_log "Recovery successful: simple execution without tee"
                return 0
            fi
            recovery_attempted=true
            ;;
    esac
    
    # Recovery failed, fall back to pass-through
    if [ "$recovery_attempted" = "true" ]; then
        report_warning "$error_code" "Recovery failed, falling back to pass-through mode"
        log_degradation_event "$error_code" "recovery_failed"
    fi
    
    initiate_passthrough_mode "$error_code" "$context" "$original_input"
}

# Recovery mechanism: try alternative temp locations
attempt_alternative_temp_location() {
    verbose_log "Attempting alternative temp directory locations"
    
    local alt_locations=(
        "$HOME/tmp"
        "$HOME/.tmp" 
        "$HOME/.cache"
        "$HOME"
        "."
    )
    
    for alt_dir in "${alt_locations[@]}"; do
        # Skip if directory doesn't exist
        [ -d "$alt_dir" ] || continue
        
        # Test write access with atomic temp file creation to avoid race conditions
        local test_file
        if test_file=$(mktemp "$alt_dir/${TEMP_FILE_PREFIX}XXXXXX" 2>/dev/null); then
            rm -f "$test_file" 2>/dev/null
            verbose_log "Alternative temp location found: $alt_dir"
            export CLAUDE_TEMP_DIR_OVERRIDE="$alt_dir"
            return 0
        fi
    done
    
    verbose_log "No alternative temp locations available"
    return 1
}

# Recovery mechanism: minimal space mode
attempt_minimal_space_mode() {
    verbose_log "Attempting minimal space mode"
    
    # Set very conservative space requirements
    export CLAUDE_MIN_TEMP_SPACE=$MIN_SPACE_BYTES  # Use configured minimum
    export CLAUDE_SPACE_CHECK=warn                 # Warn but proceed
    
    # Try with reduced requirements
    local temp_dir="${CLAUDE_TEMP_DIR_OVERRIDE:-$(detect_temp_directory 2>/dev/null)}"
    if [ -n "$temp_dir" ]; then
        local available=$(get_available_space "$temp_dir" 2>/dev/null || echo 0)
        if [ "$available" -gt $MIN_SPACE_BYTES ]; then
            verbose_log "Minimal space mode activated with ${available} bytes available"
            return 0
        fi
    fi
    
    verbose_log "Insufficient space even for minimal mode"
    return 1
}

# Recovery mechanism: simple execution without tee
attempt_simple_execution() {
    verbose_log "Attempting simple execution without tee enhancement"
    
    # Extract original command with proper JSON parsing
    local original_command
    if command -v jq >/dev/null 2>&1; then
        original_command=$(echo "$ORIGINAL_INPUT" | jq -r '.tool.input.command // empty' 2>/dev/null)
    else
        # Fallback regex with validation
        original_command=$(echo "$ORIGINAL_INPUT" | sed -n 's/.*"command":"\([^"]*\(\\"[^"]*\)*\)".*/\1/p' | sed 's/\\"/"/g')
    fi
    
    # Validate extracted command is reasonable (basic security check)
    if [ -n "$original_command" ] && [ ${#original_command} -lt $MAX_COMMAND_LENGTH ]; then
        # Additional security: validate command doesn't contain dangerous patterns
        if echo "$original_command" | grep -qE '(;|\||&|\$\(|`).*\b(rm|dd|mkfs|format)\b'; then
            verbose_log "Command contains potentially dangerous patterns, refusing simple execution"
            return 1
        fi
        
        verbose_log "Executing original command without tee: $original_command"
        
        # Execute the original command with bash -c for better security than eval
        bash -c "$original_command"
        local exit_code=$?
        
        # Show success message
        if [ $exit_code -eq 0 ]; then
            echo "Command completed successfully (claude-auto-tee functionality disabled)" >&2
        else
            echo "Command completed with exit code $exit_code (claude-auto-tee functionality disabled)" >&2
        fi
        
        exit $exit_code
    fi
    
    verbose_log "Could not extract or validate original command for simple execution"
    return 1
}

# Smart retry with exponential backoff
smart_retry() {
    local operation="$1"
    local max_attempts="${CLAUDE_RETRY_ATTEMPTS:-3}"
    local initial_delay="${CLAUDE_RETRY_DELAY:-1}"
    
    local attempt=1
    # Ensure delay is an integer for arithmetic operations
    local delay
    delay=$(echo "$initial_delay" | cut -d. -f1)
    [ "$delay" -lt 1 ] && delay=1
    
    while [ $attempt -le $max_attempts ]; do
        verbose_log "Retry attempt $attempt of $max_attempts: $operation"
        
        if eval "$operation"; then
            verbose_log "Retry successful on attempt $attempt"
            return 0
        fi
        
        if [ $attempt -lt $max_attempts ]; then
            verbose_log "Attempt $attempt failed, waiting ${delay}s before retry"
            sleep $delay
            # Use arithmetic expansion for better compatibility
            delay=$((delay * 2))
            attempt=$((attempt + 1))
        else
            break
        fi
    done
    
    verbose_log "All retry attempts failed after $max_attempts tries"
    return 1
}

# User messaging during degradation
show_degradation_message() {
    local error_code="$1"
    local user_action="$2"
    
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━" >&2
    echo "  claude-auto-tee: Functionality Temporarily Disabled" >&2
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━" >&2
    echo "  Issue: $(get_error_message "$error_code")" >&2
    echo "  Impact: Your command will execute normally without output capture" >&2
    if [ -n "$user_action" ]; then
        echo "  Action: $user_action" >&2
    fi
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━" >&2
}

# Detailed degradation information for verbose mode
show_degradation_details() {
    local error_code="$1"
    
    if is_verbose_mode 2>/dev/null; then
        echo "[VERBOSE] Degradation analysis:" >&2
        echo "[VERBOSE] - Error code: $error_code" >&2
        echo "[VERBOSE] - Error category: $(get_error_category "$error_code")" >&2
        echo "[VERBOSE] - Error severity: $(get_error_severity "$error_code")" >&2
        echo "[VERBOSE] - Degradation mode: $CLAUDE_DEGRADATION_MODE" >&2
        echo "[VERBOSE] - Fallback strategy: Pass-through mode" >&2
        echo "[VERBOSE] - Recovery attempts: ${CLAUDE_RETRY_ATTEMPTS:-0}" >&2
        echo "[VERBOSE] - Original input preserved: yes" >&2
    fi
}

# Log degradation events for monitoring
log_degradation_event() {
    local error_code="$1"
    local degradation_type="$2"
    
    if [ -n "$CLAUDE_METRICS_LOG" ]; then
        local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        local category=$(get_error_category "$error_code")
        echo "$timestamp,degradation,$error_code,$degradation_type,$category" >> "$CLAUDE_METRICS_LOG"
    fi
}

# Safe operation wrapper
safe_operation() {
    local operation="$1"
    local error_code="$2"
    local context="$3"
    
    # Set error context
    set_error_context "$context"
    
    # Try operation with retry if configured
    if [ "${CLAUDE_RETRY_ATTEMPTS:-0}" -gt 0 ]; then
        if smart_retry "$operation"; then
            clear_error_context
            return 0
        fi
    else
        if eval "$operation"; then
            clear_error_context
            return 0
        fi
    fi
    
    # Operation failed, handle gracefully
    handle_failure_gracefully "$error_code" "$context" "$ORIGINAL_INPUT"
    return $?
}

# Check if degradation is currently active
is_degradation_active() {
    [ "$DEGRADATION_ACTIVE" = "true" ]
}

# Emergency pass-through function
emergency_passthrough() {
    echo "EMERGENCY: claude-auto-tee encountered unexpected error, executing original command" >&2
    echo "$ORIGINAL_INPUT"
    exit 0
}

# Cleanup function for graceful shutdown
cleanup_degradation() {
    if [ -n "$CLAUDE_TEMP_DIR_OVERRIDE" ]; then
        unset CLAUDE_TEMP_DIR_OVERRIDE
    fi
    
    clear_error_context 2>/dev/null || true
    DEGRADATION_ACTIVE="false"
}

# Utility function to test degradation behavior
test_degradation() {
    local error_code="$1"
    local test_input='{"tool":{"name":"Bash","input":{"command":"echo test"}},"timeout":null}'
    
    echo "Testing degradation for error code $error_code" >&2
    initialize_degradation "$test_input"
    handle_failure_gracefully "$error_code" "Test scenario" "$test_input"
}

# Export functions for use in main script
export -f handle_failure_gracefully
export -f initiate_passthrough_mode  
export -f attempt_recovery
export -f safe_operation
export -f initialize_degradation
export -f cleanup_degradation
export -f is_degradation_active
export -f emergency_passthrough

# /Users/james/git/claude-auto-tee/src/markers/pretooluse-markers.sh
#!/usr/bin/env bash
# PreToolUse Markers - Inject structured markers for PostToolUse hook
# Format: '###CLAUDE-CAPTURE-START### PATH ###CLAUDE-CAPTURE-END###'

set -euo pipefail
IFS=$'\n\t'

# Environment variable configuration (define early) - avoid conflicts
if [[ -z "${ENABLE_MARKERS:-}" ]]; then
    readonly ENABLE_MARKERS="${CLAUDE_AUTO_TEE_ENABLE_MARKERS:-true}"
fi
# Note: VERBOSE_MODE will be set by main script - don't define as readonly here
if [[ -z "${VERBOSE_MODE:-}" ]]; then
    VERBOSE_MODE="${CLAUDE_AUTO_TEE_VERBOSE:-false}"
fi

# Verbose logging function (define early for use in sourcing)
log_verbose() {
    if [[ "$VERBOSE_MODE" == "true" ]] || [[ "${CLAUDE_AUTO_TEE_VERBOSE:-false}" == "true" ]]; then
        echo "[CLAUDE-MARKERS] $1" >&2
    fi
}

# Source required modules
if [[ -z "${SCRIPT_DIR:-}" ]]; then
    readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
fi

# Source required modules with conflict protection
if [[ -z "${ERR_INVALID_INPUT:-}" ]]; then
    # Only source if not already loaded
    if [[ -f "${SCRIPT_DIR}/../error-codes.sh" ]]; then
        source "${SCRIPT_DIR}/../error-codes.sh" 2>/dev/null || true
    elif [[ -f "${SCRIPT_DIR}/error-codes.sh" ]]; then
        source "${SCRIPT_DIR}/error-codes.sh" 2>/dev/null || true
    fi
fi

if ! command -v normalize_path >/dev/null 2>&1; then
    # Only source path-utils if normalize_path function is not available
    if [[ -f "${SCRIPT_DIR}/../path-utils.sh" ]]; then
        source "${SCRIPT_DIR}/../path-utils.sh" 2>/dev/null || true
    elif [[ -f "${SCRIPT_DIR}/path-utils.sh" ]]; then
        source "${SCRIPT_DIR}/path-utils.sh" 2>/dev/null || true
    fi
fi

# Source env-exporter context for capture path prediction
if [[ -z "${ENV_EXPORTER_AVAILABLE:-}" ]]; then
    if [[ -x "${SCRIPT_DIR}/../env/environment-exporter.js" ]]; then
        readonly ENV_EXPORTER_AVAILABLE=true
        log_verbose "Environment exporter available for context"
    else
        readonly ENV_EXPORTER_AVAILABLE=false
        log_verbose "Environment exporter not available - using fallback path prediction"
    fi
fi

# Marker format constants - Task specification format (avoid conflicts)
if [[ -z "${MARKER_FORMAT:-}" ]]; then
    MARKER_FORMAT="# CAPTURE_START:"
fi
if [[ -z "${MARKER_END_FORMAT:-}" ]]; then
    MARKER_END_FORMAT="# CAPTURE_END:"
fi
if [[ -z "${MARKER_SEPARATOR:-}" ]]; then
    MARKER_SEPARATOR=" "
fi

# Legacy marker constants for backward compatibility (avoid conflicts)
if [[ -z "${LEGACY_MARKER_START:-}" ]]; then
    LEGACY_MARKER_START="###CLAUDE-CAPTURE-START###"
fi
if [[ -z "${LEGACY_MARKER_END:-}" ]]; then
    LEGACY_MARKER_END="###CLAUDE-CAPTURE-END###"
fi

# Predict capture path using the same logic as main script
predict_capture_path() {
    local temp_dir="$1"
    local temp_file_prefix="${2:-claude}"
    
    if [[ -z "$temp_dir" ]]; then
        log_verbose "Warning: No temp directory provided for path prediction"
        return 1
    fi
    
    # Use the same timestamp-based path generation as claude-auto-tee.sh
    # Cross-platform timestamp generation for unique file names
    local timestamp
    if command -v gdate >/dev/null 2>&1; then
        # Use GNU date if available (installed via homebrew on macOS)
        timestamp=$(gdate +%s%N | cut -b1-13)
    elif date +%s%3N >/dev/null 2>&1; then
        # Some systems support milliseconds directly
        timestamp=$(date +%s%3N)
    else
        # Fallback: seconds + random padding for uniqueness
        # This matches what the main script would generate on macOS
        timestamp="$(date +%s)$(printf "%03d" $((RANDOM % 1000)))"
    fi
    local predicted_path="${temp_dir}/${temp_file_prefix}-${timestamp}.log"
    
    # Normalize path for consistency
    if command -v normalize_path >/dev/null 2>&1; then
        if normalized_path=$(normalize_path "$predicted_path" 2>/dev/null); then
            predicted_path="$normalized_path"
        fi
    fi
    
    echo "$predicted_path"
    return 0
}

# Inject capture start marker to stderr with task-specified format
inject_capture_start_marker() {
    local temp_file_path="$1"
    
    if [[ "$ENABLE_MARKERS" != "true" ]]; then
        log_verbose "Markers disabled - skipping injection"
        return 0
    fi
    
    # Validate path parameter
    if [[ -z "$temp_file_path" ]]; then
        log_verbose "Warning: No temp file path provided to marker injection"
        return 1
    fi
    
    # Normalize path to ensure consistent format across platforms
    local normalized_path
    if normalized_path=$(normalize_path "$temp_file_path" 2>/dev/null); then
        temp_file_path="$normalized_path"
    fi
    
    # Construct marker with task-specified format: "# CAPTURE_START: <predicted_path>"
    local marker="${MARKER_FORMAT} ${temp_file_path}"
    
    # Inject marker to stderr in a way that doesn't interfere with command execution
    # Use a background process to avoid blocking the main command
    echo "$marker" >&2 &
    
    log_verbose "Injected capture start marker: $marker"
    return 0
}

# Inject capture end marker to stderr with task-specified format
inject_capture_end_marker() {
    local temp_file_path="$1"
    
    if [[ "$ENABLE_MARKERS" != "true" ]]; then
        log_verbose "Markers disabled - skipping injection"
        return 0
    fi
    
    # Validate path parameter
    if [[ -z "$temp_file_path" ]]; then
        log_verbose "Warning: No temp file path provided to marker injection"
        return 1
    fi
    
    # Normalize path to ensure consistent format
    local normalized_path
    if normalized_path=$(normalize_path "$temp_file_path" 2>/dev/null); then
        temp_file_path="$normalized_path"
    fi
    
    # Construct end marker with task-specified format: "# CAPTURE_END: <path>"
    local marker="${MARKER_END_FORMAT} ${temp_file_path}"
    
    # Inject marker to stderr in background
    echo "$marker" >&2 &
    
    log_verbose "Injected capture end marker: $marker"
    return 0
}

# Extract markers from stderr for testing/validation (supports both formats)
extract_markers_from_text() {
    local text="$1"
    local marker_type="${2:-all}"
    
    case "$marker_type" in
        start)
            # Extract task-specified format first, then legacy format
            {
                echo "$text" | grep -oE "${MARKER_FORMAT} [^\r\n]+" || true
                echo "$text" | grep -oE "${LEGACY_MARKER_START}${MARKER_SEPARATOR}[^${MARKER_SEPARATOR}]+${MARKER_SEPARATOR}${LEGACY_MARKER_END}" || true
            }
            ;;
        end)
            # Extract task-specified format first, then legacy format
            {
                echo "$text" | grep -oE "${MARKER_END_FORMAT} [^\r\n]+" || true
                echo "$text" | grep -oE "${LEGACY_MARKER_END}${MARKER_SEPARATOR}[^${MARKER_SEPARATOR}]+${MARKER_SEPARATOR}${LEGACY_MARKER_START}" || true
            }
            ;;
        all|*)
            # Extract all markers
            {
                extract_markers_from_text "$text" "start"
                extract_markers_from_text "$text" "end"
            }
            ;;
    esac
}

# Parse path from marker (supports both task-specified and legacy formats)
parse_path_from_marker() {
    local marker="$1"
    
    # Extract path from task-specified start marker format: "# CAPTURE_START: <path>"
    if echo "$marker" | grep -qE "^${MARKER_FORMAT} "; then
        echo "$marker" | sed -E "s/^${MARKER_FORMAT} (.+)$/\1/"
        return 0
    fi
    
    # Extract path from task-specified end marker format: "# CAPTURE_END: <path>"
    if echo "$marker" | grep -qE "^${MARKER_END_FORMAT} "; then
        echo "$marker" | sed -E "s/^${MARKER_END_FORMAT} (.+)$/\1/"
        return 0
    fi
    
    # Extract path from legacy start marker format
    if echo "$marker" | grep -qE "^${LEGACY_MARKER_START}${MARKER_SEPARATOR}"; then
        echo "$marker" | sed -E "s/^${LEGACY_MARKER_START}${MARKER_SEPARATOR}(.+)${MARKER_SEPARATOR}${LEGACY_MARKER_END}$/\1/"
        return 0
    fi
    
    # Extract path from legacy end marker format
    if echo "$marker" | grep -qE "^${LEGACY_MARKER_END}${MARKER_SEPARATOR}"; then
        echo "$marker" | sed -E "s/^${LEGACY_MARKER_END}${MARKER_SEPARATOR}(.+)${MARKER_SEPARATOR}${LEGACY_MARKER_START}$/\1/"
        return 0
    fi
    
    return 1
}

# Validate marker format (supports both task-specified and legacy formats)
validate_marker_format() {
    local marker="$1"
    
    # Check task-specified start marker format: "# CAPTURE_START: <path>"
    if echo "$marker" | grep -qE "^${MARKER_FORMAT} .+$"; then
        return 0
    fi
    
    # Check task-specified end marker format: "# CAPTURE_END: <path>"
    if echo "$marker" | grep -qE "^${MARKER_END_FORMAT} .+$"; then
        return 0
    fi
    
    # Check legacy start marker format
    if echo "$marker" | grep -qE "^${LEGACY_MARKER_START}${MARKER_SEPARATOR}.+${MARKER_SEPARATOR}${LEGACY_MARKER_END}$"; then
        return 0
    fi
    
    # Check legacy end marker format
    if echo "$marker" | grep -qE "^${LEGACY_MARKER_END}${MARKER_SEPARATOR}.+${MARKER_SEPARATOR}${LEGACY_MARKER_START}$"; then
        return 0
    fi
    
    return 1
}

# Main function for PreToolUse hook - injects markers with pipe detection
inject_pretooluse_marker() {
    local command="$1"
    local temp_dir="$2"
    local temp_file_prefix="${3:-claude}"
    
    if [[ "$ENABLE_MARKERS" != "true" ]]; then
        log_verbose "PreToolUse markers disabled - skipping injection"
        return 0
    fi
    
    # Validate required parameters
    if [[ -z "$command" ]]; then
        log_verbose "Warning: No command provided to PreToolUse marker injection"
        return 1
    fi
    
    if [[ -z "$temp_dir" ]]; then
        log_verbose "Warning: No temp directory provided to PreToolUse marker injection"
        return 1
    fi
    
    # Detect if command has pipes (same logic as main script)
    local pipe_count
    if ! pipe_count=$(detect_safe_pipes_in_command "$command" 2>/dev/null); then
        log_verbose "Failed to detect pipes in command - skipping marker injection"
        return 1
    fi
    
    # Only inject markers for commands with pipes (where tee will be injected)
    if [[ "$pipe_count" -eq 0 ]]; then
        log_verbose "No pipes detected in command - skipping PreToolUse marker injection"
        return 0
    fi
    
    if [[ "$pipe_count" -ne 1 ]]; then
        log_verbose "Multiple pipes detected ($pipe_count) - skipping PreToolUse marker injection for security"
        return 0
    fi
    
    # Check if command already has tee (same logic as main script)
    if echo "$command" | grep -q "tee "; then
        log_verbose "Command already contains tee - skipping PreToolUse marker injection"
        return 0
    fi
    
    # Predict the capture path using same logic as main script
    local predicted_path
    if ! predicted_path=$(predict_capture_path "$temp_dir" "$temp_file_prefix"); then
        log_verbose "Failed to predict capture path - skipping marker injection"
        return 1
    fi
    
    # Inject the capture start marker
    log_verbose "Injecting PreToolUse capture marker for pipe command: $command"
    inject_capture_start_marker "$predicted_path"
    
    return 0
}

# Safe pipe detection for PreToolUse (simplified version of main script logic)
detect_safe_pipes_in_command() {
    local cmd="$1"
    local in_single_quote=false
    local in_double_quote=false
    local escaped=false
    local pipe_count=0
    local i=0
    
    while [[ $i -lt ${#cmd} ]]; do
        local char="${cmd:$i:1}"
        local next_char="${cmd:$((i+1)):1}"
        local prev_char="${cmd:$((i-1)):1}"
        
        if [[ "$escaped" == "true" ]]; then
            escaped=false
            ((i++))
            continue
        fi
        
        case "$char" in
            '\\')
                escaped=true
                ;;
            "'")
                if [[ "$in_double_quote" == "false" ]]; then
                    in_single_quote=$([[ "$in_single_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '"')
                if [[ "$in_single_quote" == "false" ]]; then
                    in_double_quote=$([[ "$in_double_quote" == "true" ]] && echo "false" || echo "true")
                fi
                ;;
            '|')
                if [[ "$in_single_quote" == "false" ]] && [[ "$in_double_quote" == "false" ]]; then
                    # Check for proper pipe with spaces
                    if [[ "$prev_char" == " " ]] && [[ "$next_char" == " " ]]; then
                        ((pipe_count++))
                    fi
                fi
                ;;
        esac
        
        ((i++))
    done
    
    echo "$pipe_count"
    return 0
}

# Enhanced marker injection that handles concurrent execution
inject_concurrent_safe_marker() {
    local temp_file_path="$1"
    local marker_type="${2:-start}"
    local process_id="$$"
    local timestamp="$(date +%s%N)"
    
    if [[ "$ENABLE_MARKERS" != "true" ]]; then
        return 0
    fi
    
    # Add process ID and timestamp for concurrent safety
    local enriched_path="${temp_file_path}#${process_id}#${timestamp}"
    
    case "$marker_type" in
        start)
            inject_capture_start_marker "$enriched_path"
            ;;
        end)
            inject_capture_end_marker "$enriched_path"
            ;;
        *)
            log_verbose "Warning: Unknown marker type '$marker_type'"
            return 1
            ;;
    esac
}

# Clean path from concurrent markers (remove process ID and timestamp)
clean_concurrent_path() {
    local enriched_path="$1"
    
    # Remove #processid#timestamp suffix
    echo "$enriched_path" | sed -E 's/#[0-9]+#[0-9]+$//'
}

# Test function for marker functionality
test_marker_functionality() {
    log_verbose "Testing marker functionality..."
    
    local test_path="/tmp/test-marker-file.log"
    local marker_output
    
    # Test start marker injection
    marker_output=$(inject_capture_start_marker "$test_path" 2>&1)
    if validate_marker_format "$marker_output"; then
        log_verbose "✓ Start marker format validation passed"
    else
        log_verbose "✗ Start marker format validation failed"
        return 1
    fi
    
    # Test end marker injection
    marker_output=$(inject_capture_end_marker "$test_path" 2>&1)
    if validate_marker_format "$marker_output"; then
        log_verbose "✓ End marker format validation passed"
    else
        log_verbose "✗ End marker format validation failed"
        return 1
    fi
    
    # Test path extraction
    local test_marker="${MARKER_FORMAT} ${test_path}"
    local extracted_path
    if extracted_path=$(parse_path_from_marker "$test_marker"); then
        if [[ "$extracted_path" == "$test_path" ]]; then
            log_verbose "✓ Path extraction test passed"
        else
            log_verbose "✗ Path extraction test failed: expected '$test_path', got '$extracted_path'"
            return 1
        fi
    else
        log_verbose "✗ Path extraction test failed: could not extract path"
        return 1
    fi
    
    log_verbose "All marker tests passed"
    return 0
}

# Command line interface
main() {
    local action="${1:-}"
    local path="${2:-}"
    local marker_type="${3:-start}"
    
    case "$action" in
        inject)
            if [[ -z "$path" ]]; then
                echo "Usage: $0 inject <path> [start|end]" >&2
                return 1
            fi
            inject_concurrent_safe_marker "$path" "$marker_type"
            ;;
        pretooluse)
            # New command for PreToolUse hook integration
            local command="$path"
            local temp_dir="$marker_type"
            local temp_prefix="${4:-claude}"
            if [[ -z "$command" ]] || [[ -z "$temp_dir" ]]; then
                echo "Usage: $0 pretooluse <command> <temp_dir> [temp_prefix]" >&2
                return 1
            fi
            inject_pretooluse_marker "$command" "$temp_dir" "$temp_prefix"
            ;;
        extract)
            local text="${path:-$(cat)}"
            extract_markers_from_text "$text"
            ;;
        parse)
            if [[ -z "$path" ]]; then
                echo "Usage: $0 parse <marker>" >&2
                return 1
            fi
            parse_path_from_marker "$path"
            ;;
        validate)
            if [[ -z "$path" ]]; then
                echo "Usage: $0 validate <marker>" >&2
                return 1
            fi
            if validate_marker_format "$path"; then
                echo "Valid marker format"
                return 0
            else
                echo "Invalid marker format"
                return 1
            fi
            ;;
        test)
            test_marker_functionality
            ;;
        clean-path)
            if [[ -z "$path" ]]; then
                echo "Usage: $0 clean-path <enriched_path>" >&2
                return 1
            fi
            clean_concurrent_path "$path"
            ;;
        *)
            echo "Usage: $0 {inject|pretooluse|extract|parse|validate|test|clean-path} [arguments...]" >&2
            echo "" >&2
            echo "Commands:" >&2
            echo "  inject <path> [start|end]       - Inject capture marker for path" >&2
            echo "  pretooluse <cmd> <dir> [prefix] - PreToolUse hook marker injection" >&2
            echo "  extract [text]                  - Extract markers from text or stdin" >&2
            echo "  parse <marker>                  - Parse path from marker" >&2
            echo "  validate <marker>               - Validate marker format" >&2
            echo "  test                            - Run marker functionality tests" >&2
            echo "  clean-path <path>               - Clean concurrent enriched path" >&2
            echo "" >&2
            echo "Environment variables:" >&2
            echo "  CLAUDE_AUTO_TEE_ENABLE_MARKERS - Enable/disable markers (default: true)" >&2
            echo "  CLAUDE_AUTO_TEE_VERBOSE        - Enable verbose logging (default: false)" >&2
            return 1
            ;;
    esac
}

# Only run main if script is executed directly (not sourced)
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi

# /Users/james/git/claude-auto-tee/src/parser/capture-path-parser.js
#!/usr/bin/env node
/**
 * PathParser - Capture Path Parser for PostToolUse Hook Implementation
 * 
 * Extracts file paths from stderr messages containing "Full output saved to: <path>"
 * Handles various path formats including:
 * - Absolute paths (Unix: /tmp/file, Windows: C:\temp\file)
 * - Relative paths (./file, ../file, file.txt)
 * - Paths with spaces, Unicode characters
 * - Multiple captures from single stderr output
 * 
 * Returns structured data: {path: string, timestamp: Date, raw: string}
 * 
 * @author Claude Code
 * @interface PathParser:v1
 */

const path = require('path');

/**
 * PathParser class for extracting capture paths from PostToolUse tool_response
 */
class PathParser {
    constructor() {
        // Regex patterns for different path formats
        this.patterns = {
            // Primary pattern: "Full output saved to: <path>"
            primary: /Full output saved to:\s*([^\r\n]+?)(?:\s*$|\r|\n)/gm,
            
            // Secondary patterns for edge cases
            tempFile: /temp file preserved:\s*([^\r\n]+?)(?:\s*$|\r|\n)/gm,
            
            // Path validation patterns (cross-platform) - allow quotes in path content
            unix: /^\/[^<>:|?*\x00-\x1f]*$/,
            windows: /^[A-Za-z]:[^<>|?*\x00-\x1f]*$/,
            relative: /^\.{1,2}[\/\\][^<>:|?*\x00-\x1f]*$|^[^\/\\<>:|?*\x00-\x1f][^<>:|?*\x00-\x1f]*$/
        };
        
        // Statistics for monitoring
        this.stats = {
            totalProcessed: 0,
            pathsExtracted: 0,
            errors: 0,
            lastProcessed: null
        };
    }

    /**
     * Parse stderr output to extract file paths
     * @param {string} stderr - The stderr output to parse
     * @param {Date} [timestamp] - Optional timestamp for the capture
     * @returns {Array<Object>} Array of parsed capture objects
     */
    parse(stderr, timestamp = new Date()) {
        this.stats.totalProcessed++;
        this.stats.lastProcessed = timestamp;
        
        if (stderr === null || stderr === undefined || typeof stderr !== 'string') {
            throw new TypeError('stderr must be a non-empty string');
        }
        
        // Handle empty strings gracefully
        if (stderr === '') {
            return [];
        }

        const captures = [];
        
        try {
            // Extract paths using primary pattern
            captures.push(...this._extractWithPattern(stderr, this.patterns.primary, timestamp));
            
            // Extract paths using secondary pattern
            captures.push(...this._extractWithPattern(stderr, this.patterns.tempFile, timestamp));
            
            // Remove duplicates based on path
            const uniqueCaptures = this._removeDuplicates(captures);
            
            this.stats.pathsExtracted += uniqueCaptures.length;
            return uniqueCaptures;
            
        } catch (error) {
            this.stats.errors++;
            throw new Error(`Failed to parse stderr: ${error.message}`);
        }
    }

    /**
     * Extract paths using a specific regex pattern
     * @private
     * @param {string} text - Text to search
     * @param {RegExp} pattern - Regex pattern to use
     * @param {Date} timestamp - Timestamp for captures
     * @returns {Array<Object>} Array of capture objects
     */
    _extractWithPattern(text, pattern, timestamp) {
        const captures = [];
        let match;
        
        // Reset regex state
        pattern.lastIndex = 0;
        
        while ((match = pattern.exec(text)) !== null) {
            const rawPath = match[1];
            if (!rawPath) continue;
            
            // Clean and validate the path
            const cleanPath = this._cleanPath(rawPath);
            if (this._isValidPath(cleanPath)) {
                captures.push({
                    path: cleanPath,
                    timestamp: new Date(timestamp),
                    raw: match[0].trim()
                });
            }
        }
        
        return captures;
    }

    /**
     * Clean extracted path by removing extra whitespace and quotes
     * @private
     * @param {string} rawPath - Raw path string
     * @returns {string} Cleaned path
     */
    _cleanPath(rawPath) {
        if (!rawPath) return '';
        
        // Trim whitespace
        let cleaned = rawPath.trim();
        
        // Remove surrounding quotes if they match
        if ((cleaned.startsWith('"') && cleaned.endsWith('"')) ||
            (cleaned.startsWith("'") && cleaned.endsWith("'"))) {
            cleaned = cleaned.slice(1, -1);
        }
        
        // Handle escaped quotes
        cleaned = cleaned.replace(/\\"/g, '"').replace(/\\'/g, "'");
        
        // Normalize path separators for the current platform
        // Keep original separators but normalize repeated separators
        cleaned = cleaned.replace(/[\/\\]+/g, path.sep);
        
        return cleaned;
    }

    /**
     * Validate if a path is a valid file system path
     * @private
     * @param {string} pathStr - Path to validate
     * @returns {boolean} True if path is valid
     */
    _isValidPath(pathStr) {
        if (!pathStr || pathStr.length === 0) return false;
        
        // Check for invalid characters or suspicious patterns
        if (pathStr.includes('\x00') || pathStr.includes('\r') || pathStr.includes('\n')) {
            return false;
        }
        
        // Check against path patterns
        return this.patterns.unix.test(pathStr) || 
               this.patterns.windows.test(pathStr) || 
               this.patterns.relative.test(pathStr);
    }

    /**
     * Remove duplicate captures based on path
     * @private
     * @param {Array<Object>} captures - Array of capture objects
     * @returns {Array<Object>} Array with duplicates removed
     */
    _removeDuplicates(captures) {
        const seen = new Set();
        return captures.filter(capture => {
            const key = path.resolve(capture.path);
            if (seen.has(key)) {
                return false;
            }
            seen.add(key);
            return true;
        });
    }

    /**
     * Parse multiple stderr outputs
     * @param {Array<string>} stderrList - Array of stderr outputs
     * @param {Date} [timestamp] - Optional base timestamp
     * @returns {Array<Object>} Array of all parsed captures
     */
    parseMultiple(stderrList, timestamp = new Date()) {
        if (!Array.isArray(stderrList)) {
            throw new TypeError('stderrList must be an array');
        }

        const allCaptures = [];
        
        stderrList.forEach((stderr, index) => {
            // Use incrementing timestamps for multiple entries
            const entryTimestamp = new Date(timestamp.getTime() + index * 100);
            try {
                const captures = this.parse(stderr, entryTimestamp);
                allCaptures.push(...captures);
            } catch (error) {
                // Continue processing other entries even if one fails
                console.warn(`Failed to parse stderr entry ${index}: ${error.message}`);
            }
        });

        return this._removeDuplicates(allCaptures);
    }

    /**
     * Get parser statistics
     * @returns {Object} Statistics object
     */
    getStats() {
        return { ...this.stats };
    }

    /**
     * Reset parser statistics
     */
    resetStats() {
        this.stats = {
            totalProcessed: 0,
            pathsExtracted: 0,
            errors: 0,
            lastProcessed: null
        };
    }

    /**
     * Check if stderr contains capture patterns
     * @param {string} stderr - stderr output to check
     * @returns {boolean} True if patterns are found
     */
    hasCaptures(stderr) {
        if (!stderr || typeof stderr !== 'string') return false;
        
        return this.patterns.primary.test(stderr) || this.patterns.tempFile.test(stderr);
    }

    /**
     * Extract just the paths (strings) from stderr
     * @param {string} stderr - stderr output to parse
     * @returns {Array<string>} Array of path strings
     */
    extractPaths(stderr) {
        const captures = this.parse(stderr);
        return captures.map(capture => capture.path);
    }

    /**
     * Factory method to create a new PathParser instance
     * @returns {PathParser} New PathParser instance
     */
    static create() {
        return new PathParser();
    }
}

module.exports = PathParser;

# /Users/james/git/claude-auto-tee/src/path-utils.sh
#!/usr/bin/env bash
# Path Utilities for claude-auto-tee
# P1.T007 - Validate path handling (forward/backward slashes)

# Normalize path separators across platforms
normalize_path() {
    local input_path="$1"
    local normalized_path
    
    if [[ -z "$input_path" ]]; then
        echo ""
        return 0
    fi
    
    # Handle different path formats
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            # Windows-like environments - convert forward slashes to backslashes
            normalized_path=$(echo "$input_path" | sed 's|/|\\|g')
            ;;
        *)
            # Unix-like environments - convert backslashes to forward slashes
            normalized_path=$(echo "$input_path" | sed 's|\\|/|g')
            ;;
    esac
    
    # Remove duplicate separators
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            normalized_path=$(echo "$normalized_path" | sed 's|\\\\\\*|\\|g')
            ;;
        *)
            normalized_path=$(echo "$normalized_path" | sed 's|//*|/|g')
            ;;
    esac
    
    # Remove trailing separator (except for root)
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            if [[ "$normalized_path" != "\\" ]] && [[ "$normalized_path" != ?:\\ ]]; then
                normalized_path="${normalized_path%\\}"
            fi
            ;;
        *)
            if [[ "$normalized_path" != "/" ]]; then
                normalized_path="${normalized_path%/}"
            fi
            ;;
    esac
    
    echo "$normalized_path"
}

# Join path components with appropriate separators
join_path() {
    local separator="/"
    local result=""
    local component
    
    # Determine platform-appropriate separator
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            separator="\\"
            ;;
    esac
    
    # Process each argument as a path component
    for component in "$@"; do
        if [[ -z "$component" ]]; then
            continue
        fi
        
        # Normalize component
        component=$(normalize_path "$component")
        
        if [[ -z "$result" ]]; then
            result="$component"
        else
            # Remove leading separator from component if present
            case "$(uname -s)" in
                "CYGWIN"* | "MINGW"* | "MSYS"*)
                    component="${component#\\}"
                    result="${result}\\${component}"
                    ;;
                *)
                    component="${component#/}"
                    result="${result}/${component}"
                    ;;
            esac
        fi
    done
    
    echo "$result"
}

# Check if path is absolute
is_absolute_path() {
    local path="$1"
    
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            # Windows: Check for drive letter or UNC path
            if [[ "$path" =~ ^[A-Za-z]:[\\/] ]] || [[ "$path" =~ ^[\\/][\\/] ]]; then
                return 0
            fi
            ;;
        *)
            # Unix: Check for leading slash
            if [[ "$path" =~ ^/ ]]; then
                return 0
            fi
            ;;
    esac
    
    return 1
}

# Resolve relative path to absolute path
resolve_absolute_path() {
    local input_path="$1"
    local base_dir="${2:-$(pwd)}"
    
    # If already absolute, just normalize
    if is_absolute_path "$input_path"; then
        normalize_path "$input_path"
        return 0
    fi
    
    # Join with base directory and normalize
    local full_path
    full_path=$(join_path "$base_dir" "$input_path")
    normalize_path "$full_path"
}

# Validate path components for security
validate_path_security() {
    local path="$1"
    
    # Check for dangerous patterns
    if [[ "$path" =~ \.\./|\.\.\\ ]]; then
        echo "Path contains parent directory traversal: $path" >&2
        return 1
    fi
    
    # Check for null bytes
    if [[ "$path" == *$'\0'* ]]; then
        echo "Path contains null bytes: $path" >&2
        return 1
    fi
    
    # Check for extremely long paths
    if [[ ${#path} -gt 4096 ]]; then
        echo "Path exceeds maximum length (4096): ${#path}" >&2
        return 1
    fi
    
    return 0
}

# Create a safe temp file path
create_safe_temp_path() {
    local temp_dir="$1"
    local prefix="${2:-claude-auto-tee}"
    local suffix="${3:-.log}"
    
    # Normalize temp directory
    temp_dir=$(normalize_path "$temp_dir")
    
    # Validate temp directory path
    if ! validate_path_security "$temp_dir"; then
        return 1
    fi
    
    # Generate unique filename component - POSIX compliant
    # Use epoch seconds + fast random suffix for uniqueness
    local timestamp
    timestamp=$(date +%s)
    
    # Get 4 random hex characters for uniqueness (extremely fast from /dev/urandom)
    local random_suffix
    if [ -r /dev/urandom ]; then
        # Read 2 bytes = 4 hex chars (very fast, no external commands needed)
        random_suffix=$(od -An -N2 -tx1 /dev/urandom 2>/dev/null | tr -d ' \n')
    else
        # Fallback: use PID + whatever randomness we have
        random_suffix="$$${RANDOM:-0}"
    fi
    
    local filename="${prefix}-${timestamp}-${random_suffix}${suffix}"
    
    # Join and return the complete path
    join_path "$temp_dir" "$filename"
}

# Handle UNC paths on Windows
handle_unc_path() {
    local path="$1"
    
    case "$(uname -s)" in
        "CYGWIN"* | "MINGW"* | "MSYS"*)
            # UNC path format: \\server\share\path
            if [[ "$path" =~ ^[\\/][\\/] ]]; then
                # Normalize UNC path
                local unc_path
                unc_path=$(echo "$path" | sed 's|/|\\|g' | sed 's|\\\\\\*|\\\\|g')
                
                # Ensure it starts with exactly two backslashes
                unc_path="\\\\${unc_path#\\\\}"
                
                echo "$unc_path"
                return 0
            fi
            ;;
    esac
    
    # Not a UNC path, return normalized path
    normalize_path "$path"
}

# Convert between Unix and Windows path formats (for WSL)
convert_wsl_path() {
    local path="$1"
    local to_format="${2:-unix}"  # "unix" or "windows"
    
    # Only relevant in WSL environment
    if [[ -n "${WSL_DISTRO_NAME:-}" ]] || grep -qi "microsoft\|wsl" /proc/version 2>/dev/null; then
        if command -v wslpath >/dev/null 2>&1; then
            case "$to_format" in
                "windows")
                    wslpath -w "$path" 2>/dev/null || echo "$path"
                    ;;
                "unix"|*)
                    wslpath -u "$path" 2>/dev/null || echo "$path"
                    ;;
            esac
            return 0
        fi
    fi
    
    # Fallback to basic conversion
    case "$to_format" in
        "windows")
            echo "$path" | sed 's|^/mnt/\([a-z]\)/|\U\1:/|' | sed 's|/|\\|g'
            ;;
        "unix"|*)
            echo "$path" | sed 's|^\([A-Z]\):|/mnt/\L\1|' | sed 's|\\|/|g'
            ;;
    esac
}

# Test path handling functions
test_path_functions() {
    echo "=== Path Utilities Test Suite ==="
    echo "Platform: $(uname -s)"
    echo ""
    
    # Test normalize_path
    echo "Testing normalize_path:"
    echo "  Input: '/tmp//test\\path/'"
    echo "  Output: '$(normalize_path '/tmp//test\path/')'"
    echo ""
    
    # Test join_path
    echo "Testing join_path:"
    echo "  Input: '/tmp' 'test' 'path'"
    echo "  Output: '$(join_path '/tmp' 'test' 'path')'"
    echo ""
    
    # Test is_absolute_path
    echo "Testing is_absolute_path:"
    for test_path in "/tmp/test" "relative/path" "C:\\Windows" "\\\\server\\share"; do
        if is_absolute_path "$test_path"; then
            echo "  '$test_path': ABSOLUTE"
        else
            echo "  '$test_path': RELATIVE"
        fi
    done
    echo ""
    
    # Test resolve_absolute_path
    echo "Testing resolve_absolute_path:"
    echo "  Input: 'relative/path' from '/tmp'"
    echo "  Output: '$(resolve_absolute_path 'relative/path' '/tmp')'"
    echo ""
    
    # Test create_safe_temp_path
    echo "Testing create_safe_temp_path:"
    echo "  Input: '/tmp'"
    echo "  Output: '$(create_safe_temp_path '/tmp')'"
    echo ""
    
    # Test UNC handling (Windows)
    if [[ "$(uname -s)" =~ ^(CYGWIN|MINGW|MSYS) ]]; then
        echo "Testing handle_unc_path (Windows):"
        echo "  Input: '//server/share/path'"
        echo "  Output: '$(handle_unc_path '//server/share/path')'"
        echo ""
    fi
    
    # Test WSL path conversion
    if [[ -n "${WSL_DISTRO_NAME:-}" ]] || grep -qi "microsoft\|wsl" /proc/version 2>/dev/null; then
        echo "Testing convert_wsl_path (WSL):"
        echo "  Unix to Windows: '/mnt/c/temp' -> '$(convert_wsl_path '/mnt/c/temp' 'windows')'"
        echo "  Windows to Unix: 'C:\\temp' -> '$(convert_wsl_path 'C:\temp' 'unix')'"
        echo ""
    fi
    
    echo "=== Path Utilities Test Complete ==="
}

# Execute tests if script is run directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    test_path_functions
fi

# /Users/james/git/claude-auto-tee/src/scoring/freshness-scorer.js
/**
 * FreshnessScorer - Intelligent scoring system for command output freshness
 * 
 * Calculates freshness scores (0-100) based on:
 * - Time decay (exponential)
 * - File modifications
 * - Command reruns
 * - System state changes
 * 
 * Part of P3.T003: PostToolUse hook implementation
 */

const fs = require('fs').promises;
const path = require('path');
const crypto = require('crypto');
const { execSync } = require('child_process');

/**
 * Configuration for freshness scoring algorithm
 */
const DEFAULT_CONFIG = {
  // Time decay parameters
  lambda: 0.08,  // Decay rate (slightly slower decay for better mid-range scores)
  maxAge: 24,   // Hours after which score approaches 0
  
  // Penalty factors (reduced for better accuracy)
  fileChangePenalty: 5,      // Points lost per related file modification
  commandRerunPenalty: 15,   // Points lost if same command run again
  gitChangePenalty: 8,       // Points lost for git operations
  packageChangePenalty: 12,  // Points lost for package updates
  
  // Confidence intervals
  baseConfidence: 0.95,      // Base confidence level
  uncertaintyFactor: 0.1,    // Uncertainty increase per hour
  
  // Performance
  maxComputeTime: 10,        // Maximum computation time in ms
  cacheEnabled: true,        // Enable score caching
};

/**
 * Data structure for capture metadata
 */
class CaptureMetadata {
  constructor(data) {
    this.path = data.path || '';
    this.command = data.command || '';
    this.timestamp = new Date(data.timestamp || Date.now());
    this.size = data.size || 0;
    this.hash = data.hash || '';
    this.workingDirectory = data.workingDirectory || process.cwd();
    this.relatedFiles = data.relatedFiles || [];
    this.systemState = data.systemState || {};
  }
}

/**
 * Result object for freshness scoring
 */
class FreshnessResult {
  constructor() {
    this.score = 0;              // Main freshness score (0-100)
    this.confidence = 0;         // Confidence interval (0-1)
    this.factors = {};           // Individual scoring factors
    this.reasons = [];           // Explanations for staleness
    this.computeTime = 0;        // Time taken to compute (ms)
    this.cached = false;         // Whether result was cached
  }
}

/**
 * Main freshness scorer class
 */
class FreshnessScorer {
  constructor(config = {}) {
    this.config = { ...DEFAULT_CONFIG, ...config };
    this.cache = new Map();
    this.systemStateCache = new Map();
  }

  /**
   * Calculate freshness score for a capture
   * @param {CaptureMetadata} metadata - Capture metadata
   * @param {Object} currentState - Current system state
   * @returns {FreshnessResult} Scoring result
   */
  async calculateScore(metadata, currentState = {}) {
    const startTime = Date.now();
    const result = new FreshnessResult();
    
    try {
      // Check cache first
      const cacheKey = this._generateCacheKey(metadata, currentState);
      if (this.config.cacheEnabled && this.cache.has(cacheKey)) {
        const cached = this.cache.get(cacheKey);
        result.cached = true;
        result.computeTime = Date.now() - startTime;
        return { ...cached, computeTime: result.computeTime, cached: true };
      }

      // Calculate time-based decay
      await this._calculateTimeDecay(metadata, result);
      
      // Check file modifications
      await this._checkFileModifications(metadata, currentState, result);
      
      // Check command reruns
      await this._checkCommandReruns(metadata, currentState, result);
      
      // Check system state changes
      await this._checkSystemChanges(metadata, currentState, result);
      
      // Calculate final score and confidence
      this._calculateFinalScore(result);
      this._calculateConfidence(metadata, result);
      
      result.computeTime = Date.now() - startTime;
      
      // Cache result if enabled
      if (this.config.cacheEnabled) {
        this.cache.set(cacheKey, { ...result, cached: false });
      }
      
      return result;
      
    } catch (error) {
      result.score = 0;
      result.confidence = 0;
      result.reasons.push(`Error calculating freshness: ${error.message}`);
      result.computeTime = Date.now() - startTime;
      return result;
    }
  }

  /**
   * Calculate time-based decay using exponential function
   * score = 100 * exp(-λ * hours_elapsed)
   */
  async _calculateTimeDecay(metadata, result) {
    const now = new Date();
    const hoursElapsed = (now - metadata.timestamp) / (1000 * 60 * 60);
    
    const timeScore = Math.max(0, 100 * Math.exp(-this.config.lambda * hoursElapsed));
    
    result.factors.timeDecay = timeScore;
    result.score = timeScore;
    
    if (hoursElapsed > 1) {
      result.reasons.push(`Capture is ${hoursElapsed.toFixed(1)} hours old`);
    }
    
    if (timeScore < 50) {
      result.reasons.push('Significant time decay detected');
    }
  }

  /**
   * Check for related file modifications
   */
  async _checkFileModifications(metadata, currentState, result) {
    let fileChanges = 0;
    const changedFiles = [];

    try {
      const now = new Date();
      const hoursElapsed = (now - metadata.timestamp) / (1000 * 60 * 60);
      
      // For very fresh captures (< 1 minute), be more lenient with file changes
      if (hoursElapsed < 1/60) {
        return; // Skip file change penalties for captures less than 1 minute old
      }

      // Check the main output file (but be lenient for recent creates)
      if (metadata.path && await this._fileExists(metadata.path)) {
        const stats = await fs.stat(metadata.path);
        const timeDiff = (stats.mtime - metadata.timestamp) / 1000; // seconds
        
        // Only penalize if modified significantly after capture (> 5 seconds)
        if (timeDiff > 5) {
          fileChanges++;
          changedFiles.push(metadata.path);
        }
      }

      // Only check working directory for captures older than 30 minutes
      if (hoursElapsed > 0.5) {
        const workingDir = metadata.workingDirectory;
        if (await this._fileExists(workingDir)) {
          const files = await this._getRecentlyModifiedFiles(workingDir, metadata.timestamp);
          fileChanges += Math.min(files.length, 2); // Limit impact
          changedFiles.push(...files.slice(0, 2));
        }
      }

      // Check explicitly related files
      for (const file of metadata.relatedFiles.slice(0, 3)) { // Limit for performance
        if (await this._fileExists(file)) {
          const stats = await fs.stat(file);
          if (stats.mtime > metadata.timestamp) {
            fileChanges++;
            changedFiles.push(file);
          }
        }
      }

    } catch (error) {
      // Ignore file check errors for better performance and reliability
    }

    if (fileChanges > 0) {
      const penalty = fileChanges * this.config.fileChangePenalty;
      result.factors.fileChanges = -penalty;
      result.score = Math.max(0, result.score - penalty);
      result.reasons.push(`${fileChanges} file(s) modified since capture: ${changedFiles.slice(0, 3).join(', ')}`);
      
      if (changedFiles.length > 3) {
        result.reasons.push(`... and ${changedFiles.length - 3} more files`);
      }
    }
  }

  /**
   * Check if the same command has been run again
   */
  async _checkCommandReruns(metadata, currentState, result) {
    try {
      // Check if command appears in recent history
      const recentCommands = currentState.recentCommands || [];
      const commandHash = crypto.createHash('md5').update(metadata.command).digest('hex');
      
      const rerunCount = recentCommands.filter(cmd => {
        const cmdHash = crypto.createHash('md5').update(cmd.command || '').digest('hex');
        return cmdHash === commandHash && new Date(cmd.timestamp) > metadata.timestamp;
      }).length;

      if (rerunCount > 0) {
        const penalty = rerunCount * this.config.commandRerunPenalty;
        result.factors.commandReruns = -penalty;
        result.score = Math.max(0, result.score - penalty);
        result.reasons.push(`Same command run ${rerunCount} time(s) since capture`);
      }

    } catch (error) {
      result.reasons.push(`Command rerun check error: ${error.message}`);
    }
  }

  /**
   * Check for system state changes (git, packages, etc.)
   */
  async _checkSystemChanges(metadata, currentState, result) {
    try {
      // Check git state
      await this._checkGitChanges(metadata, result);
      
      // Check package changes
      await this._checkPackageChanges(metadata, result);
      
      // Check environment changes
      await this._checkEnvironmentChanges(metadata, currentState, result);
      
    } catch (error) {
      result.reasons.push(`System state check error: ${error.message}`);
    }
  }

  /**
   * Check for git repository changes
   */
  async _checkGitChanges(metadata, result) {
    try {
      const workingDir = metadata.workingDirectory;
      
      // Skip git checks for very fresh captures (< 5 minutes)
      const now = new Date();
      const hoursElapsed = (now - metadata.timestamp) / (1000 * 60 * 60);
      if (hoursElapsed < 5/60) {
        return;
      }
      
      // Quick check if we're in a git repository
      try {
        execSync('git rev-parse --git-dir', { 
          cwd: workingDir, 
          stdio: 'ignore',
          timeout: 1000 // 1 second timeout
        });
      } catch {
        return; // Not a git repository or timeout
      }

      // Only check git for older captures to improve performance
      if (hoursElapsed > 1) { // Wait longer before checking git
        try {
          // Simple check - just see if there are uncommitted changes
          const status = execSync('git status --porcelain', { 
            cwd: workingDir, 
            encoding: 'utf8',
            timeout: 1000
          }).trim();

          if (status) {
            const penalty = this.config.gitChangePenalty;
            result.factors.gitChanges = -penalty;
            result.score = Math.max(0, result.score - penalty);
            result.reasons.push('Git repository has uncommitted changes');
          }
        } catch {
          // Ignore git errors for performance
        }
      }

    } catch (error) {
      // Ignore git errors in non-git directories
    }
  }

  /**
   * Check for package manager changes
   */
  async _checkPackageChanges(metadata, result) {
    try {
      const workingDir = metadata.workingDirectory;
      
      // Skip package checks for very fresh captures (< 10 minutes)
      const now = new Date();
      const hoursElapsed = (now - metadata.timestamp) / (1000 * 60 * 60);
      if (hoursElapsed < 10/60) {
        return;
      }
      
      // Only check package files for captures older than 1 hour
      if (hoursElapsed < 1) {
        return;
      }
      
      // Check package.json modification with tolerance
      const packageJsonPath = path.join(workingDir, 'package.json');
      if (await this._fileExists(packageJsonPath)) {
        const stats = await fs.stat(packageJsonPath);
        const timeDiff = (stats.mtime - metadata.timestamp) / 1000; // seconds
        
        // Only penalize if modified significantly after capture (> 60 seconds)
        if (timeDiff > 60) {
          const penalty = this.config.packageChangePenalty;
          result.factors.packageChanges = -penalty;
          result.score = Math.max(0, result.score - penalty);
          result.reasons.push('package.json modified since capture');
        }
      }

      // Check package-lock.json modification with tolerance
      const lockfilePath = path.join(workingDir, 'package-lock.json');
      if (await this._fileExists(lockfilePath)) {
        const stats = await fs.stat(lockfilePath);
        const timeDiff = (stats.mtime - metadata.timestamp) / 1000; // seconds
        
        // Only penalize if modified significantly after capture (> 60 seconds)
        if (timeDiff > 60) {
          const penalty = this.config.packageChangePenalty;
          result.factors.packageChanges = Math.min(result.factors.packageChanges || 0, -penalty);
          result.score = Math.max(0, result.score - penalty);
          result.reasons.push('Dependencies changed since capture');
        }
      }

    } catch (error) {
      // Ignore package check errors
    }
  }

  /**
   * Check for environment variable changes
   */
  async _checkEnvironmentChanges(metadata, currentState, result) {
    // Simple environment change detection
    if (metadata.systemState && currentState.environment) {
      const oldEnvHash = metadata.systemState.environmentHash;
      const currentEnvHash = this._hashEnvironment(currentState.environment);
      
      if (oldEnvHash && oldEnvHash !== currentEnvHash) {
        result.factors.envChanges = -5;
        result.score = Math.max(0, result.score - 5);
        result.reasons.push('Environment variables changed');
      }
    }
  }

  /**
   * Calculate final weighted score
   */
  _calculateFinalScore(result) {
    // Score is already calculated incrementally
    result.score = Math.max(0, Math.min(100, result.score));
  }

  /**
   * Calculate confidence interval
   */
  _calculateConfidence(metadata, result) {
    const now = new Date();
    const hoursElapsed = (now - metadata.timestamp) / (1000 * 60 * 60);
    
    // Confidence decreases over time
    let confidence = this.config.baseConfidence;
    confidence -= hoursElapsed * this.config.uncertaintyFactor;
    
    // Reduce confidence for missing metadata
    if (!metadata.hash) confidence -= 0.1;
    if (!metadata.size) confidence -= 0.05;
    if (metadata.relatedFiles.length === 0) confidence -= 0.05;
    
    // Increase confidence for recent captures with complete metadata
    if (hoursElapsed < 0.5 && metadata.hash && metadata.size) {
      confidence = Math.min(1.0, confidence + 0.05);
    }
    
    result.confidence = Math.max(0.1, Math.min(1.0, confidence));
  }

  /**
   * Helper methods
   */

  async _fileExists(filePath) {
    try {
      await fs.access(filePath);
      return true;
    } catch {
      return false;
    }
  }

  async _getRecentlyModifiedFiles(directory, sinceTime) {
    try {
      const files = await fs.readdir(directory);
      const recentFiles = [];
      
      // Limit to first 5 files for better performance
      for (const file of files.slice(0, 5)) {
        try {
          const filePath = path.join(directory, file);
          const stats = await fs.stat(filePath);
          
          if (stats.isFile() && stats.mtime > sinceTime) {
            recentFiles.push(filePath);
          }
        } catch {
          // Skip files we can't access
        }
      }
      
      return recentFiles;
    } catch {
      return [];
    }
  }

  _generateCacheKey(metadata, currentState) {
    const keyData = {
      path: metadata.path,
      command: metadata.command,
      timestamp: metadata.timestamp.getTime(),
      stateHash: JSON.stringify(currentState)
    };
    return crypto.createHash('md5').update(JSON.stringify(keyData)).digest('hex');
  }

  _hashEnvironment(env) {
    const relevant = ['NODE_ENV', 'PATH', 'HOME', 'PWD'];
    const envData = {};
    
    for (const key of relevant) {
      if (env[key]) {
        envData[key] = env[key];
      }
    }
    
    return crypto.createHash('md5').update(JSON.stringify(envData)).digest('hex');
  }

  /**
   * Clear the scoring cache
   */
  clearCache() {
    this.cache.clear();
    this.systemStateCache.clear();
  }

  /**
   * Get scoring statistics
   */
  getStats() {
    return {
      cacheSize: this.cache.size,
      config: this.config
    };
  }
}

module.exports = {
  FreshnessScorer,
  CaptureMetadata,
  FreshnessResult,
  DEFAULT_CONFIG
};

# /Users/james/git/claude-auto-tee/src/semantic/demo.js
#!/usr/bin/env node

/**
 * Demonstration script for SemanticExtractor
 * Shows real-world examples of semantic extraction
 */

const { SemanticExtractor } = require('./semantic-extractor');

console.log('🧠 SemanticExtractor Demo\n');
console.log('=' * 50);

const extractor = new SemanticExtractor();

// Example 1: NPM Test Output
const npmOutput = `
npm test

> myapp@1.0.0 test
> jest --coverage

PASS src/utils/helper.test.js
  ✓ should format dates correctly (5ms)
  ✓ should validate emails (12ms)

PASS src/components/Button.test.js
  ✓ should render button with text (23ms)
  ✓ should handle click events (8ms)

FAIL src/api/client.test.js
  ✗ should handle network errors (45ms)

    TypeError: Cannot read properties of undefined (reading 'data')
        at handleResponse (/Users/dev/myapp/src/api/client.js:34:12)
        at processResponse (/Users/dev/myapp/src/api/client.js:67:8)

Test Suites: 2 passed, 1 failed, 3 total
Tests:       4 passed, 1 failed, 5 total
Coverage:    87.3% of statements
Time:        2.345s
`;

console.log('📝 Example 1: NPM Test Output');
console.log('-'.repeat(30));
const result1 = extractor.extract(npmOutput);
console.log(`✓ Found ${result1.successes.length} success indicators`);
console.log(`✗ Found ${result1.errors.length} error indicators`);
console.log(`📊 Found ${result1.metrics.length} metrics`);
console.log(`📁 Found ${result1.paths.length} file paths`);
console.log(`🎯 Overall confidence: ${(result1.confidence * 100).toFixed(1)}%`);
console.log(`⏱️  Processing time: ${result1.metadata.processingTime}ms\n`);

// Example 2: Build Output
const buildOutput = `
Building production bundle...

✓ Compiling TypeScript sources
✓ Bundling JavaScript modules
⚠ Warning: Large bundle detected (2.1 MB)
✓ Generating source maps (150 KB)
✓ Minifying assets: 2.1 MB → 800 KB (62% reduction)

Build completed successfully in 15.7 seconds
Output: /dist/bundle.js
Ready for deployment at https://myapp.vercel.app
`;

console.log('📝 Example 2: Build Output');
console.log('-'.repeat(30));
const result2 = extractor.extract(buildOutput);
console.log(`✓ Found ${result2.successes.length} success indicators`);
console.log(`✗ Found ${result2.errors.length} error indicators`);
console.log(`📊 Found ${result2.metrics.length} metrics`);
console.log(`📁 Found ${result2.paths.length} file paths`);
console.log(`🌐 Found ${result2.paths.filter(p => p.type === 'url').length} URLs`);
console.log(`🎯 Overall confidence: ${(result2.confidence * 100).toFixed(1)}%`);
console.log(`⏱️  Processing time: ${result2.metadata.processingTime}ms\n`);

// Example 3: Git Output
const gitOutput = `
$ git status
On branch feature/semantic-extractor
Changes to be committed:
  (use "git reset HEAD <file>..." to unstage)

	new file:   src/semantic/semantic-extractor.js
	new file:   test/semantic/semantic-extractor.test.js
	modified:   package.json

$ git commit -m "feat: implement semantic extractor (P3.T005)"
[feature/semantic-extractor 1a2b3c4] feat: implement semantic extractor (P3.T005)
 3 files changed, 847 insertions(+), 2 deletions(-)
 create mode 100644 src/semantic/semantic-extractor.js
 create mode 100644 test/semantic/semantic-extractor.test.js
`;

console.log('📝 Example 3: Git Output');  
console.log('-'.repeat(30));
const result3 = extractor.extract(gitOutput);
console.log(`✓ Found ${result3.successes.length} success indicators`);
console.log(`📁 Found ${result3.paths.length} file paths`);
console.log(`💻 Found ${result3.commands.length} commands`);
console.log(`🎯 Overall confidence: ${(result3.confidence * 100).toFixed(1)}%`);
console.log(`⏱️  Processing time: ${result3.metadata.processingTime}ms\n`);

// Performance test
console.log('🚀 Performance Test');
console.log('-'.repeat(30));
const largeSample = npmOutput.repeat(100); // ~10KB sample
const startTime = Date.now();
const largeResult = extractor.extract(largeSample);
const endTime = Date.now();
console.log(`📏 Input size: ${largeSample.length} bytes (~${(largeSample.length/1024).toFixed(1)}KB)`);
console.log(`⏱️  Processing time: ${endTime - startTime}ms`);
console.log(`✅ Performance requirement: ${endTime - startTime < 50 ? 'PASS' : 'FAIL'} (<50ms)`);
console.log(`🎯 Maintained confidence: ${(largeResult.confidence * 100).toFixed(1)}%\n`);

console.log('🎉 Demo completed successfully!');
console.log('\n📚 See docs/semantic/semantic-patterns.md for full pattern documentation');

# /Users/james/git/claude-auto-tee/src/semantic/semantic-extractor.js
/**
 * SemanticExtractor - Extract semantic information from command outputs
 * 
 * This class provides pattern-based extraction of key information from
 * captured command outputs, including errors, successes, metrics, paths,
 * and recognized commands.
 * 
 * Interface: SemanticExtractor:v1
 * Performance: <50ms for 10KB output
 * Language-agnostic patterns where possible
 */

class SemanticExtractor {
    constructor(options = {}) {
        this.options = {
            includeLineNumbers: options.includeLineNumbers || false,
            maxProcessingTime: options.maxProcessingTime || 50, // ms
            stripAnsi: options.stripAnsi !== false, // default true
            ...options
        };
        
        // Initialize pattern matchers
        this.patterns = this._initializePatterns();
        
        // ANSI escape sequence regex
        this.ansiRegex = /\x1b\[[0-9;]*[mGKH]/g;
    }
    
    /**
     * Extract semantic information from command output
     * @param {string} output - The command output to analyze
     * @param {Object} metadata - Optional metadata (command, timestamp, etc.)
     * @returns {Object} Extracted semantic information with confidence scores
     */
    extract(output, metadata = {}) {
        const startTime = Date.now();
        
        if (!output || typeof output !== 'string') {
            return this._createEmptyResult();
        }
        
        try {
            // Strip ANSI codes if enabled
            const cleanOutput = this.options.stripAnsi ? 
                this._stripAnsiCodes(output) : output;
            
            // Split into lines for analysis
            const lines = cleanOutput.split('\n');
            
            // Extract information using pattern matchers
            const extraction = {
                errors: this._extractErrors(lines),
                successes: this._extractSuccesses(lines),
                metrics: this._extractMetrics(lines),
                paths: this._extractPaths(lines),
                commands: this._extractCommands(lines),
                metadata: {
                    totalLines: lines.length,
                    originalSize: output.length,
                    cleanedSize: cleanOutput.length,
                    processingTime: Date.now() - startTime,
                    ...metadata
                }
            };
            
            // Calculate overall confidence
            extraction.confidence = this._calculateOverallConfidence(extraction);
            
            return extraction;
            
        } catch (error) {
            return {
                ...this._createEmptyResult(),
                error: error.message,
                metadata: {
                    processingTime: Date.now() - startTime,
                    ...metadata
                }
            };
        }
    }
    
    /**
     * Initialize pattern matching definitions
     * @private
     */
    _initializePatterns() {
        return {
            // Error patterns
            errors: [
                { pattern: /^Error:\s*(.+)$/gmi, confidence: 0.95, type: 'generic_error' },
                { pattern: /^(.+)Error:\s*(.+)$/gmi, confidence: 0.9, type: 'typed_error' },
                { pattern: /^Failed:\s*(.+)$/gmi, confidence: 0.9, type: 'failure' },
                { pattern: /^FAIL\s*(.*)$/gmi, confidence: 0.85, type: 'test_failure' },
                { pattern: /^✗\s*(.+)$/gmi, confidence: 0.8, type: 'failed_check' },
                { pattern: /^Exception:\s*(.+)$/gmi, confidence: 0.9, type: 'exception' },
                { pattern: /^\s*at\s+(.+?)\s*\((.+?):(\d+):(\d+)\)/gmi, confidence: 0.95, type: 'stack_trace' },
                { pattern: /^\s*at\s+(.+?)$/gmi, confidence: 0.7, type: 'stack_frame' },
                { pattern: /^npm ERR!\s*(.+)$/gmi, confidence: 0.9, type: 'npm_error' },
                { pattern: /^fatal:\s*(.+)$/gmi, confidence: 0.95, type: 'fatal_error' }
            ],
            
            // Success patterns
            successes: [
                { pattern: /^Success:\s*(.+)$/gmi, confidence: 0.9, type: 'generic_success' },
                { pattern: /^PASS\s*(.*)$/gmi, confidence: 0.85, type: 'test_pass' },
                { pattern: /^✓\s*(.+)$/gmi, confidence: 0.8, type: 'check_passed' },
                { pattern: /^OK\s*(.*)$/gmi, confidence: 0.75, type: 'ok_status' },
                { pattern: /^Completed:\s*(.+)$/gmi, confidence: 0.8, type: 'completion' },
                { pattern: /^Done\s*(.*)$/gmi, confidence: 0.7, type: 'done_status' },
                { pattern: /^\s*(\d+)\s+passing/gmi, confidence: 0.9, type: 'test_summary_pass' },
                { pattern: /^Build successful/gmi, confidence: 0.95, type: 'build_success' }
            ],
            
            // Metrics patterns (numbers with units)
            metrics: [
                { pattern: /(\d+(?:\.\d+)?)\s*(ms|milliseconds?)/gmi, confidence: 0.9, type: 'time_metric', unit: 'ms' },
                { pattern: /(\d+(?:\.\d+)?)\s*(s|seconds?)/gmi, confidence: 0.85, type: 'time_metric', unit: 's' },
                { pattern: /(\d+(?:\.\d+)?)\s*(KB|MB|GB)/gmi, confidence: 0.9, type: 'size_metric' },
                { pattern: /(\d+(?:\.\d+)?)\s*%/gmi, confidence: 0.85, type: 'percentage_metric', unit: '%' },
                { pattern: /(\d+)\/(\d+)/gmi, confidence: 0.8, type: 'ratio_metric' },
                { pattern: /(\d+(?:\.\d+)?)\s*(fps|qps|rps)/gmi, confidence: 0.85, type: 'rate_metric' },
                { pattern: /Coverage:\s*(\d+(?:\.\d+)?)\s*%/gmi, confidence: 0.95, type: 'coverage_metric', unit: '%' }
            ],
            
            // Path patterns
            paths: [
                { pattern: /(?:^|\s)(\/(?:[^\/\s]+\/)*[^\/\s]*)/gm, confidence: 0.8, type: 'unix_path' },
                { pattern: /(?:^|\s)([A-Za-z]:\\(?:[^\\\/\s]+[\\\/])*[^\\\/\s]*)/gm, confidence: 0.8, type: 'windows_path' },
                { pattern: /(?:^|\s)(\.\/(?:[^\/\s]+\/)*[^\/\s]*)/gm, confidence: 0.75, type: 'relative_path' },
                { pattern: /(?:^|\s)(\.\.\/(?:[^\/\s]+\/)*[^\/\s]*)/gm, confidence: 0.75, type: 'parent_relative_path' },
                { pattern: /https?:\/\/(?:[-\w.])+(?::[0-9]+)?(?:\/(?:[\w\/_.])*)?(?:\?[;&%\w=]*)?/gmi, confidence: 0.95, type: 'url' },
                { pattern: /(?:^|\s)(~\/(?:[^\/\s]+\/)*[^\/\s]*)/gm, confidence: 0.8, type: 'home_relative_path' }
            ],
            
            // Command patterns
            commands: [
                { pattern: /^\$\s*(.+)$/gm, confidence: 0.9, type: 'shell_command' },
                { pattern: /^>\s*(.+)$/gm, confidence: 0.8, type: 'prompt_command' },
                { pattern: /^npm\s+(install|start|test|build|run)\s*(.*)?$/gmi, confidence: 0.95, type: 'npm_command' },
                { pattern: /^git\s+(\w+)\s*(.*)?$/gmi, confidence: 0.95, type: 'git_command' },
                { pattern: /^docker\s+(\w+)\s*(.*)?$/gmi, confidence: 0.9, type: 'docker_command' },
                { pattern: /^node\s+(.*)?$/gmi, confidence: 0.85, type: 'node_command' },
                { pattern: /^python\s+(.*)?$/gmi, confidence: 0.85, type: 'python_command' }
            ]
        };
    }
    
    /**
     * Strip ANSI escape sequences from text
     * @param {string} text - Text to clean
     * @returns {string} Cleaned text
     * @private
     */
    _stripAnsiCodes(text) {
        return text.replace(this.ansiRegex, '');
    }
    
    /**
     * Extract error information from lines
     * @param {string[]} lines - Lines to analyze
     * @returns {Array} Extracted errors with confidence scores
     * @private
     */
    _extractErrors(lines) {
        return this._extractByPatterns(lines, this.patterns.errors);
    }
    
    /**
     * Extract success information from lines
     * @param {string[]} lines - Lines to analyze
     * @returns {Array} Extracted successes with confidence scores
     * @private
     */
    _extractSuccesses(lines) {
        return this._extractByPatterns(lines, this.patterns.successes);
    }
    
    /**
     * Extract metrics from lines
     * @param {string[]} lines - Lines to analyze
     * @returns {Array} Extracted metrics with confidence scores
     * @private
     */
    _extractMetrics(lines) {
        return this._extractByPatterns(lines, this.patterns.metrics);
    }
    
    /**
     * Extract paths from lines
     * @param {string[]} lines - Lines to analyze
     * @returns {Array} Extracted paths with confidence scores
     * @private
     */
    _extractPaths(lines) {
        return this._extractByPatterns(lines, this.patterns.paths);
    }
    
    /**
     * Extract commands from lines
     * @param {string[]} lines - Lines to analyze
     * @returns {Array} Extracted commands with confidence scores
     * @private
     */
    _extractCommands(lines) {
        return this._extractByPatterns(lines, this.patterns.commands);
    }
    
    /**
     * Generic pattern extraction method
     * @param {string[]} lines - Lines to analyze
     * @param {Array} patterns - Pattern definitions
     * @returns {Array} Extracted matches with metadata
     * @private
     */
    _extractByPatterns(lines, patterns) {
        const results = [];
        
        for (let lineIndex = 0; lineIndex < lines.length; lineIndex++) {
            const line = lines[lineIndex];
            
            for (const patternDef of patterns) {
                // Reset regex lastIndex for global patterns
                patternDef.pattern.lastIndex = 0;
                
                let match;
                while ((match = patternDef.pattern.exec(line)) !== null) {
                    const result = {
                        type: patternDef.type,
                        content: match[0].trim(),
                        match: match.slice(1), // Captured groups
                        confidence: patternDef.confidence,
                        line: lineIndex + 1,
                        context: line.trim()
                    };
                    
                    // Add unit information if available
                    if (patternDef.unit) {
                        result.unit = patternDef.unit;
                    }
                    
                    results.push(result);
                    
                    // Prevent infinite loops with global regex
                    if (!patternDef.pattern.global) break;
                }
            }
        }
        
        // Remove duplicates and sort by confidence
        return this._deduplicateAndSort(results);
    }
    
    /**
     * Remove duplicate extractions and sort by confidence
     * @param {Array} results - Raw extraction results
     * @returns {Array} Deduplicated and sorted results
     * @private
     */
    _deduplicateAndSort(results) {
        const seen = new Set();
        const unique = [];
        
        for (const result of results) {
            const key = `${result.type}:${result.content}`;
            if (!seen.has(key)) {
                seen.add(key);
                unique.push(result);
            }
        }
        
        return unique.sort((a, b) => b.confidence - a.confidence);
    }
    
    /**
     * Calculate overall confidence score for extraction
     * @param {Object} extraction - Extraction results
     * @returns {number} Overall confidence (0-1)
     * @private
     */
    _calculateOverallConfidence(extraction) {
        const categories = ['errors', 'successes', 'metrics', 'paths', 'commands'];
        let totalConfidence = 0;
        let totalItems = 0;
        
        for (const category of categories) {
            const items = extraction[category] || [];
            for (const item of items) {
                totalConfidence += item.confidence;
                totalItems++;
            }
        }
        
        // If no items found, return low confidence
        if (totalItems === 0) {
            return 0.1;
        }
        
        // Average confidence weighted by presence of different types
        const baseConfidence = totalConfidence / totalItems;
        const typesDiversityBonus = categories.filter(cat => 
            extraction[cat] && extraction[cat].length > 0
        ).length * 0.05;
        
        return Math.min(1.0, baseConfidence + typesDiversityBonus);
    }
    
    /**
     * Create empty extraction result
     * @returns {Object} Empty extraction result structure
     * @private
     */
    _createEmptyResult() {
        return {
            errors: [],
            successes: [],
            metrics: [],
            paths: [],
            commands: [],
            confidence: 0.1,
            metadata: {
                totalLines: 0,
                originalSize: 0,
                cleanedSize: 0,
                processingTime: 0
            }
        };
    }
    
    /**
     * Get extraction patterns for debugging/inspection
     * @returns {Object} Current pattern definitions
     */
    getPatterns() {
        return this.patterns;
    }
    
    /**
     * Add custom pattern to specific category
     * @param {string} category - Category (errors, successes, metrics, paths, commands)
     * @param {Object} patternDef - Pattern definition
     */
    addPattern(category, patternDef) {
        if (this.patterns[category]) {
            this.patterns[category].push(patternDef);
        }
    }
}

module.exports = { SemanticExtractor };

# /Users/james/git/claude-auto-tee/src/unicode/demo.js
#!/usr/bin/env node
/**
 * Unicode Path Handler Demo
 * 
 * Demonstrates the capabilities of the Unicode path handler
 * for the PostToolUse hook implementation.
 */

const { UnicodeHandler } = require('./unicode-path-handler.js');
const PathParser = require('../parser/capture-path-parser.js');

console.log('=== Unicode Path Handler Demo ===');
console.log();

// Create instances
const handler = new UnicodeHandler();
const parser = new PathParser();

console.log('System Information:');
console.log(`Platform: ${handler.platform}`);
console.log(`Default Unicode Normalization: ${handler.defaultNormalization}`);
console.log(`Maximum Path Length: ${handler.maxPathLength}`);
console.log();

// Demo 1: Basic Unicode path handling
console.log('Demo 1: Basic Unicode Path Processing');
console.log('=====================================');

const samplePaths = [
    '/tmp/📝_capture_2025.txt',           // Emoji
    '/home/用户/输出.log',                 // CJK
    '/path/with/مجلد/file.txt',           // RTL Arabic
    '/café/naïve_résumé.txt'              // Diacritics
];

samplePaths.forEach(samplePath => {
    console.log(`\nProcessing: ${samplePath}`);
    
    const analysis = handler.analyzePath(samplePath);
    console.log(`  Normalized: ${analysis.normalized}`);
    console.log(`  Length: ${analysis.length} chars, ${analysis.byteLength} bytes`);
    console.log(`  Scripts: ${[
        analysis.containsEmoji ? 'Emoji' : null,
        analysis.containsCJK ? 'CJK' : null, 
        analysis.containsRTL ? 'RTL' : null
    ].filter(Boolean).join(', ') || 'Latin'}`);
    console.log(`  Shell safe: ${analysis.shellEncoded.bash}`);
});

// Demo 2: Integration with PathParser
console.log('\n\nDemo 2: PathParser Integration');
console.log('==============================');

const stderrExamples = [
    'Command executed successfully\nFull output saved to: /tmp/🎉_test_output.log\nProcess completed',
    'Processing data...\nFull output saved to: /home/用户/分析_结果.txt',
    'Error: Connection timeout\nFull output saved to: "/workspace/مشروع/نتائج.log"'
];

stderrExamples.forEach((stderr, index) => {
    console.log(`\nStderr Example ${index + 1}:`);
    console.log(`Input: ${stderr.replace(/\n/g, '\\n')}`);
    
    const captures = parser.parse(stderr);
    if (captures.length > 0) {
        const capture = captures[0];
        console.log(`  Captured path: ${capture.path}`);
        
        const analysis = handler.analyzePath(capture.path);
        console.log(`  Unicode analysis:`);
        console.log(`    - Normalized: ${analysis.normalized}`);
        console.log(`    - Contains special scripts: ${[
            analysis.containsEmoji ? 'Emoji' : null,
            analysis.containsCJK ? 'CJK' : null,
            analysis.containsRTL ? 'RTL' : null
        ].filter(Boolean).join(', ') || 'None'}`);
        console.log(`    - Shell-safe encoding: ${analysis.shellEncoded.bash}`);
    } else {
        console.log('  No paths captured');
    }
});

// Demo 3: Shell encoding for different environments
console.log('\n\nDemo 3: Cross-Platform Shell Encoding');
console.log('=====================================');

const complexPath = '/project/测试_🔥_café_مجلد/output.log';
console.log(`Complex path: ${complexPath}`);

const shellEncodings = {
    'Bash (Linux/macOS)': handler.encodeForShell(complexPath, 'bash'),
    'CMD (Windows)': handler.encodeForShell(complexPath, 'cmd'),
    'PowerShell': handler.encodeForShell(complexPath, 'powershell')
};

Object.entries(shellEncodings).forEach(([shell, encoded]) => {
    console.log(`  ${shell}: ${encoded}`);
});

// Demo 4: Error handling showcase
console.log('\n\nDemo 4: Error Handling');
console.log('======================');

const problematicPaths = [
    null,                               // Null input
    '',                                // Empty string  
    '/path/with/null\x00byte.txt',     // Null bytes
    '/path/' + 'a'.repeat(5000) + '.txt' // Too long
];

problematicPaths.forEach((badPath, index) => {
    try {
        const result = handler.normalizePath(badPath);
        console.log(`  Test ${index + 1}: ❌ Should have failed for: ${JSON.stringify(badPath)}`);
    } catch (error) {
        console.log(`  Test ${index + 1}: ✓ Correctly rejected: ${error.name} - ${error.message.substring(0, 50)}...`);
    }
});

console.log('\n=== Demo Complete ===');
console.log();
console.log('The Unicode Path Handler successfully:');
console.log('✓ Handles emoji, CJK, RTL, and diacritic characters in paths');
console.log('✓ Normalizes paths according to filesystem requirements');
console.log('✓ Provides shell-safe encoding for different environments');
console.log('✓ Integrates seamlessly with the PathParser');
console.log('✓ Validates and sanitizes paths for security');
console.log('✓ Supports cross-platform path handling');

# /Users/james/git/claude-auto-tee/src/unicode/unicode-path-handler.js
#!/usr/bin/env node
/**
 * Unicode Path Handler - UnicodeHandler:v1
 * Comprehensive Unicode path handling for claude-auto-tee PostToolUse hook
 * P2.T006 - Handle Unicode paths for the PostToolUse hook implementation
 * 
 * This module provides bulletproof Unicode handling for global user base.
 * Supports UTF-8, UTF-16, emoji, CJK characters, RTL text, combining characters,
 * and proper normalization across different filesystems.
 */

const path = require('path');
const fs = require('fs');

/**
 * Custom error types for Unicode path handling
 */
class UnicodePathError extends Error {
    constructor(message, code = 'UNICODE_PATH_ERROR', path = null) {
        super(message);
        this.name = 'UnicodePathError';
        this.code = code;
        this.path = path;
    }
}

class UnicodeNormalizationError extends UnicodePathError {
    constructor(message, path = null) {
        super(message, 'UNICODE_NORMALIZATION_ERROR', path);
        this.name = 'UnicodeNormalizationError';
    }
}

class UnicodeEncodingError extends UnicodePathError {
    constructor(message, path = null) {
        super(message, 'UNICODE_ENCODING_ERROR', path);
        this.name = 'UnicodeEncodingError';
    }
}

/**
 * Main Unicode Path Handler Class
 */
class UnicodeHandler {
    constructor() {
        this.platform = process.platform;
        this.supportedEncodings = ['utf8', 'utf16le', 'ascii', 'latin1'];
        
        // Filesystem-specific normalization preferences
        this.fsNormalizationMap = {
            'darwin': 'NFD',     // HFS+ prefers NFD
            'win32': 'NFC',      // NTFS prefers NFC
            'linux': 'NFC',      // ext4 and most Linux fs prefer NFC
            'freebsd': 'NFC',    // UFS prefers NFC
            'openbsd': 'NFC',    // FFS prefers NFC
            'sunos': 'NFC'       // ZFS prefers NFC
        };
        
        // Zero-width and problematic Unicode categories
        this.problematicCategories = [
            'Mn', // Mark, nonspacing (combining diacritics)
            'Me', // Mark, enclosing
            'Cf', // Other, format (zero-width chars)
            'Cs', // Other, surrogate
            'Co', // Other, private use
            'Cn'  // Other, not assigned
        ];
        
        // Initialize platform-specific settings
        this.initializePlatformSettings();
    }
    
    /**
     * Initialize platform-specific Unicode settings
     */
    initializePlatformSettings() {
        this.defaultNormalization = this.fsNormalizationMap[this.platform] || 'NFC';
        this.maxPathLength = this.platform === 'win32' ? 260 : 4096;
        this.pathSeparator = this.platform === 'win32' ? '\\' : '/';
        this.reservedNames = this.platform === 'win32' ? 
            ['CON', 'PRN', 'AUX', 'NUL', 'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9', 'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9'] : 
            [];
    }
    
    /**
     * Normalize Unicode path according to filesystem requirements
     * @param {string} inputPath - The path to normalize
     * @param {string} form - Normalization form (NFC, NFD, NFKC, NFKD)
     * @returns {string} Normalized path
     */
    normalizePath(inputPath, form = null) {
        if (!inputPath || typeof inputPath !== 'string') {
            throw new UnicodePathError('Input path must be a non-empty string', 'INVALID_INPUT', inputPath);
        }
        
        const normForm = form || this.defaultNormalization;
        
        try {
            // Normalize Unicode characters
            let normalized = inputPath.normalize(normForm);
            
            // Handle platform-specific path separators
            normalized = this.normalizePathSeparators(normalized);
            
            // Remove zero-width characters that could cause issues
            normalized = this.removeProblematicCharacters(normalized);
            
            // Validate the normalized path
            this.validateNormalizedPath(normalized);
            
            return normalized;
        } catch (error) {
            if (error instanceof UnicodePathError) {
                throw error;
            }
            throw new UnicodeNormalizationError(`Failed to normalize path: ${error.message}`, inputPath);
        }
    }
    
    /**
     * Normalize path separators for the current platform
     * @param {string} pathStr - Path string to normalize
     * @returns {string} Path with normalized separators
     */
    normalizePathSeparators(pathStr) {
        if (this.platform === 'win32') {
            // Convert forward slashes to backslashes on Windows
            return pathStr.replace(/\//g, '\\');
        } else {
            // Convert backslashes to forward slashes on Unix-like systems
            return pathStr.replace(/\\/g, '/');
        }
    }
    
    /**
     * Remove problematic Unicode characters that could cause filesystem issues
     * @param {string} pathStr - Path string to clean
     * @returns {string} Cleaned path string
     */
    removeProblematicCharacters(pathStr) {
        // Remove zero-width spaces and similar characters
        let cleaned = pathStr.replace(/[\u200B-\u200D\uFEFF]/g, '');
        
        // Remove bidirectional text markers that could cause confusion
        cleaned = cleaned.replace(/[\u202A-\u202E\u2066-\u2069]/g, '');
        
        // Handle combining characters - keep them but ensure they're properly attached
        cleaned = this.handleCombiningCharacters(cleaned);
        
        return cleaned;
    }
    
    /**
     * Handle combining characters properly
     * @param {string} pathStr - Path string with potential combining characters
     * @returns {string} Path with properly handled combining characters
     */
    handleCombiningCharacters(pathStr) {
        // Ensure combining characters are properly attached to their base characters
        // This prevents orphaned combining marks
        return pathStr.replace(/^[\u0300-\u036F\u1AB0-\u1AFF\u1DC0-\u1DFF\u20D0-\u20FF\uFE20-\uFE2F]+/g, '');
    }
    
    /**
     * Validate normalized path for filesystem compatibility
     * @param {string} normalizedPath - The normalized path to validate
     * @throws {UnicodePathError} If path is invalid
     */
    validateNormalizedPath(normalizedPath) {
        // Check path length
        if (normalizedPath.length > this.maxPathLength) {
            throw new UnicodePathError(
                `Path exceeds maximum length (${this.maxPathLength}): ${normalizedPath.length}`,
                'PATH_TOO_LONG',
                normalizedPath
            );
        }
        
        // Check for null bytes
        if (normalizedPath.includes('\0')) {
            throw new UnicodePathError('Path contains null bytes', 'NULL_BYTES', normalizedPath);
        }
        
        // Check for reserved names on Windows
        if (this.platform === 'win32') {
            const pathComponents = normalizedPath.split(/[/\\]/);
            for (const component of pathComponents) {
                const baseName = component.split('.')[0].toUpperCase();
                if (this.reservedNames.includes(baseName)) {
                    throw new UnicodePathError(
                        `Path contains reserved Windows name: ${component}`,
                        'RESERVED_NAME',
                        normalizedPath
                    );
                }
            }
        }
        
        // Check for dangerous directory traversal patterns
        if (normalizedPath.includes('..') && (normalizedPath.includes('../') || normalizedPath.includes('..\\'))) {
            throw new UnicodePathError('Path contains directory traversal', 'DIRECTORY_TRAVERSAL', normalizedPath);
        }
    }
    
    /**
     * Encode path for shell command execution
     * @param {string} pathStr - Path to encode
     * @param {string} shellType - Type of shell ('bash', 'cmd', 'powershell')
     * @returns {string} Shell-encoded path
     */
    encodeForShell(pathStr, shellType = 'bash') {
        const normalizedPath = this.normalizePath(pathStr);
        
        switch (shellType.toLowerCase()) {
            case 'bash':
            case 'sh':
            case 'zsh':
                return this.encodeBashPath(normalizedPath);
            case 'cmd':
                return this.encodeCmdPath(normalizedPath);
            case 'powershell':
            case 'pwsh':
                return this.encodePowerShellPath(normalizedPath);
            default:
                return this.encodeBashPath(normalizedPath); // Default to bash
        }
    }
    
    /**
     * Encode path for bash shell
     * @param {string} pathStr - Path to encode
     * @returns {string} Bash-encoded path
     */
    encodeBashPath(pathStr) {
        // Use single quotes to preserve all characters literally
        // Escape any single quotes in the path by ending the quoted string,
        // adding an escaped single quote, then starting a new quoted string
        return "'" + pathStr.replace(/'/g, "'\"'\"'") + "'";
    }
    
    /**
     * Encode path for Windows CMD
     * @param {string} pathStr - Path to encode
     * @returns {string} CMD-encoded path
     */
    encodeCmdPath(pathStr) {
        // Use double quotes and escape special characters
        let encoded = pathStr.replace(/"/g, '""');
        encoded = encoded.replace(/[&<>|^%]/g, '^$&');
        return '"' + encoded + '"';
    }
    
    /**
     * Encode path for PowerShell
     * @param {string} pathStr - Path to encode
     * @returns {string} PowerShell-encoded path
     */
    encodePowerShellPath(pathStr) {
        // Use single quotes and escape single quotes
        return "'" + pathStr.replace(/'/g, "''") + "'";
    }
    
    /**
     * Encode path for JSON contexts
     * @param {string} pathStr - Path to encode
     * @returns {string} JSON-encoded path
     */
    encodeForJSON(pathStr) {
        const normalizedPath = this.normalizePath(pathStr);
        return JSON.stringify(normalizedPath);
    }
    
    /**
     * Detect the encoding of a path string
     * @param {string|Buffer} pathInput - Path to detect encoding for
     * @returns {string} Detected encoding
     */
    detectEncoding(pathInput) {
        if (Buffer.isBuffer(pathInput)) {
            // Try to detect encoding from buffer - check UTF-16LE first (more specific)
            if (this.isValidUTF16LE(pathInput)) {
                return 'utf16le';
            } else if (this.isValidUTF8(pathInput)) {
                return 'utf8';
            } else {
                return 'latin1'; // Fallback for binary data
            }
        }
        
        // For strings, assume UTF-8
        return 'utf8';
    }
    
    /**
     * Check if buffer contains valid UTF-8
     * @param {Buffer} buffer - Buffer to check
     * @returns {boolean} True if valid UTF-8
     */
    isValidUTF8(buffer) {
        try {
            buffer.toString('utf8');
            return true;
        } catch (error) {
            return false;
        }
    }
    
    /**
     * Check if buffer contains valid UTF-16LE
     * @param {Buffer} buffer - Buffer to check
     * @returns {boolean} True if valid UTF-16LE
     */
    isValidUTF16LE(buffer) {
        try {
            // UTF-16LE should have even length
            if (buffer.length % 2 !== 0) return false;
            
            // Check for UTF-16LE BOM (FF FE) or decode successfully
            if (buffer.length >= 2 && buffer[0] === 0xFF && buffer[1] === 0xFE) {
                return true;
            }
            
            // Try to decode - if it succeeds and contains valid UTF-16 patterns, it's probably UTF-16LE
            const decoded = buffer.toString('utf16le');
            return decoded.length > 0 && !decoded.includes('\uFFFD'); // No replacement characters
        } catch (error) {
            return false;
        }
    }
    
    /**
     * Convert path between different encodings
     * @param {string|Buffer} pathInput - Path to convert
     * @param {string} fromEncoding - Source encoding
     * @param {string} toEncoding - Target encoding
     * @returns {string} Converted path
     */
    convertEncoding(pathInput, fromEncoding, toEncoding) {
        if (!this.supportedEncodings.includes(fromEncoding) || 
            !this.supportedEncodings.includes(toEncoding)) {
            throw new UnicodeEncodingError(
                `Unsupported encoding. Supported: ${this.supportedEncodings.join(', ')}`,
                pathInput
            );
        }
        
        try {
            let pathStr;
            if (Buffer.isBuffer(pathInput)) {
                pathStr = pathInput.toString(fromEncoding);
            } else {
                pathStr = pathInput;
            }
            
            // Convert through Unicode normalization
            const normalized = this.normalizePath(pathStr);
            
            // Return as string (Node.js handles internal encoding)
            return normalized;
        } catch (error) {
            throw new UnicodeEncodingError(
                `Failed to convert encoding from ${fromEncoding} to ${toEncoding}: ${error.message}`,
                pathInput
            );
        }
    }
    
    /**
     * Check if path contains RTL (Right-to-Left) text
     * @param {string} pathStr - Path to check
     * @returns {boolean} True if contains RTL text
     */
    containsRTL(pathStr) {
        // Check for Arabic, Hebrew, and other RTL scripts
        const rtlRegex = /[\u0590-\u05FF\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB1D-\uFDFF\uFE70-\uFEFF]/;
        return rtlRegex.test(pathStr);
    }
    
    /**
     * Check if path contains CJK (Chinese, Japanese, Korean) characters
     * @param {string} pathStr - Path to check
     * @returns {boolean} True if contains CJK characters
     */
    containsCJK(pathStr) {
        // Check for CJK ideographs and related scripts including Hangul
        const cjkRegex = /[\u2E80-\u2EFF\u2F00-\u2FDF\u3040-\u309F\u30A0-\u30FF\u3100-\u312F\u3130-\u318F\u3190-\u319F\u31C0-\u31EF\u3200-\u32FF\u3400-\u4DBF\u4E00-\u9FFF\uAC00-\uD7AF\uF900-\uFAFF]/;
        return cjkRegex.test(pathStr);
    }
    
    /**
     * Check if path contains emoji
     * @param {string} pathStr - Path to check
     * @returns {boolean} True if contains emoji
     */
    containsEmoji(pathStr) {
        // Check for emoji ranges
        const emojiRegex = /[\u{1F600}-\u{1F64F}]|[\u{1F300}-\u{1F5FF}]|[\u{1F680}-\u{1F6FF}]|[\u{1F1E0}-\u{1F1FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/u;
        return emojiRegex.test(pathStr);
    }
    
    /**
     * Create a safe temporary path with Unicode support
     * @param {string} tempDir - Temporary directory
     * @param {string} prefix - Filename prefix
     * @param {string} suffix - Filename suffix
     * @returns {string} Safe temporary path
     */
    createSafeTempPath(tempDir, prefix = 'claude-auto-tee', suffix = '.log') {
        const normalizedTempDir = this.normalizePath(tempDir);
        this.validateNormalizedPath(normalizedTempDir);
        
        // Generate unique filename with timestamp and random component
        const timestamp = Date.now();
        const random = Math.floor(Math.random() * 10000);
        const filename = `${prefix}-${timestamp}-${random}${suffix}`;
        
        // Ensure filename doesn't contain problematic Unicode
        const safeFilename = this.normalizePath(filename);
        
        return path.join(normalizedTempDir, safeFilename);
    }
    
    /**
     * Extract analysis information about a Unicode path
     * @param {string} pathStr - Path to analyze
     * @returns {Object} Analysis results
     */
    analyzePath(pathStr) {
        return {
            original: pathStr,
            normalized: this.normalizePath(pathStr),
            platform: this.platform,
            encoding: this.detectEncoding(pathStr),
            normalizationForm: this.defaultNormalization,
            length: pathStr.length,
            byteLength: Buffer.byteLength(pathStr, 'utf8'),
            containsRTL: this.containsRTL(pathStr),
            containsCJK: this.containsCJK(pathStr),
            containsEmoji: this.containsEmoji(pathStr),
            shellEncoded: {
                bash: this.encodeForShell(pathStr, 'bash'),
                cmd: this.encodeForShell(pathStr, 'cmd'),
                powershell: this.encodeForShell(pathStr, 'powershell')
            },
            jsonEncoded: this.encodeForJSON(pathStr)
        };
    }
}

// Export the classes and create a default instance
module.exports = {
    UnicodeHandler,
    UnicodePathError,
    UnicodeNormalizationError,
    UnicodeEncodingError
};

// Create and export default instance
const defaultHandler = new UnicodeHandler();
module.exports.default = defaultHandler;

// Command-line interface when run directly
if (require.main === module) {
    const args = process.argv.slice(2);
    
    if (args.length === 0) {
        console.log('Unicode Path Handler - UnicodeHandler:v1');
        console.log('Usage: node unicode-path-handler.js <command> [arguments]');
        console.log('');
        console.log('Commands:');
        console.log('  normalize <path>           - Normalize a Unicode path');
        console.log('  analyze <path>             - Analyze Unicode path properties');
        console.log('  encode <path> <shell>      - Encode path for shell (bash/cmd/powershell)');
        console.log('  test                       - Run built-in tests');
        console.log('');
        console.log('Examples:');
        console.log('  node unicode-path-handler.js normalize "/tmp/test_🎉_output.txt"');
        console.log('  node unicode-path-handler.js analyze "/用户/文档/输出.log"');
        console.log('  node unicode-path-handler.js encode "/café/naïve.txt" bash');
        process.exit(0);
    }
    
    const command = args[0];
    const handler = new UnicodeHandler();
    
    try {
        switch (command) {
            case 'normalize':
                if (args.length < 2) {
                    console.error('Error: normalize command requires a path argument');
                    process.exit(1);
                }
                console.log(handler.normalizePath(args[1]));
                break;
                
            case 'analyze':
                if (args.length < 2) {
                    console.error('Error: analyze command requires a path argument');
                    process.exit(1);
                }
                console.log(JSON.stringify(handler.analyzePath(args[1]), null, 2));
                break;
                
            case 'encode':
                if (args.length < 3) {
                    console.error('Error: encode command requires path and shell type arguments');
                    process.exit(1);
                }
                console.log(handler.encodeForShell(args[1], args[2]));
                break;
                
            case 'test':
                // Run basic tests
                const testPaths = [
                    '/tmp/test_🎉_output.txt',
                    '/用户/文档/输出.log',
                    '/מסמכים/פלט.txt',
                    '/café/naïve.txt'
                ];
                
                console.log('=== Unicode Path Handler Tests ===');
                for (const testPath of testPaths) {
                    console.log(`\nTesting: ${testPath}`);
                    const analysis = handler.analyzePath(testPath);
                    console.log(`  Normalized: ${analysis.normalized}`);
                    console.log(`  Contains RTL: ${analysis.containsRTL}`);
                    console.log(`  Contains CJK: ${analysis.containsCJK}`);
                    console.log(`  Contains Emoji: ${analysis.containsEmoji}`);
                    console.log(`  Bash encoded: ${analysis.shellEncoded.bash}`);
                }
                console.log('\n=== All tests completed ===');
                break;
                
            default:
                console.error(`Error: Unknown command "${command}"`);
                process.exit(1);
        }
    } catch (error) {
        console.error(`Error: ${error.message}`);
        process.exit(1);
    }
}

